{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503c81c2-012a-4e15-a255-a4a3e4c576d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece protobuf datasets transformers trl textstat peft bitsandbytes nltk --quiet\n",
    "!pip install -U bitsandbytes accelerate --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2c708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hf.token\", \"r\") as f:\n",
    "    hftoken = f.read().strip()  \n",
    "\n",
    "import os\n",
    "cache_dir = \"/mnt/c/Users/yc/.cache/huggingface\"\n",
    "os.environ['HF_HOME'] = cache_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c967d-ea35-4d4e-8ddc-f39328032b1a",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3b7919-277b-47b9-95b9-eab518373862",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yc/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import csv\n",
    "import re\n",
    "import torch\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "from collections import Counter\n",
    "import textwrap\n",
    "\n",
    "\n",
    "LINE_WIDTH = 140\n",
    "# Third-party data and ML libraries\n",
    "import pandas as pd\n",
    "# Hugging Face ecosystem\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "# Optional: Uncomment if needed\n",
    "from huggingface_hub import login\n",
    "login(token=hftoken)  # Move token to environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd4555-473d-48cd-bc86-60a4c41da0a8",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d74a59c-b625-4944-8a79-aea69bc6cd8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:31<00:00,  7.98s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "device_map = {\"\": 0}\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map,\n",
    "    load_in_8bit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1c388-57f9-41b0-87d1-25a9ad884430",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf6281f4-7ebb-48fd-a08b-4271349ededf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def txt_to_dict(file_path):\n",
    "    data_dict = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(0, len(lines) - 1, 2):\n",
    "            key = lines[i].strip()    # Odd line are key\n",
    "            value = lines[i + 1].strip()  # Even line are value\n",
    "            data_dict[key] = value\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "txt_file_path = 'data/formaldef.txt'\n",
    "formaldic = txt_to_dict(txt_file_path)\n",
    "len(formaldic)\n",
    "\n",
    "meddict={}\n",
    "for k,v in formaldic.items():\n",
    "    meddict[k.split('Listen to pronunciation')[0].split('(')[0]]=v\n",
    "filename= 'data/filtered_medical_dictionary.csv'\n",
    "eighth_grade_words=set()\n",
    "with open(filename, 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)  # Skip the header row\n",
    "    for row in reader:\n",
    "        if row:  # Make sure row is not empty\n",
    "            eighth_grade_words.add(row[0])  # Add the word (first column)\n",
    "filtered_meddict = {word: explanation for word, explanation in meddict.items() \n",
    "                   if word in eighth_grade_words}\n",
    "meddict=filtered_meddict\n",
    "# load data\n",
    "df = pd.read_csv('/mnt/c/Users/yc/Downloads/coral/unannotated/data/breastca_unannotated.csv')\n",
    "df = df.sample(2, random_state=42) \n",
    "text=df.iloc[0]['note_text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8239be",
   "metadata": {},
   "source": [
    "audience--> audiense str\n",
    "key details, summary --> a summary\n",
    "extraction terms --> a dict?\n",
    "main prompt, takes in 123, out a str\n",
    "check with key details and main Gen, takes \n",
    "final clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a445b4-0a2b-45d1-9892-42f775ef20b8",
   "metadata": {},
   "source": [
    "# prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516413a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing row 84/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yc/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/yc/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home/yc/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS FOR ROW 84\n",
      "============================================================\n",
      "\n",
      "--- Column: keysummary ---\n",
      "**TREATMENTS RECEIVED:**  * Letrozole and Palbociclib * Zolendronic acid * Capecitabine (Xeloda) *\n",
      "Fulvestrant (considered for future option)  **MEDICAL CONDITIONS:**  * Metastatic breast cancer *\n",
      "Multiple sclerosis * CHEK2 mutation * Liver disease * Possibly leptomeningeal disease * Bone\n",
      "metastases * Soft tissue metastases  **CANCER STAGE:** Metastatic  **REFERRALS:**  * Referral to\n",
      "radiation oncology for consideration of radiation therapy * Referral to UCSF Rad Onc for opinion\n",
      "**CURRENT STATUS:**  * Extensive osseous metastatic disease * Disease in bone, soft tissue, liver,\n",
      "and possibly meninges * Progressively worsening neurologic symptoms * Recent right hearing loss *\n",
      "Decreased vision in right eye * Double vision with gaze in certain positions  **NEXT STEPS/PLAN:**\n",
      "* Repeat CT CAP now * Repeat LP for CSF cytology * Repeat MRI spine to rule out LMD in the spine *\n",
      "Consider starting low-dose steroids to see if reduction of swelling improves symptoms * Continue\n",
      "Xeloda 1500mg BID for now * Continue zolendronic acid * Consider fulvestrant + palbociclib at time\n",
      "of progression of disease\n",
      "\n",
      "--- Column: raw_explanation ---\n",
      "Dear [Patient's Family],  We want to take a moment to discuss your loved one's situation and the\n",
      "latest developments regarding her health.   ### Why did you come to the clinic? Your loved one came\n",
      "to us because she has been experiencing some concerning symptoms, particularly with regards to her\n",
      "vision and hearing. She has noticed a decline in her eyesight and has experienced hearing loss in\n",
      "her right ear.  ### What was discussed? During our conversation, we went over her medical history,\n",
      "including her previous diagnoses of metastatic breast cancer, multiple sclerosis, and a CHEK2\n",
      "mutation. We also talked about her treatment plans and the various medications she has been taking,\n",
      "such as letrozole, palbociclib, zolendronic acid, and capecitabine (also known as Xeloda).  ### What\n",
      "did we find? Our team has been monitoring your loved one's progress closely, and unfortunately,\n",
      "we've seen that her cancer has continued to spread to other parts of her body, including her bones,\n",
      "soft tissue, liver, and possibly her meninges. Her neurological symptoms have also been getting\n",
      "progressively worse, indicating potential complications.  ### What is the plan? Given the current\n",
      "situation, we're recommending the following:  * We'll conduct another CT scan (called a CT CAP) to\n",
      "evaluate the extent of the cancer's spread. * We'll repeat a procedure called a lumbar puncture (LP)\n",
      "to collect a sample of cerebrospinal fluid (CSF) to check for any signs of cancer cells. * We might\n",
      "prescribe low-dose steroids to see if they alleviate some of her symptoms. * We'll continue treating\n",
      "her with Xeloda (capecitabine). * We'll keep administering zolendronic acid to manage her bone-\n",
      "related issues. * If the cancer progresses, we might explore alternative treatments, including a\n",
      "medication called fulvestrant combined with palbociclib.  ### Closing with Support We understand\n",
      "that this news can be overwhelming, and we want to assure you that we're committed to providing the\n",
      "best possible care for your loved one. Our team is here to answer any questions you may have and\n",
      "offer emotional support throughout this challenging time.  If you have any concerns or questions,\n",
      "please don't hesitate to reach out to us. We're here to support you and your loved one.  Sincerely,\n",
      "Your Care Team at [Institution]\n",
      "\n",
      "--- Column: final_letter ---\n",
      "Dear [Patient's Family],  We would like to take a moment to discuss your loved one's situation and\n",
      "the latest developments regarding her health.  She came to us due to concerning symptoms affecting\n",
      "her vision and hearing, specifically a decline in her eyesight and hearing loss in her right ear.\n",
      "During our conversation, we reviewed her medical history, which includes previous diagnoses of\n",
      "metastatic breast cancer, multiple sclerosis, and a CHEK2 mutation. We also discussed her ongoing\n",
      "treatment plans and the various medications she has been taking, such as letrozole, palbociclib,\n",
      "zolendronic acid, and capecitabine (also known as Xeloda), a chemotherapy medication used to treat\n",
      "certain types of cancer.  Our team has been closely monitoring your loved one's progress, and\n",
      "unfortunately, we've observed that her cancer has continued to spread to other parts of her body,\n",
      "including her bones, soft tissue, liver, and potentially her meninges. Additionally, her\n",
      "neurological symptoms have worsened, suggesting potential complications.  Considering the current\n",
      "situation, we recommend the following course of action:  We will perform another computed tomography\n",
      "(CT) scan to assess the extent of the cancer's spread. This imaging test uses X-rays to produce\n",
      "detailed cross-sectional images of internal structures. We will also repeat a lumbar puncture (LP)\n",
      "to collect a sample of cerebrospinal fluid (CSF) to check for any signs of cancer cells in the\n",
      "central nervous system. Furthermore, we may prescribe low-dose steroids to determine whether they\n",
      "alleviate some of her symptoms. Treatment with Xeloda (capecitabine) will continue, and zolendronic\n",
      "acid will remain administered to manage her bone-related issues. If the cancer progresses, we may\n",
      "consider exploring alternative treatments, including a combination of fulvestrant and palbociclib.\n",
      "We recognize that this news can be overwhelming, and we want to reassure you that we are committed\n",
      "to providing the best possible care for your loved one. Our team is available to address any\n",
      "questions you may have and offer emotional support during this challenging time.  Please do not\n",
      "hesitate to contact us if you have any concerns or questions. We are here to support both you and\n",
      "your loved one.  Sincerely, Your Care Team at [Institution]  Note: I made the following changes to\n",
      "the original text:  - Improved sentence structure and wording for better clarity. - Removed\n",
      "redundant words and phrases. - Enhanced the logical flow and transitions between sections. - Defined\n",
      "medical terms for the target audience (family/patient) where necessary. - Removed section headings\n",
      "and formatted the text as a continuous letter.\n",
      "\n",
      "Processing row 54/2...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "def clean_model_output(text: str, fix_incomplete=True) -> str:\n",
    "    \"\"\"\n",
    "    Clean up model-generated text with common fixes, not currently using\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Basic cleanup\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize all whitespace\n",
    "    \n",
    "    # Fix paragraph spacing\n",
    "    text = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', text)\n",
    "    \n",
    "    # Fix punctuation spacing\n",
    "    text = re.sub(r'\\s+([,.!?;:])', r'\\1', text)\n",
    "    text = re.sub(r'([.!?])\\s*([A-Z])', r'\\1 \\2', text)\n",
    "    \n",
    "    # Remove repetitive patterns (simple version)\n",
    "    lines = text.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        if not cleaned_lines or line.strip() != cleaned_lines[-1].strip():\n",
    "            cleaned_lines.append(line)\n",
    "    text = '\\n'.join(cleaned_lines)\n",
    "    \n",
    "    # Handle incomplete sentences\n",
    "    if fix_incomplete and text and not text.endswith(('.', '!', '?')):\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        if len(sentences) > 1 and len(sentences[-1].strip()) < 10:\n",
    "            # Remove likely incomplete last sentence\n",
    "            text = '.'.join(sentences[:-1]) + '.'\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def extract_medical_terms(text: str, meddict: Dict[str, str]) -> Dict[str, str]:\n",
    "\n",
    "    found_terms = {}\n",
    "    \n",
    "    # Strategy 1: Single words\n",
    "    words = re.findall(r'\\b[A-Za-z]+(?:[-\\'][A-Za-z]+)*\\b', text)\n",
    "    for word in words:\n",
    "        definition = find_term_in_dict(word, meddict)\n",
    "        if definition:\n",
    "            found_terms[word] = definition\n",
    "    \n",
    "    # Strategy 2: Multi-word terms\n",
    "    for n in range(2, 6):\n",
    "        n_grams = get_n_grams(text, n)\n",
    "        for phrase in n_grams:\n",
    "            definition = find_term_in_dict(phrase, meddict)\n",
    "            if definition:\n",
    "                found_terms[phrase] = definition\n",
    "    \n",
    "    # Strategy 3: Medical abbreviations\n",
    "    abbreviations = re.findall(r'\\b[A-Z]{2,8}\\b', text)\n",
    "    for abbrev in abbreviations:\n",
    "        definition = find_term_in_dict(abbrev, meddict)\n",
    "        if definition:\n",
    "            found_terms[abbrev] = definition\n",
    "    \n",
    "    # Strategy 4: Medical procedures and conditions with specific patterns\n",
    "    medical_patterns = [\n",
    "        r'\\b\\w+oscopy\\b',          # bronchoscopy, endoscopy, etc.\n",
    "        r'\\b\\w+ectomy\\b',          # appendectomy, etc.\n",
    "        r'\\b\\w+itis\\b',            # bronchitis, arthritis, etc.\n",
    "        r'\\b\\w+osis\\b',            # fibrosis, stenosis, etc.\n",
    "        r'\\b\\w+emia\\b',            # anemia, septicemia, etc.\n",
    "        r'\\b\\w+pathy\\b',           # myopathy, neuropathy, etc.\n",
    "        r'\\b\\w+malacia\\b',         # tracheomalacia, etc.\n",
    "    ]\n",
    "    \n",
    "    for pattern in medical_patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            definition = find_term_in_dict(match, meddict)\n",
    "            if definition:\n",
    "                found_terms[match] = definition\n",
    "    \n",
    "    # Strategy 5: Medication names\n",
    "    medication_patterns = [\n",
    "        r'\\b\\w+cillin\\b',          # penicillin, amoxicillin, etc.\n",
    "        r'\\b\\w+mycin\\b',           # streptomycin, etc.\n",
    "        r'\\b\\w+floxacin\\b',        # levofloxacin, ciprofloxacin, etc.\n",
    "        r'\\b\\w+sone\\b',            # prednisone, cortisone, etc.\n",
    "        r'\\b\\w+pam\\b',             # lorazepam, etc.\n",
    "    ]\n",
    "    \n",
    "    for pattern in medication_patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            definition = find_term_in_dict(match, meddict)\n",
    "            if definition:\n",
    "                found_terms[match] = definition\n",
    "    \n",
    "    return found_terms\n",
    "\n",
    "\n",
    "def get_n_grams(text: str, n: int) -> List[str]:\n",
    "    \"\"\"Generate n-grams from text.\"\"\"\n",
    "    words = re.findall(r'\\b[A-Za-z]+\\b', text.lower())\n",
    "    n_grams = []\n",
    "    for i in range(len(words) - n + 1):\n",
    "        phrase = ' '.join(words[i:i+n])\n",
    "        n_grams.append(phrase)\n",
    "    return n_grams\n",
    "\n",
    "\n",
    "def find_term_in_dict(term: str, meddict: Dict[str, str]) -> Optional[str]:\n",
    "    \"\"\"Find term in medical dictionary.\"\"\"\n",
    "    search_formats = [\n",
    "        term, term.lower(), term.upper(), term.title(), term.capitalize()\n",
    "    ]\n",
    "    \n",
    "    for search_term in search_formats:\n",
    "        if search_term in meddict:\n",
    "            return meddict[search_term]\n",
    "    \n",
    "    # Partial matching\n",
    "    for key in meddict.keys():\n",
    "        if key.lower() == term.lower():\n",
    "            return meddict[key]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_annotated_text(text: str, meddict: Dict[str, str]) -> str:\n",
    "\n",
    "    # 1. Use the existing function to find all unique terms and their definitions.\n",
    "    found_terms = extract_medical_terms(text, meddict)\n",
    "    \n",
    "    # 2. Sort terms by length in descending order to handle overlaps.\n",
    "    # This is critical for terms like \"cerebral palsy\" and \"palsy\".\n",
    "    sorted_terms = sorted(found_terms.keys(), key=len, reverse=True)\n",
    "    \n",
    "    annotated_text = text\n",
    "    \n",
    "    # 3. Iterate and replace.\n",
    "    for term in sorted_terms:\n",
    "        definition = found_terms[term]\n",
    "        annotation = f\"{term} [DEFINITION: {definition}]\"\n",
    "        pattern = r'\\b' + re.escape(term) + r'\\b'\n",
    "        annotated_text = re.sub(pattern, annotation, annotated_text, count=1, flags=re.IGNORECASE)\n",
    "        \n",
    "    return annotated_text\n",
    "\n",
    "\n",
    "def create_key_summary_prompt(original_text: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are an expert medical information extractor with exceptional attention to detail. Your task is to carefully read the medical text and extract ONLY the key factual details that are explicitly mentioned. You must be extremely precise and never infer, assume, or add any information not directly stated in the text.\n",
    "CRITICAL RULES:\n",
    "1. Extract ONLY facts explicitly stated in the text\n",
    "2. Use the EXACT wording from the original text when possible\n",
    "3. Do not interpret, infer, or elaborate beyond what is written\n",
    "4. If multiple items exist in a category, separate them with semicolons\n",
    "5. Keep each section concise but complete\n",
    "6. If a category is not mentioned or unclear, write \"Not mentioned\" for that section.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"**Medical Text:**\\n\"{original_text}\"\\n\\n**Format your response EXACTLY as follows:**\\n\\n**TREATMENTS RECEIVED:**\\n[List treatments]\\n\\n**MEDICAL CONDITIONS:**\\n[List conditions]\\n\\n**CANCER STAGE:**\\n[List stage]\\n\\n**REFERRALS:**\\n[List referrals]\\n\\n**CURRENT STATUS:**\\n[List status]\\n\\n**NEXT STEPS/PLAN:**\\n[List plan]\"\"\"}\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "def create_audience_determination_prompt(original_text: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are an expert medical text classifier. Read the following medical text and determine the appropriate audience for a summary letter based on these rules:\n",
    "- If the text describes a patient recovering, has a positive outlook, or an ongoing treatment plan, the audience is the **patient**.\n",
    "- If the text mentions \"died,\" \"passed away,\" \"deceased,\" or a fatal outcome like \"comfort care\" or \"hospice,\" the audience is the **patient's family**.\n",
    "Respond with a single word ONLY: **patient** or **family**.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f'**Medical Text:**\\n\"{original_text}\"'}\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "def create_explanation_prompt(annotated_text: str, audience: str, keysummary: str) -> str:\n",
    "    if audience == 'family':\n",
    "        audience_instruction = \"The determined audience for this letter is the **patient's family**. You must address them directly as 'you' and refer to the patient in the third person (e.g., 'your loved one,' 'he/she').\"\n",
    "    else:  # patient\n",
    "        audience_instruction = \"The determined audience for this letter is the **patient**. You must address them directly as 'you' throughout the entire letter.\"\n",
    "    \n",
    "    system_prompt = f\"\"\"### Persona\n",
    "You are an experienced and compassionate Oncologist and medical educator. Your primary role is to translate complex medical information into clear, 8th-grade level English. Your tone should be professional, empathetic, and honest.\n",
    "\n",
    "### Golden Rule: Radical Simplicity - Translate, Don't Transfer\n",
    "Your single most important task is to convert medical terminology into simple explanations. Do not just define a term; replace it with an easy-to-understand explanation.\n",
    "\n",
    "### Your Task:\n",
    "Write a complete letter explaining the information from the medical text. Imagine you are sitting with the recipient and explaining this to them in person.\n",
    "\n",
    "{audience_instruction}\n",
    "\n",
    "### Letter Structure and Flow:\n",
    "Organize your letter logically using the following question-based headers:\n",
    "* **Empathetic Opening:** Start with a warm and supportive salutation.\n",
    "* **Why did you come to the clinic?** (Explain the Chief Complaint)\n",
    "* **What was discussed?** (Explain the History of Present Illness)\n",
    "* **What did we find? (Assessment)** (Explain the diagnosis)\n",
    "* **What is the plan? (Plan)** (Explain the next steps)\n",
    "* **Closing with Support:** End by reinforcing your support.\n",
    "\n",
    "### STRICT NEGATIVE CONSTRAINTS:\n",
    "* Do not say anything not present in the medical note.\n",
    "* If cancer has spread (metastasis), DO NOT list the specific organs affected. Say \"the cancer has spread to other parts of the body.\"\n",
    "* Do not use fatalistic language. The focus MUST be on quality of life.\n",
    "\n",
    "### Strict Output Formatting:\n",
    "Provide ONLY the letter. Your output must start directly with \"Dear [Patient Name],\" and end with \"Sincerely,\\nYour Care Team at [Institution]\". Use the question-based headers exactly as specified.\"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"### Original Medical Text:\n",
    "\"{annotated_text}\"\n",
    "\n",
    "### Internal Fact-Checking Reference (Translate these facts, do not copy them):\n",
    "\"{keysummary}\"\n",
    "\n",
    "Please provide the patient-focused explanation now. Your output must start directly with the salutation.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "\n",
    "\n",
    "def create_cleaning_prompt(raw_response: str, audience: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates the correctly formatted prompt for Llama 3 to clean/revise a response.\n",
    "    \"\"\"\n",
    "    system_prompt = f\"\"\"### Persona\n",
    "You are an expert medical writer and editor. Your unique skill is communicating complex clinical information with absolute precision and clarity. Your primary directive is to preserve the original meaning without fail.\n",
    "\n",
    "### Target Audience:\n",
    "{audience}\n",
    "\n",
    "### Your Task\n",
    "Revise the provided medical text to improve its quality in the following areas:\n",
    "1.  **Clean Up Language:** Improve sentence structure and use professional language.\n",
    "2.  **Reduce Repetition:** Eliminate redundant words and phrases.\n",
    "3.  **Improve Flow:** Enhance the logical flow and transitions.\n",
    "4.  **Define Medical Terms (Conditional Task):**\n",
    "    * **IF the Target Audience is 'patient' or 'family'**: For any complex medical term, provide a simple explanation in parentheses after its first appearance. Example: \"tachycardia (a fast heart rate)\".\n",
    "    * **IF the Target Audience is a clinical professional**: DO NOT define standard medical terms.\n",
    "5.  **Remove formatting subtitles:** remove any section headers or subtitles from the text to make it read as a continuous letter.\n",
    "### The Golden Rule: Preserve Clinical Meaning at All Costs\n",
    "The revised text MUST be factually identical to the original.\n",
    "* **DO NOT** alter any clinical facts, diagnoses, measurements, or timelines.\n",
    "* **DO NOT** change the certainty of a statement.\n",
    "\n",
    "### Instructions for Output\n",
    "Provide your Revised Medical Text: The complete, revised version of the text.\"\"\"\n",
    "    user_prompt = f\"\"\"### Medical Text to Revise:\n",
    "{raw_response}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    \n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "AUDIENCE_DETERMINATION_CONFIG = {\n",
    "    \"max_new_tokens\": 5,\n",
    "    \"do_sample\": False,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"eos_token_id\": terminators, \n",
    "}\n",
    "\n",
    "KEY_SUMMARY_CONFIG = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"do_sample\": False, \n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"eos_token_id\": terminators, \n",
    "}\n",
    "\n",
    "EXPLANATION_GENERATION_CONFIG = {\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"temperature\": 0.3,\n",
    "    \"top_p\": 0.85,\n",
    "    \"repetition_penalty\": 1.15,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"eos_token_id\": terminators, \n",
    "    \"early_stopping\": True,\n",
    "}\n",
    "\n",
    "CLEANING_CONFIG = {\n",
    "    \"max_new_tokens\": 1500,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"eos_token_id\": terminators, \n",
    "    \"early_stopping\": True,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def run_model(prompt: str, model, tokenizer, generation_config: Dict) -> str:\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "        input_length = inputs[\"input_ids\"].shape[1]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                **generation_config\n",
    "            )\n",
    "        response_tokens = outputs[0][input_length:]\n",
    "        raw_output = tokenizer.decode(response_tokens, skip_special_tokens=True)\n",
    "        return raw_output\n",
    "        \n",
    "\n",
    "def parse_audience_response(raw_response: str) -> str:\n",
    "    cleaned_response = raw_response.lower().strip()\n",
    "    return \"family\" if \"family\" in cleaned_response else \"patient\"\n",
    "\n",
    "\n",
    "\n",
    "all_results = {}\n",
    "LINE_WIDTH = 100 \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['note_text'] \n",
    "    \n",
    "    print(f\"\\nProcessing row {index + 1}/{len(df)}...\")\n",
    "    \n",
    "    # --- Step 1: Determine Audience ---\n",
    "    audience_prompt = create_audience_determination_prompt(text)\n",
    "    raw_audience_output = run_model(audience_prompt, model, tokenizer, AUDIENCE_DETERMINATION_CONFIG)\n",
    "    audience = parse_audience_response(raw_audience_output)\n",
    "    \n",
    "    # --- Step 2: Annotate Text (Non-LLM step) ---\n",
    "    annotated_text = create_annotated_text(text, meddict)\n",
    "    \n",
    "    # --- Step 3: Extract Key Summary ---\n",
    "    summary_prompt = create_key_summary_prompt(text)\n",
    "    keysummary = run_model(summary_prompt, model, tokenizer, KEY_SUMMARY_CONFIG)\n",
    "    \n",
    "    # --- Step 4: Generate Initial Explanation ---\n",
    "    explanation_prompt = create_explanation_prompt(annotated_text, audience, keysummary)\n",
    "    explanation = run_model(explanation_prompt, model, tokenizer, EXPLANATION_GENERATION_CONFIG)\n",
    "\n",
    "    # --- Step 5: Clean and Finalize the Explanation ---\n",
    "    cleaning_prompt = create_cleaning_prompt(explanation, audience)\n",
    "    final_result = run_model(cleaning_prompt, model, tokenizer, CLEANING_CONFIG)\n",
    "    \n",
    "    # --- Store and Print Results ---\n",
    "    row_result = {\n",
    "        'original_text': text,\n",
    "        'determined_audience': audience,\n",
    "        'annotated_text': annotated_text,\n",
    "        'keysummary': keysummary,\n",
    "        'raw_explanation': explanation,\n",
    "        'final_letter': final_result\n",
    "    }\n",
    "    \n",
    "    all_results[index]=(row_result)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RESULTS FOR ROW {index + 1}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for col in ['keysummary', 'raw_explanation', 'final_letter']:\n",
    "        print(f\"\\n--- Column: {col} ---\")\n",
    "        original_text = row_result[col]\n",
    "        wrapped_text = textwrap.fill(original_text, width=LINE_WIDTH)\n",
    "        print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5b8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to 'output/output_3.json'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save to CSV\n",
    "base_filename = 'output/output'\n",
    "extension = '.json'\n",
    "output_filename = base_filename + extension\n",
    "counter = 1\n",
    "\n",
    "while os.path.exists(output_filename):\n",
    "    output_filename = f\"{base_filename}_{counter}{extension}\"\n",
    "    counter += 1\n",
    "\n",
    "results_df.to_json(output_filename, orient='index', indent=2)\n",
    "\n",
    "# Read back\n",
    "# df = pd.read_json(output_filename, orient='index')\n",
    "\n",
    "print(f\"DataFrame saved to '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1773b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
