{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503c81c2-012a-4e15-a255-a4a3e4c576d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece protobuf datasets transformers trl textstat peft bitsandbytes --quiet\n",
    "!pip install -U bitsandbytes accelerate --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c967d-ea35-4d4e-8ddc-f39328032b1a",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3b7919-277b-47b9-95b9-eab518373862",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-party data and ML libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Hugging Face ecosystem\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "# Fine-tuning and optimization\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Text analysis and readability metrics\n",
    "from textstat import (\n",
    "    flesch_kincaid_grade, \n",
    "    flesch_reading_ease,\n",
    "    smog_index, \n",
    "    gunning_fog, \n",
    "    dale_chall_readability_score,\n",
    "    text_standard, \n",
    "    syllable_count\n",
    ")\n",
    "\n",
    "# Optional: Uncomment if needed\n",
    "from huggingface_hub import login\n",
    "login(token=\"\")  # Move token to environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd4555-473d-48cd-bc86-60a4c41da0a8",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74a59c-b625-4944-8a79-aea69bc6cd8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d748507e40434b34a6015a3779f229ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2453d504ae404fb10ae456a097ce2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa239beda41f40998f8ab9c785e63e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca163550bff54dcaa405b784a3feb4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0a08afd7dd422b811788a7de15580e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40af761759d4ea79fc47cb4a10e1d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003ee0a38fe543e9a9a08c6ceabf585b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3a209663af4838a21231e0c6027b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e4d94684dd47dc81d965bba714443e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f835a222c26a4f77b646ce0c0b99250a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25af58426ba94224b448118586a5d708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7932091a894f76982b87f12e765fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Configuration\n",
    "# model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "# Recommended upgrade - Llama 3.1 8B\n",
    "# model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Or try Mistral 7B\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "# Load model with quantization\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=device_map,\n",
    "#     quantization_config=bnb_config\n",
    "# )\n",
    "\n",
    "# full precision\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map,\n",
    "    torch_dtype=torch.float16  # Use half precision instead\n",
    ")\n",
    "\n",
    "# # 8 precision\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=device_map,\n",
    "#     load_in_8bit=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1c388-57f9-41b0-87d1-25a9ad884430",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6281f4-7ebb-48fd-a08b-4271349ededf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_readability_scores(text, term=None):\n",
    "    \"\"\"Calculate readability scores for a piece of text, optionally removing a term\"\"\"\n",
    "    scoring_text = text\n",
    "    \n",
    "    # Remove the term and its variations before scoring if provided\n",
    "    if term:\n",
    "        # Create variations of the term to remove (capitalized, lowercase)\n",
    "        term_variations = [term, term.lower(), term.capitalize()]\n",
    "        \n",
    "        for variation in term_variations:\n",
    "            scoring_text = scoring_text.replace(variation, \"\")\n",
    "        \n",
    "        # Clean up any double spaces created\n",
    "        scoring_text = \" \".join(scoring_text.split())\n",
    "    \n",
    "    fk_grade = flesch_kincaid_grade(scoring_text)\n",
    "    readability = flesch_reading_ease(scoring_text)\n",
    "    return {\n",
    "        \"fk_grade\": fk_grade,\n",
    "        \"readability\": readability,\n",
    "    }\n",
    "def txt_to_dict(file_path):\n",
    "    data_dict = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(0, len(lines) - 1, 2):\n",
    "            key = lines[i].strip()    # Odd line are key\n",
    "            value = lines[i + 1].strip()  # Even line are value\n",
    "            data_dict[key] = value\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "txt_file_path = 'formaldef.txt' \n",
    "formaldic = txt_to_dict(txt_file_path)\n",
    "len(formaldic)\n",
    "\n",
    "meddict={}\n",
    "for k,v in formaldic.items():\n",
    "    meddict[k.split('Listen to pronunciation')[0].split('(')[0]]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fbc3ba8-e388-43a3-b0d2-347f71c2b862",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!\n"
     ]
    }
   ],
   "source": [
    "print('ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c6d4475-de2d-4b19-b300-0db9acd700c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "file_name = \"Discharge Sum_Sample_MIMIC.csv\"\n",
    "df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34119805-0771-45a9-ac20-79e23affb9f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# promt, single term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7eb4e6f-2c30-4f9d-a79e-11efada26fe7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Medical Term Explanation System\n",
    "# Converts complex medical terminology into simple, accessible language\n",
    "\n",
    "# Improved prompt template with clearer instruction formatting\n",
    "explanation_template = \"\"\"<s>[INST] You are a medical educator who explains complex medical terms in simple language.\n",
    "\n",
    "Medical term: {term}\n",
    "Medical definition: {definition}\n",
    "\n",
    "Instructions:\n",
    "1. Explain this term using everyday language that anyone can understand\n",
    "2. Avoid all medical jargon and technical terms\n",
    "3. Write at a middle school reading level (grades 7-8)\n",
    "4. Keep it concise - maximum 3 short sentences\n",
    "5. Be medically accurate but accessible\n",
    "6. Start immediately with the explanation (no introductory phrases)\n",
    "\n",
    "[/INST]\"\"\"\n",
    "\n",
    "# Optimized generation parameters for clear, concise explanations\n",
    "generation_config = {\n",
    "    \"max_new_tokens\": 150,           # Reduced for concise responses\n",
    "    \"temperature\": 0.3,              # Lower for more consistent, focused output\n",
    "    \"top_p\": 0.85,                   # Slightly reduced for better coherence\n",
    "    \"repetition_penalty\": 1.15,      # Higher to avoid repetition\n",
    "    \"do_sample\": True,               # Enable sampling for natural language\n",
    "    \"pad_token_id\": tokenizer.eos_token_id  # Handle padding properly\n",
    "}\n",
    "\n",
    "def find_term_in_dict(term):\n",
    "    \"\"\"\n",
    "    Find a term in the medical dictionary using various case formats.\n",
    "    \n",
    "    Args:\n",
    "        term (str): The term to search for\n",
    "    \n",
    "    Returns:\n",
    "        str or None: The definition if found, None otherwise\n",
    "    \"\"\"\n",
    "    # Try different case formats\n",
    "    search_formats = [\n",
    "        term,                           # Original case\n",
    "        term.lower(),                   # lowercase\n",
    "        term.upper(),                   # UPPERCASE  \n",
    "        term.title(),                   # Title Case\n",
    "        term.capitalize(),              # Capitalized\n",
    "    ]\n",
    "    \n",
    "    for search_term in search_formats:\n",
    "        if search_term in meddict:\n",
    "            return meddict[search_term]\n",
    "    \n",
    "    # If still not found, try partial matching for terms with special characters\n",
    "    for key in meddict.keys():\n",
    "        if key.lower() == term.lower():\n",
    "            return meddict[key]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def explain_medical_term(term, definition=None):\n",
    "    \"\"\"\n",
    "    Generate a simple explanation for a medical term.\n",
    "    \n",
    "    Args:\n",
    "        term (str): The medical term to explain\n",
    "        definition (str, optional): Medical definition. If None, looks up in meddict\n",
    "    \n",
    "    Returns:\n",
    "        str: Simple explanation suitable for general audience\n",
    "    \"\"\"\n",
    "    # Look up definition if not provided\n",
    "    if definition is None:\n",
    "        definition = find_term_in_dict(term)\n",
    "        if definition is None:\n",
    "            return f\"‚ùå Term '{term}' not found in medical dictionary.\"\n",
    "    \n",
    "    # Create formatted prompt\n",
    "    prompt = explanation_template.format(term=term, definition=definition)\n",
    "    \n",
    "    try:\n",
    "        # Tokenize input\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "        \n",
    "        # Generate explanation\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                **generation_config\n",
    "            )\n",
    "        \n",
    "        # Decode and clean response\n",
    "        full_response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "        \n",
    "        # Extract just the explanation part\n",
    "        explanation = extract_explanation(full_response, prompt)\n",
    "        \n",
    "        return explanation.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error generating explanation: {str(e)}\"\n",
    "\n",
    "def extract_explanation(full_response, prompt):\n",
    "    \"\"\"\n",
    "    Extract the model's explanation from the full response.\n",
    "    \n",
    "    Args:\n",
    "        full_response (str): Complete model output\n",
    "        prompt (str): Original prompt\n",
    "    \n",
    "    Returns:\n",
    "        str: Cleaned explanation text\n",
    "    \"\"\"\n",
    "    explanation = full_response\n",
    "    \n",
    "    # Remove the prompt part\n",
    "    if \"[/INST]\" in explanation:\n",
    "        explanation = explanation.split(\"[/INST]\", 1)[1]\n",
    "    else:\n",
    "        # Fallback: remove original prompt\n",
    "        explanation = explanation.replace(prompt, \"\")\n",
    "    \n",
    "    # Clean up special tokens and artifacts\n",
    "    cleanup_patterns = [\n",
    "        \"</s>\",\n",
    "        \"<s>\",\n",
    "        \"[INST]\",\n",
    "        \"[/INST]\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in cleanup_patterns:\n",
    "        explanation = explanation.replace(pattern, \"\")\n",
    "    \n",
    "    # Remove common response artifacts\n",
    "    artifacts = [\n",
    "        \"Here's the explanation:\",\n",
    "        \"Let me explain:\",\n",
    "        \"The explanation is:\",\n",
    "        \"Okay!\",\n",
    "        \"Sure!\",\n",
    "        \"Here's my explanation:\"\n",
    "    ]\n",
    "    \n",
    "    for artifact in artifacts:\n",
    "        if explanation.lower().startswith(artifact.lower()):\n",
    "            explanation = explanation[len(artifact):].strip()\n",
    "    \n",
    "    return explanation\n",
    "\n",
    "def demo_explanations(num_terms=5):\n",
    "    \"\"\"\n",
    "    Demonstrate the explanation system with sample medical terms.\n",
    "    \n",
    "    Args:\n",
    "        num_terms (int): Number of terms to demonstrate\n",
    "    \"\"\"\n",
    "    print(\"üè• Medical Term Explanation Demo\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get sample terms that actually exist\n",
    "    available_terms = []\n",
    "    for term in list(meddict.keys())[:20]:  # Check more terms to find valid ones\n",
    "        if find_term_in_dict(term) is not None:\n",
    "            available_terms.append(term)\n",
    "        if len(available_terms) >= num_terms:\n",
    "            break\n",
    "    \n",
    "    if len(available_terms) == 0:\n",
    "        print(\"‚ùå No valid terms found in dictionary\")\n",
    "        return\n",
    "    \n",
    "    for i, term in enumerate(available_terms[:num_terms], 1):\n",
    "        print(f\"\\n{i}. Term: {term.title()}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        explanation = explain_medical_term(term)\n",
    "        print(f\"{explanation}\")\n",
    "        \n",
    "        if i < len(available_terms[:num_terms]):\n",
    "            print(\"=\" * 50)\n",
    "\n",
    "# Advanced function with readability scoring\n",
    "def explain_with_metrics(term, definition=None):\n",
    "    \"\"\"\n",
    "    Generate explanation with readability metrics.\n",
    "    \n",
    "    Args:\n",
    "        term (str): Medical term\n",
    "        definition (str, optional): Medical definition\n",
    "    \n",
    "    Returns:\n",
    "        dict: Explanation with readability scores\n",
    "    \"\"\"\n",
    "    explanation = explain_medical_term(term, definition)\n",
    "    \n",
    "    if explanation.startswith(\"‚ùå\"):\n",
    "        return {\"explanation\": explanation, \"metrics\": None}\n",
    "    \n",
    "    # Calculate readability metrics\n",
    "    try:\n",
    "        metrics = {\n",
    "            \"flesch_reading_ease\": flesch_reading_ease(explanation),\n",
    "            \"flesch_kincaid_grade\": flesch_kincaid_grade(explanation),\n",
    "            \"word_count\": len(explanation.split()),\n",
    "            \"sentence_count\": explanation.count('.') + explanation.count('!') + explanation.count('?')\n",
    "        }\n",
    "        \n",
    "        # Determine reading level\n",
    "        grade_level = metrics[\"flesch_kincaid_grade\"]\n",
    "        if grade_level <= 8:\n",
    "            level_assessment = \"‚úÖ Appropriate (Middle school level)\"\n",
    "        elif grade_level <= 10:\n",
    "            level_assessment = \"‚ö†Ô∏è Slightly high (Early high school)\"\n",
    "        else:\n",
    "            level_assessment = \"‚ùå Too complex (Advanced high school+)\"\n",
    "            \n",
    "        metrics[\"level_assessment\"] = level_assessment\n",
    "        \n",
    "    except Exception as e:\n",
    "        metrics = {\"error\": f\"Could not calculate metrics: {str(e)}\"}\n",
    "    \n",
    "    return {\n",
    "        \"explanation\": explanation,\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "# Run demonstration\n",
    "def debug_dictionary(sample_size=10):\n",
    "    \"\"\"\n",
    "    Debug function to examine the structure of meddict.\n",
    "    \n",
    "    Args:\n",
    "        sample_size (int): Number of sample keys to examine\n",
    "    \"\"\"\n",
    "    print(\"üîç Medical Dictionary Debug Info\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    keys = list(meddict.keys())\n",
    "    print(f\"Total terms in dictionary: {len(keys)}\")\n",
    "    print(f\"\\nFirst {sample_size} keys:\")\n",
    "    \n",
    "    for i, key in enumerate(keys[:sample_size]):\n",
    "        print(f\"{i+1:2d}. '{key}' -> {len(meddict[key])} chars\")\n",
    "    \n",
    "    # Check for specific problematic terms\n",
    "    problematic_terms = ['A33', 'A6', 'AAP', 'AAT deficiency', 'abarelix']\n",
    "    print(f\"\\nChecking problematic terms:\")\n",
    "    \n",
    "    for term in problematic_terms:\n",
    "        result = find_term_in_dict(term)\n",
    "        if result:\n",
    "            print(f\"‚úÖ Found '{term}': {result[:50]}...\")\n",
    "        else:\n",
    "            print(f\"‚ùå Not found: '{term}'\")\n",
    "            # Look for similar keys\n",
    "            similar = [k for k in keys if term.lower() in k.lower()][:3]\n",
    "            if similar:\n",
    "                print(f\"   Similar keys: {similar}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    # demo_explanations(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eefaba-320e-4774-afc9-48e7af43786c",
   "metadata": {},
   "source": [
    "chatgpt baseline.\n",
    "\n",
    "A33\n",
    "A33 is a protein found on the surface of certain cells in the intestines and some types of cancer. Doctors can target it to help find or treat these cancers. It acts like a flag that helps identify where the cancer cells are.\n",
    "\n",
    "A6\n",
    "A6 is a small part of a protein that can help stop cancer from spreading. It works by blocking signals that tell cancer cells to move. Scientists are studying it to see if it can be used as a treatment.\n",
    "\n",
    "AAP\n",
    "AAP stands for American Academy of Pediatrics. It‚Äôs a group of doctors who focus on keeping children healthy. They create guidelines to help parents and doctors care for kids.\n",
    "\n",
    "AAT deficiency\n",
    "AAT deficiency is a condition where the body doesn't make enough of a protein that protects the lungs. Without it, the lungs can get damaged more easily, especially by smoking or pollution. It can also affect the liver in some people.\n",
    "\n",
    "Abarelix\n",
    "Abarelix is a medicine that lowers certain hormones in the body. It is mainly used to treat prostate cancer by stopping the cancer from growing. It works by blocking signals from the brain that tell the body to make these hormones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a445b4-0a2b-45d1-9892-42f775ef20b8",
   "metadata": {},
   "source": [
    "# prompt, paragraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c2222c0-0f85-4ea9-abb3-283edb543491",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\"Admission Date:  [**2118-6-2**]       Discharge Date:  [**2118-6-14**]\n",
    "\n",
    "Date of Birth:                    Sex:  F\n",
    "\n",
    "Service:  MICU and then to [**Doctor Last Name **] Medicine\n",
    "\n",
    "HISTORY OF PRESENT ILLNESS:  This is an 81-year-old female\n",
    "with a history of emphysema (not on home O2), who presents\n",
    "with three days of shortness of breath thought by her primary\n",
    "care doctor to be a COPD flare.  Two days prior to admission,\n",
    "she was started on a prednisone taper and one day prior to\n",
    "admission she required oxygen at home in order to maintain\n",
    "oxygen saturation greater than 90%.  She has also been on\n",
    "levofloxacin and nebulizers, and was not getting better, and\n",
    "presented to the [**Hospital1 18**] Emergency Room.\n",
    "\n",
    "In the [**Hospital3 **] Emergency Room, her oxygen saturation was\n",
    "100% on CPAP.  She was not able to be weaned off of this\n",
    "despite nebulizer treatment and Solu-Medrol 125 mg IV x2.\n",
    "\n",
    "Review of systems is negative for the following:  Fevers,\n",
    "chills, nausea, vomiting, night sweats, change in weight,\n",
    "gastrointestinal complaints, neurologic changes, rashes,\n",
    "palpitations, orthopnea.  Is positive for the following:\n",
    "Chest pressure occasionally with shortness of breath with\n",
    "exertion, some shortness of breath that is positionally\n",
    "related, but is improved with nebulizer treatment.\n",
    "\n",
    "PAST MEDICAL HISTORY:\n",
    "1. COPD.  Last pulmonary function tests in [**2117-11-3**]\n",
    "demonstrated a FVC of 52% of predicted, a FEV1 of 54% of\n",
    "predicted, a MMF of 23% of predicted, and a FEV1:FVC ratio of\n",
    "67% of predicted, that does not improve with bronchodilator\n",
    "treatment.  The FVC, however, does significantly improve with\n",
    "bronchodilator treatment consistent with her known reversible\n",
    "air flow obstruction in addition to an underlying restrictive\n",
    "ventilatory defect.  The patient has never been on home\n",
    "oxygen prior to this recent episode.  She has never been on\n",
    "steroid taper or been intubated in the past.\n",
    "2. Lacunar CVA.  MRI of the head in [**2114-11-4**]\n",
    "demonstrates \"mild degree of multiple small foci of high T2\n",
    "signal within the white matter of both cerebral hemispheres\n",
    "as well as the pons, in the latter region predominantly to\n",
    "the right of midline.  The abnormalities, while nonspecific\n",
    "in etiology, are most likely secondary to chronic\n",
    "microvascular infarction.  There is no mass, lesion, shift of\n",
    "the normal midline strictures or hydrocephalus.  The major\n",
    "vascular flow patterns are preserved.  There is moderate\n",
    "right maxillary, moderate bilateral ethmoid, mild left\n",
    "maxillary, minimal right sphenoid, and frontal sinus mucosal\n",
    "thickening.  These abnormalities could represent an allergic\n",
    "or some other type of inflammatory process.  Additionally\n",
    "noted is a moderately enlarged subtotally empty sella\n",
    "turcica\".\n",
    "3. Angina:  Most recent stress test was in [**2118-1-3**]\n",
    "going for four minutes with a rate pressure product of\n",
    "10,000, 64% of maximum predicted heart rate without evidence\n",
    "of ischemic EKG changes or symptoms.  The imaging portion of\n",
    "the study demonstrated no evidence of myocardial ischemia and\n",
    "a calculated ejection fraction of 84%.  The patient denies\n",
    "angina at rest and gets angina with walking a few blocks.\n",
    "Are alleviated by sublingual nitroglycerin.\n",
    "4. Hypothyroidism on Synthroid.\n",
    "5. Depression on Lexapro.\n",
    "6. Motor vehicle accident with head injury approximately 10\n",
    "years ago.\n",
    "\n",
    "MEDICATIONS ON ADMISSION:\n",
    "1. Hydrochlorothiazide 25 q.d.\n",
    "2. Prednisone 60 mg, 50 mg, 40 mg, 20 mg.\n",
    "3. Levofloxacin 500 mg q.d.\n",
    "4. Imdur 60 mg q.d.\n",
    "5. Synthroid 75 mcg q.d.\n",
    "6. Pulmicort nebulizer b.i.d.\n",
    "7. Albuterol nebulizer q.4. prn.\n",
    "8. Lexapro 10 mg q.d.\n",
    "9. Protonix 40 mg q.d.\n",
    "10. Aspirin 81 mg q.d.\n",
    "\n",
    "ALLERGIES:  Norvasc leads to lightheadedness and headache.\n",
    "\n",
    "FAMILY HISTORY:  Noncontributory.\n",
    "\n",
    "SOCIAL HISTORY:  Lives with her husband, Dr. [**Known lastname 1809**] an\n",
    "eminent Pediatric Neurologist at [**Hospital3 1810**].  The\n",
    "patient is a prior smoker, but has not smoked in over 10\n",
    "years.  She has no known alcohol use and she is a full code.\n",
    "\n",
    "PHYSICAL EXAM AT TIME OF ADMISSION:  Blood pressure 142/76,\n",
    "heart rate 100 and regular, respirations at 17-21, and 97%\n",
    "axillary temperature.  She was saturating at 100% on CPAP\n",
    "with dry mucous membranes.  An elderly female in no apparent\n",
    "distress.  Pupils are equal, round, and reactive to light and\n",
    "accommodation.  Extraocular movements are intact.  Oropharynx\n",
    "difficult to assess due to CPAP machine.  No evidence of\n",
    "jugular venous pressure, however, the strap from the CPAP\n",
    "machine obscures the neck exam.  Cranial nerves II through\n",
    "XII are grossly intact.  Neck is supple without\n",
    "lymphadenopathy.  Heart exam:  Tachycardic, regular, obscured\n",
    "by loud bilateral wheezing with increase in the expiratory\n",
    "phase as well as profuse scattered rhonchi throughout the\n",
    "lung fields.  Positive bowel sounds, soft, nontender,\n",
    "nondistended, obese, no masses.  Mild edema of the lower\n",
    "extremities without clubbing or cyanosis, no rashes.  There\n",
    "is a right hand hematoma.  Strength is assessed as [**5-9**] in the\n",
    "lower extremities, [**5-9**] in the upper extremities with a normal\n",
    "mental status and cognition.\n",
    "\n",
    "LABORATORY STUDIES:  White count 19, hematocrit 41, platelets\n",
    "300.  Chem-7:  127, 3.6, 88, 29, 17, 0.6, 143.  Troponin was\n",
    "negative.  CKs were negative times three.  Initial blood gas\n",
    "showed a pH of 7.4, pO2 of 66, pCO2 of 54.\n",
    "\n",
    "Chest x-ray demonstrates a moderate sized hiatal hernia,\n",
    "segmental atelectasis, left lower lobe infiltrate versus\n",
    "segmental atelectasis.\n",
    "\n",
    "EKG shows normal sinus rhythm at 113 beats per minute, normal\n",
    "axis, no evidence of ST-T wave changes.\n",
    "\n",
    "BRIEF SUMMARY OF HOSPITAL COURSE:\n",
    "1. COPD/dyspnea/pneumonia:  The patient was initially placed\n",
    "on an aggressive steroid taper and admitted to the Medical\n",
    "Intensive Care Unit due to her difficulty with oxygenation\n",
    "despite CPAP machine.  She was also given nebulizer\n",
    "treatments q.4h. as well as chest PT.  The nebulizers were\n",
    "increased to q.1h. due to the fact that she continued to have\n",
    "labored breathing.\n",
    "\n",
    "Due to persistent respiratory failure and labored breathing,\n",
    "the patient was intubated on [**2118-6-7**] in order to improve\n",
    "oxygenation, ventilation, and ability to suction.  A\n",
    "bronchoscopy was performed on [**2118-6-7**], which demonstrated\n",
    "marked narrowing of the airways with expiration consistent\n",
    "with tracheomalacia.\n",
    "\n",
    "On [**2118-6-9**], two silicone stents were placed, one in the left\n",
    "main stem (12 x 25 and one in the trachea 16 x 40) by Dr.\n",
    "[**First Name (STitle) **] [**Name (STitle) **] under rigid bronchoscopy with general anesthesia.\n",
    "\n",
    "On [**2118-6-11**], the patient was extubated to a cool mist shovel\n",
    "mask and her oxygen was titrated down to 2 liters nasal\n",
    "cannula at which time she was transferred to the medical\n",
    "floor.  On the medical floor, the steroids were weaned to off\n",
    "on [**2118-6-14**], and the patient was saturating at 97% on 2\n",
    "liters, 92% on room air.\n",
    "\n",
    "On [**2118-6-14**], the patient was seen again by the Interventional\n",
    "Pulmonology service, who agreed that she looked much improved\n",
    "and recommended that she go to pulmonary rehabilitation with\n",
    "followup within six weeks' time status post placement of\n",
    "stents in respiratory failure.\n",
    "\n",
    "2. Cardiovascular:  The patient was ruled out for a MI.  She\n",
    "did have another episode on the medical floor of chest pain,\n",
    "which showed no evidence of EKG changes and negative\n",
    "troponin, negative CKs x3.  She was continued on aspirin,\n",
    "Imdur, and diltiazem for rate control per her outpatient\n",
    "regimen.\n",
    "\n",
    "3. Hypertension:  She was maintained on diltiazem and\n",
    "hydrochlorothiazide with adequate blood pressure control and\n",
    "normalization of electrolytes.\n",
    "\n",
    "4. Hematuria:  The patient had intermittent hematuria likely\n",
    "secondary to Foley placement.  The Foley catheter was\n",
    "discontinued on [**2118-6-14**].  She had serial urinalyses, which\n",
    "were all negative for signs of infection.\n",
    "\n",
    "5. Hyperglycemia:  Patient was placed on insulin-sliding\n",
    "scale due to hyperglycemia, which was steroid induced.  This\n",
    "worked quite well and her glucose came back to normal levels\n",
    "once the steroids were tapered to off.\n",
    "\n",
    "6. Leukocytosis:  Patient did have a profound leukocytosis of\n",
    "20 to 22 during much of her hospital course.  As the steroids\n",
    "were tapered to off, her white blood cell count on [**2118-6-14**]\n",
    "was 15,000.  It was felt that the leukocytosis was secondary\n",
    "to both steroids as well as question of a left lower lobe\n",
    "pneumonia.\n",
    "\n",
    "7. For the left lower lobe pneumonia, the patient had\n",
    "initially received a course of levofloxacin 500 p.o. q.d.\n",
    "from [**2118-6-4**] to [**2118-6-10**].  This was restarted on [**2118-6-12**]\n",
    "for an additional seven day course given the fact that she\n",
    "still had the leukocytosis and still had marked rales at the\n",
    "left lower lobe.\n",
    "\n",
    "8. Hypothyroidism:  The patient was continued on outpatient\n",
    "medical regimen.\n",
    "\n",
    "9. Depression:  The patient was continued on Lexapro per\n",
    "outpatient regimen.  It is recommended that she follow up\n",
    "with a therapist as an outpatient due to the fact that she\n",
    "did have a blunted affect throughout much of the hospital\n",
    "course, and did appear clinically to be depressed.\n",
    "\n",
    "10. Prophylaxis:  She was maintained on proton-pump inhibitor\n",
    "with subQ Heparin.\n",
    "\n",
    "11. Sore throat:  The patient did have a sore throat for much\n",
    "of the hospital course post extubation.  This was treated\n",
    "with Cepacol lozenges as well as KBL liquid (a solution\n",
    "containing Kaopectate, Bismuth, and lidocaine) at bedtime.\n",
    "\n",
    "12. Communication/code status:  The patient was full code\n",
    "throughout her hospital course, and communication was\n",
    "maintained with the patient and her husband.\n",
    "\n",
    "13. Muscle weakness:  The patient did have profound muscle\n",
    "weakness and was evaluated by Physical Therapy, and was found\n",
    "to have impaired functional mobility, impaired\n",
    "musculoskeletal performance, impaired gas exchange, impaired\n",
    "endurance, impaired ventilation, and needed help with supine\n",
    "to sit.  However, she was able to tolerate sitting in a chair\n",
    "for approximately one hour.\n",
    "\n",
    "On motor exam, her flexors and extensors of the lower\n",
    "extremities were [**4-8**] at the knee, [**4-8**] at the ankle, [**4-8**] at\n",
    "the elbows, and [**4-8**] hips.  It was felt that this weakness was\n",
    "most likely due to a combination of steroid myopathy as well\n",
    "as muscle atrophy secondary to deconditioning after a\n",
    "prolonged hospital course.\n",
    "\n",
    "14. Speech/swallow:  The patient had a Speech and Swallow\n",
    "evaluation showing no evidence of dysphagia, no evidence of\n",
    "vocal cord damage status post tracheal stent placement.\n",
    "\n",
    "DISCHARGE CONDITION:  The patient was able to oxygenate on\n",
    "room air at 93% at the time of discharge.  She was profoundly\n",
    "weak, but was no longer tachycardic and had a normal blood\n",
    "pressure.  Her respirations were much improved albeit with\n",
    "transmitted upper airway sounds.\n",
    "\n",
    "DISCHARGE STATUS:  The patient will be discharged to [**Hospital1 **]\n",
    "for both pulmonary and physical rehabilitation.\n",
    "\n",
    "DISCHARGE MEDICATIONS:\n",
    "1. Levothyroxine 75 mcg p.o. q.d.\n",
    "2. Citalopram 10 mg p.o. q.d.\n",
    "3. Aspirin 81 mg p.o. q.d.\n",
    "4. Fluticasone 110 mcg two puffs inhaled b.i.d.\n",
    "5. Salmeterol Diskus one inhalation b.i.d.\n",
    "6. Acetaminophen 325-650 mg p.o. q.4-6h. prn.\n",
    "7. Ipratropium bromide MDI two puffs inhaled q.2h. prn.\n",
    "8. Albuterol 1-2 puffs inhaled q.2h. prn.\n",
    "9. Zolpidem tartrate 5 mg p.o. q.h.s. prn.\n",
    "10. Isosorbide dinitrate 10 mg p.o. t.i.d.\n",
    "11. Diltiazem 60 mg p.o. q.i.d.\n",
    "12. Pantoprazole 40 mg p.o. q.24h.\n",
    "13. Trazodone 25 mg p.o. q.h.s. prn.\n",
    "14. SubQ Heparin 5000 units subcutaneous b.i.d. until such\n",
    "time that the patient is able to get out of bed twice a day.\n",
    "15. Cepacol lozenges q.2h. prn.\n",
    "16. Levofloxacin 500 mg p.o. q.d. for a seven day course to\n",
    "be completed on [**2118-6-21**].\n",
    "17. Kaopectate/Benadryl/lidocaine 5 mL p.o. b.i.d. prn, not\n",
    "to be given around mealtimes for concern of dysphagia induced\n",
    "by lidocaine.\n",
    "18. Lorazepam 0.5-2 mg IV q.6h. prn.\n",
    "\n",
    "FOLLOW-UP PLANS:  The patient is recommended to followup with\n",
    "Dr. [**First Name4 (NamePattern1) **] [**Last Name (NamePattern1) 1407**], [**Telephone/Fax (1) 1408**] within two weeks of leaving\n",
    "of the hospital.  She is also recommended to followup with\n",
    "the Interventional Pulmonary service for followup status post\n",
    "stent placement.  She is also recommended to followup with a\n",
    "neurologist if her muscle weakness does not improve within\n",
    "one week on physical therapy with concern for steroid-induced\n",
    "myopathy.\n",
    "\n",
    "FINAL DIAGNOSES:\n",
    "1. Tracheomalacia status post tracheal and left main stem\n",
    "bronchial stent placement.\n",
    "2. Hypertension.\n",
    "3. Hypothyroidism.\n",
    "4. Restrictive lung defect.\n",
    "5. Depression.\n",
    "\n",
    "\n",
    "                     DR.[**Last Name (STitle) **],[**First Name3 (LF) **] 12-207\n",
    "\n",
    "\n",
    "Dictated By:[**Last Name (NamePattern1) 1811**]\n",
    "MEDQUIST36\n",
    "\n",
    "D:  [**2118-6-14**]  11:30\n",
    "T:  [**2118-6-14**]  11:33\n",
    "JOB#:  [**Job Number 1812**]\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5214f6-5ac9-4799-bc18-cfeb96d6deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß MODULAR MEDICAL EXPLANATION SYSTEM\n",
      "============================================================\n",
      "üìã Available Step Combinations:\n",
      "\n",
      "1Ô∏è‚É£ FULL PIPELINE - All steps (default)\n",
      "   result = explainer.explain_medical_text(text)\n",
      "   result = explainer.explain_medical_text(text, steps=['extract', 'generate', 'clean'])\n",
      "\n",
      "2Ô∏è‚É£ SKIP CLEANING - Raw model output\n",
      "   result = explainer.explain_medical_text(text, steps=['extract', 'generate'])\n",
      "\n",
      "3Ô∏è‚É£ ONLY EXTRACT - Just find medical terms\n",
      "   result = explainer.explain_medical_text(text, steps=['extract'])\n",
      "\n",
      "4Ô∏è‚É£ GENERATE ONLY - Skip extraction\n",
      "   result = explainer.explain_medical_text(text, steps=['generate'])\n",
      "\n",
      "5Ô∏è‚É£ CUSTOM PIPELINE - Generate then clean\n",
      "   result = explainer.explain_medical_text(text, steps=['generate', 'clean'])\n",
      "\n",
      "‚úÖ BENEFITS:\n",
      "   ‚Ä¢ Run only the steps you need\n",
      "   ‚Ä¢ Debug individual steps\n",
      "   ‚Ä¢ Compare raw vs cleaned outputs\n",
      "   ‚Ä¢ Skip expensive cleaning for quick tests\n"
     ]
    }
   ],
   "source": [
    "# Modular Medical Text Explanation System\n",
    "# Returns clean dict with configurable steps: extract, generate, clean\n",
    "\n",
    "import re\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "class MedicalTextExplainer:\n",
    "    def __init__(self, model, tokenizer, meddict):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.meddict = meddict\n",
    "        \n",
    "        # Improved generation config for better outputs\n",
    "        self.generation_config = {\n",
    "            \"max_new_tokens\": 999,              # Increased for fuller explanations\n",
    "            \"temperature\": 0.3,\n",
    "            \"top_p\": 0.85,\n",
    "            \"repetition_penalty\": 1.15,\n",
    "            \"do_sample\": True,\n",
    "            \"pad_token_id\": tokenizer.eos_token_id,\n",
    "            \"eos_token_id\": tokenizer.eos_token_id,  # Ensure proper stopping\n",
    "            \"early_stopping\": True,              # Stop when EOS token is generated\n",
    "        }\n",
    "        \n",
    "        # Define available steps\n",
    "        self.available_steps = ['extract', 'generate', 'clean']\n",
    "        self.step_functions = {\n",
    "            'extract': self._step_extract_terms,\n",
    "            'generate': self._step_generate_explanation,\n",
    "            'clean': self._step_clean_response\n",
    "        }\n",
    "    \n",
    "    def explain_medical_text(self, text, steps=['extract', 'generate', 'clean']):\n",
    "        \"\"\"\n",
    "        Modular main function that runs configurable steps.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input medical text\n",
    "            steps (list): List of steps to run. Options: ['extract', 'generate', 'clean']\n",
    "                         - 'extract': Extract medical terms from text\n",
    "                         - 'generate': Generate explanation from model  \n",
    "                         - 'clean': Clean the raw output\n",
    "        \n",
    "        Returns:\n",
    "            dict: Contains results from each step that was run\n",
    "        \"\"\"\n",
    "        \n",
    "        # Validate steps\n",
    "        invalid_steps = [step for step in steps if step not in self.available_steps]\n",
    "        if invalid_steps:\n",
    "            raise ValueError(f\"Invalid steps: {invalid_steps}. Available steps: {self.available_steps}\")\n",
    "        \n",
    "        # Initialize result with original text\n",
    "        result = {\n",
    "            'original_text': text,\n",
    "            'steps_run': steps.copy(),\n",
    "            'available_steps': self.available_steps.copy()\n",
    "        }\n",
    "        \n",
    "        # Run each step in sequence, passing result between steps\n",
    "        for step in steps:\n",
    "            print(f\"üîÑ Running step: {step}\")\n",
    "            result = self.step_functions[step](result)\n",
    "        \n",
    "        print(f\"‚úÖ Completed {len(steps)} steps: {steps}\")\n",
    "        return result\n",
    "    \n",
    "    def _step_extract_terms(self, result):\n",
    "        \"\"\"Step 1: Extract medical terms from text.\"\"\"\n",
    "        text = result['original_text']\n",
    "        found_terms = self.extract_medical_terms(text)\n",
    "        \n",
    "        result.update({\n",
    "            'found_terms': found_terms,\n",
    "            'terms_count': len(found_terms)\n",
    "        })\n",
    "        \n",
    "        print(f\"   üìã Found {len(found_terms)} medical terms\")\n",
    "        return result\n",
    "    \n",
    "    def _step_generate_explanation(self, result):\n",
    "        \"\"\"Step 2: Generate explanation using model.\"\"\"\n",
    "        text = result['original_text']\n",
    "        \n",
    "        # Use found terms if extract step was run, otherwise extract them now\n",
    "        if 'found_terms' in result:\n",
    "            found_terms = result['found_terms']\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  Terms not extracted yet, extracting now...\")\n",
    "            found_terms = self.extract_medical_terms(text)\n",
    "            result['found_terms'] = found_terms\n",
    "        \n",
    "        # Create prompt and generate\n",
    "        prompt = self.create_prompt(text, found_terms)\n",
    "        raw_output = self._generate_raw_response(prompt)\n",
    "        \n",
    "        result.update({\n",
    "            'prompt': prompt,\n",
    "            'raw_output': raw_output,\n",
    "            'prompt_length': len(prompt),\n",
    "            'raw_output_length': len(raw_output)\n",
    "        })\n",
    "        \n",
    "        print(f\"   ü§ñ Generated {len(raw_output)} character response\")\n",
    "        return result\n",
    "    \n",
    "    def _step_clean_response(self, result):\n",
    "        \"\"\"Step 3: Clean the raw model output.\"\"\"\n",
    "        \n",
    "        # Check if we have raw output to clean\n",
    "        if 'raw_output' not in result:\n",
    "            raise ValueError(\"No raw_output found. Must run 'generate' step before 'clean' step.\")\n",
    "        \n",
    "        raw_output = result['raw_output']\n",
    "        original_prompt = result.get('prompt', '')\n",
    "        \n",
    "        # Clean the response\n",
    "        cleaned_output = self.model_clean_response(raw_output, original_prompt)\n",
    "        cleaning_prompt = self.create_cleaning_prompt(raw_output, original_prompt)\n",
    "        \n",
    "        result.update({\n",
    "            'cleaning_prompt': cleaning_prompt,\n",
    "            'cleaned_output': cleaned_output,\n",
    "            'cleaned_length': len(cleaned_output)\n",
    "        })\n",
    "        \n",
    "        print(f\"   üßπ Cleaned to {len(cleaned_output)} characters\")\n",
    "        return result\n",
    "    \n",
    "    def extract_medical_terms(self, text):\n",
    "        \"\"\"\n",
    "        Enhanced medical term extraction to catch more terms from complex texts.\n",
    "        \"\"\"\n",
    "        found_terms = {}\n",
    "        \n",
    "        # Strategy 1: Single words (improved regex for medical terms)\n",
    "        words = re.findall(r'\\b[A-Za-z]+(?:[-\\'][A-Za-z]+)*\\b', text)\n",
    "        for word in words:\n",
    "            definition = self.find_term_in_dict(word)\n",
    "            if definition:\n",
    "                found_terms[word] = definition\n",
    "        \n",
    "        # Strategy 2: Multi-word terms (expanded range for complex medical phrases)\n",
    "        for n in range(2, 6):  # Increased from 5 to 6 for longer medical phrases\n",
    "            n_grams = self.get_n_grams(text, n)\n",
    "            for phrase in n_grams:\n",
    "                definition = self.find_term_in_dict(phrase)\n",
    "                if definition:\n",
    "                    found_terms[phrase] = definition\n",
    "        \n",
    "        # Strategy 3: Medical abbreviations (enhanced pattern)\n",
    "        abbreviations = re.findall(r'\\b[A-Z]{2,8}\\b', text)  # Increased from 6 to 8\n",
    "        for abbrev in abbreviations:\n",
    "            definition = self.find_term_in_dict(abbrev)\n",
    "            if definition:\n",
    "                found_terms[abbrev] = definition\n",
    "        \n",
    "        # Strategy 4: Medical procedures and conditions with specific patterns\n",
    "        medical_patterns = [\n",
    "            r'\\b\\w+oscopy\\b',          # bronchoscopy, endoscopy, etc.\n",
    "            r'\\b\\w+ectomy\\b',          # appendectomy, etc.\n",
    "            r'\\b\\w+itis\\b',            # bronchitis, arthritis, etc.\n",
    "            r'\\b\\w+osis\\b',            # fibrosis, stenosis, etc.\n",
    "            r'\\b\\w+emia\\b',            # anemia, septicemia, etc.\n",
    "            r'\\b\\w+pathy\\b',           # myopathy, neuropathy, etc.\n",
    "            r'\\b\\w+malacia\\b',         # tracheomalacia, etc.\n",
    "        ]\n",
    "        \n",
    "        for pattern in medical_patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                definition = self.find_term_in_dict(match)\n",
    "                if definition:\n",
    "                    found_terms[match] = definition\n",
    "        \n",
    "        # Strategy 5: Medication names (often end in specific suffixes)\n",
    "        medication_patterns = [\n",
    "            r'\\b\\w+cillin\\b',          # penicillin, amoxicillin, etc.\n",
    "            r'\\b\\w+mycin\\b',           # streptomycin, etc.\n",
    "            r'\\b\\w+floxacin\\b',        # levofloxacin, ciprofloxacin, etc.\n",
    "            r'\\b\\w+sone\\b',            # prednisone, cortisone, etc.\n",
    "            r'\\b\\w+pam\\b',             # lorazepam, etc.\n",
    "        ]\n",
    "        \n",
    "        for pattern in medication_patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                definition = self.find_term_in_dict(match)\n",
    "                if definition:\n",
    "                    found_terms[match] = definition\n",
    "        \n",
    "        return found_terms\n",
    "    \n",
    "    def get_n_grams(self, text, n):\n",
    "        \"\"\"Generate n-grams from text.\"\"\"\n",
    "        words = re.findall(r'\\b[A-Za-z]+\\b', text.lower())\n",
    "        n_grams = []\n",
    "        for i in range(len(words) - n + 1):\n",
    "            phrase = ' '.join(words[i:i+n])\n",
    "            n_grams.append(phrase)\n",
    "        return n_grams\n",
    "    \n",
    "    def find_term_in_dict(self, term):\n",
    "        \"\"\"Find term in medical dictionary.\"\"\"\n",
    "        search_formats = [\n",
    "            term, term.lower(), term.upper(), term.title(), term.capitalize()\n",
    "        ]\n",
    "        \n",
    "        for search_term in search_formats:\n",
    "            if search_term in self.meddict:\n",
    "                return self.meddict[search_term]\n",
    "        \n",
    "        # Partial matching\n",
    "        for key in self.meddict.keys():\n",
    "            if key.lower() == term.lower():\n",
    "                return self.meddict[key]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def create_prompt(self, original_text, found_terms):\n",
    "        \"\"\"\n",
    "        Create the exact prompt that will be sent to the model.\n",
    "        Enhanced with better instructions for patient-focused explanations.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Format found terms for inclusion in prompt\n",
    "        terms_section = \"\"\n",
    "        if found_terms:\n",
    "            terms_section = \"Found medical terms and their definitions:\\n\"\n",
    "            for term, definition in found_terms.items():\n",
    "                terms_section += f\"- {term}: {definition}\\n\"\n",
    "        else:\n",
    "            terms_section = \"No medical terms found in dictionary.\\n\"\n",
    "        \n",
    "        # Enhanced prompt with direct patient addressing\n",
    "        prompt = f\"\"\"<s>[INST] You are a medical doctor and educator who explains medical information directly to patients in simple, caring language.\n",
    "\n",
    "Original medical text:\n",
    "\"{original_text}\"\n",
    "\n",
    "{terms_section}\n",
    "\n",
    "Your task:\n",
    "1. Address the patient directly using \"you\" and \"your\" (e.g., \"You have a condition called...\" not \"This is a story about...\")\n",
    "2. Explain the medical content in simple, everyday language that anyone can understand\n",
    "3. For EVERY medical term found above, provide a clear explanation using middle school level words\n",
    "4. Be accurate, reassuring, and caring in tone\n",
    "5. Organize your explanation clearly: condition ‚Üí what happened ‚Üí treatments ‚Üí outcome\n",
    "6. Include key procedures and treatments mentioned in the text (e.g., code status related procedures, procedures, medications, and test results)\n",
    "7. Explain why treatments were necessary and how they helped\n",
    "8. End with encouraging words about recovery and next steps\n",
    "\n",
    "Please provide your patient-focused explanation now:\n",
    "\n",
    "[/INST]\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def _generate_raw_response(self, prompt):\n",
    "        \"\"\"\n",
    "        Generate raw response from model (separated from cleaning).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Tokenize input\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(self.model.device)\n",
    "            input_length = inputs[\"input_ids\"].shape[1]\n",
    "            \n",
    "            # Generate response\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    inputs[\"input_ids\"],\n",
    "                    attention_mask=inputs[\"attention_mask\"],\n",
    "                    **self.generation_config\n",
    "                )\n",
    "            \n",
    "            # Extract only the NEW tokens (response), not the input prompt\n",
    "            response_tokens = outputs[0][input_length:]  # Skip input tokens\n",
    "            raw_output = self.tokenizer.decode(response_tokens, skip_special_tokens=False)\n",
    "            \n",
    "            return raw_output\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Error generating response: {str(e)}\"\n",
    "    \n",
    "    def model_clean_response(self, raw_response, original_prompt):\n",
    "        \"\"\"\n",
    "        Enhanced cleaning with better instructions for patient-focused, structured output.\n",
    "        \"\"\"\n",
    "        \n",
    "        # If response is very short or error, return as-is\n",
    "        if len(raw_response.strip()) < 10 or raw_response.startswith(\"‚ùå\"):\n",
    "            return raw_response\n",
    "        \n",
    "        cleaning_prompt = f\"\"\"<s>[INST] You are a medical text editor. Clean up this patient explanation to make it perfect.\n",
    "\n",
    "ORIGINAL PROMPT GIVEN TO MODEL:\n",
    "{original_prompt}\n",
    "\n",
    "RAW MODEL OUTPUT TO CLEAN:\n",
    "\"{raw_response}\"\n",
    "\n",
    "CLEANING INSTRUCTIONS:\n",
    "1. Remove any special tokens like <s>, </s>, [INST], [/INST]\n",
    "2. Fix any anonymization issues - use \"you\" and \"your\" consistently instead of \"[**Patient Name**]\" \n",
    "3. Remove any incomplete sentences at the end\n",
    "4. Remove repetitive or garbled text\n",
    "5. Ensure direct patient addressing throughout (\"You have...\" not \"The patient has...\")\n",
    "6. Organize clearly: Your condition ‚Üí What happened ‚Üí Treatments ‚Üí Outcome ‚Üí Next steps\n",
    "7. Make sure all medical terms mentioned are properly explained in simple language\n",
    "8. Keep the caring, reassuring tone\n",
    "9. Ensure it flows naturally and is easy to read\n",
    "10. End on an encouraging, positive note about recovery\n",
    "11. Do not skip medical procedures related to code status (intubation, extubation, and Cardiopulmonary Resuscitation)\n",
    "\n",
    "Return only the clean, patient-focused explanation:\n",
    "\n",
    "[/INST]\"\"\"\n",
    "        \n",
    "        try:\n",
    "            inputs = self.tokenizer(cleaning_prompt, return_tensors=\"pt\", truncation=True).to(self.model.device)\n",
    "            input_length = inputs[\"input_ids\"].shape[1]\n",
    "            \n",
    "            # Use enhanced generation config for cleaning\n",
    "            cleaning_config = {\n",
    "                \"max_new_tokens\": 600,  # Increased for more complete cleaning\n",
    "                \"temperature\": 0.1,\n",
    "                \"top_p\": 0.9,\n",
    "                \"repetition_penalty\": 1.1,\n",
    "                \"do_sample\": True,\n",
    "                \"pad_token_id\": self.tokenizer.eos_token_id,\n",
    "                \"eos_token_id\": self.tokenizer.eos_token_id,\n",
    "                \"early_stopping\": True,\n",
    "            }\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    inputs[\"input_ids\"],\n",
    "                    attention_mask=inputs[\"attention_mask\"],\n",
    "                    **cleaning_config\n",
    "                )\n",
    "            \n",
    "            # Extract only the cleaned response\n",
    "            response_tokens = outputs[0][input_length:]\n",
    "            cleaned = self.tokenizer.decode(response_tokens, skip_special_tokens=True)\n",
    "            \n",
    "            # Post-process to fix common issues\n",
    "            cleaned = self.post_process_patient_text(cleaned.strip())\n",
    "            \n",
    "            return cleaned\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Fallback to enhanced cleaning if model cleaning fails\n",
    "            return self.enhanced_fallback_clean(raw_response)\n",
    "    \n",
    "    def post_process_patient_text(self, text):\n",
    "        \"\"\"\n",
    "        Post-process the cleaned text to ensure patient-focused language.\n",
    "        \"\"\"\n",
    "        # Fix anonymization placeholders\n",
    "        anonymization_fixes = [\n",
    "            (r'\\[?\\*?\\*?Patient Name\\*?\\*?\\]?', 'you'),\n",
    "            (r'\\[?\\*?\\*?Patient\\*?\\*?\\]?', 'you'),\n",
    "            (r'the patient', 'you'),\n",
    "            (r'The patient', 'You'),\n",
    "            (r'This patient', 'You'),\n",
    "            (r'this patient', 'you'),\n",
    "            (r'A patient', 'You'),\n",
    "            (r'a patient', 'you'),\n",
    "        ]\n",
    "        \n",
    "        for pattern, replacement in anonymization_fixes:\n",
    "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "        \n",
    "        # Fix common grammar issues after pronoun replacement\n",
    "        text = re.sub(r'\\byou was\\b', 'you were', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\byou has\\b', 'you have', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\byou is\\b', 'you are', text, flags=re.IGNORECASE)\n",
    "        \n",
    "        # Remove story-like introductions\n",
    "        story_patterns = [\n",
    "            r'^This is a story about.*?\\.',\n",
    "            r'^Let me tell you about.*?\\.',\n",
    "            r'^Here\\'s what happened.*?\\.',\n",
    "        ]\n",
    "        \n",
    "        for pattern in story_patterns:\n",
    "            text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.DOTALL)\n",
    "        \n",
    "        # Clean up extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = text.strip()\n",
    "        \n",
    "        # Ensure it starts with \"You\" if it doesn't already\n",
    "        if not text.lower().startswith('you'):\n",
    "            text = 'You ' + text.lower()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def enhanced_fallback_clean(self, raw_output):\n",
    "        \"\"\"\n",
    "        Enhanced fallback cleaning with patient-focused improvements.\n",
    "        \"\"\"\n",
    "        cleaned = raw_output\n",
    "        \n",
    "        # Remove special tokens\n",
    "        cleanup_patterns = [\"</s>\", \"<s>\", \"[INST]\", \"[/INST]\"]\n",
    "        for pattern in cleanup_patterns:\n",
    "            cleaned = cleaned.replace(pattern, \"\")\n",
    "        \n",
    "        # Apply patient-focused post-processing\n",
    "        cleaned = self.post_process_patient_text(cleaned)\n",
    "        \n",
    "        # Remove incomplete sentences more intelligently\n",
    "        sentences = re.split(r'[.!?]+', cleaned)\n",
    "        complete_sentences = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if len(sentence) > 10 and not sentence.endswith(('and', 'or', 'but', 'the', 'a', 'an')):\n",
    "                complete_sentences.append(sentence)\n",
    "        \n",
    "        if complete_sentences:\n",
    "            result = '. '.join(complete_sentences) + '.'\n",
    "            # Fix double periods\n",
    "            result = re.sub(r'\\.+', '.', result)\n",
    "            return result\n",
    "        \n",
    "        return cleaned\n",
    "    \n",
    "    def create_cleaning_prompt(self, raw_response, original_prompt):\n",
    "        \"\"\"\n",
    "        Create the enhanced cleaning prompt for transparency.\n",
    "        \"\"\"\n",
    "        return f\"\"\"<s>[INST] You are a medical text editor. Clean up this patient explanation to make it perfect.\n",
    "\n",
    "ORIGINAL PROMPT GIVEN TO MODEL:\n",
    "{original_prompt}\n",
    "\n",
    "RAW MODEL OUTPUT TO CLEAN:\n",
    "\"{raw_response}\"\n",
    "\n",
    "CLEANING INSTRUCTIONS:\n",
    "1. Remove any special tokens like <s>, </s>, [INST], [/INST]\n",
    "2. Fix any anonymization issues - use \"you\" and \"your\" consistently instead of \"[**Patient Name**]\" \n",
    "3. Remove any incomplete sentences at the end\n",
    "4. Remove repetitive or garbled text\n",
    "5. Ensure direct patient addressing throughout (\"You have...\" not \"The patient has...\")\n",
    "6. Organize clearly: Your condition ‚Üí What happened ‚Üí Treatments ‚Üí Outcome ‚Üí Next steps\n",
    "7. Make sure all medical terms mentioned are properly explained in simple language\n",
    "8. Keep the caring, reassuring tone\n",
    "9. Ensure it flows naturally and is easy to read\n",
    "10. End on an encouraging, positive note about recovery\n",
    "\n",
    "Return only the clean, patient-focused explanation:\n",
    "\n",
    "[/INST]\"\"\"\n",
    "\n",
    "    def clean_raw_output(self, raw_output, original_prompt=\"\"):\n",
    "        \"\"\"\n",
    "        Directly clean a raw output with optional original prompt context.\n",
    "        \n",
    "        Args:\n",
    "            raw_output (str): Raw model output to clean\n",
    "            original_prompt (str): Original prompt for context (optional)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Cleaning results\n",
    "        \"\"\"\n",
    "        print(\"üßπ Cleaning raw output directly...\")\n",
    "        \n",
    "        cleaned_output = self.model_clean_response(raw_output, original_prompt)\n",
    "        cleaning_prompt = self.create_cleaning_prompt(raw_output, original_prompt)\n",
    "        \n",
    "        result = {\n",
    "            'raw_output': raw_output,\n",
    "            'original_prompt': original_prompt,\n",
    "            'cleaning_prompt': cleaning_prompt,\n",
    "            'cleaned_output': cleaned_output,\n",
    "            'cleaned_length': len(cleaned_output)\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úÖ Cleaned to {len(cleaned_output)} characters\")\n",
    "        return result\n",
    "        \"\"\"\n",
    "        Create the enhanced cleaning prompt for transparency.\n",
    "        \"\"\"\n",
    "        return f\"\"\"<s>[INST] You are a medical text editor. Clean up this patient explanation to make it perfect.\n",
    "\n",
    "ORIGINAL PROMPT GIVEN TO MODEL:\n",
    "{original_prompt}\n",
    "\n",
    "RAW MODEL OUTPUT TO CLEAN:\n",
    "\"{raw_response}\"\n",
    "\n",
    "CLEANING INSTRUCTIONS:\n",
    "1. Remove any special tokens like <s>, </s>, [INST], [/INST]\n",
    "2. Fix any anonymization issues - use \"you\" and \"your\" consistently instead of \"[**Patient Name**]\" \n",
    "3. Remove any incomplete sentences at the end\n",
    "4. Remove repetitive or garbled text\n",
    "5. Ensure direct patient addressing throughout (\"You have...\" not \"The patient has...\")\n",
    "6. Organize clearly: Your condition ‚Üí What happened ‚Üí Treatments ‚Üí Outcome ‚Üí Next steps\n",
    "7. Make sure all medical terms mentioned are properly explained in simple language\n",
    "8. Keep the caring, reassuring tone\n",
    "9. Ensure it flows naturally and is easy to read\n",
    "10. End on an encouraging, positive note about recovery\n",
    "\n",
    "Return only the clean, patient-focused explanation:\n",
    "\n",
    "[/INST]\"\"\"\n",
    "\n",
    "# Demo and usage examples\n",
    "def demo_modular_system():\n",
    "    \"\"\"Demonstrate the new modular step system.\"\"\"\n",
    "    \n",
    "    print(\"üîß MODULAR MEDICAL EXPLANATION SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"üìã Available Step Combinations:\")\n",
    "    print()\n",
    "    \n",
    "    print(\"1Ô∏è‚É£ FULL PIPELINE - All steps (default)\")\n",
    "    print(\"   result = explainer.explain_medical_text(text)\")\n",
    "    print(\"   result = explainer.explain_medical_text(text, steps=['extract', 'generate', 'clean'])\")\n",
    "    print()\n",
    "    \n",
    "    print(\"2Ô∏è‚É£ SKIP CLEANING - Raw model output\")\n",
    "    print(\"   result = explainer.explain_medical_text(text, steps=['extract', 'generate'])\")\n",
    "    print()\n",
    "    \n",
    "    print(\"3Ô∏è‚É£ ONLY EXTRACT - Just find medical terms\")\n",
    "    print(\"   result = explainer.explain_medical_text(text, steps=['extract'])\")\n",
    "    print()\n",
    "    \n",
    "    print(\"4Ô∏è‚É£ GENERATE ONLY - Skip extraction\")\n",
    "    print(\"   result = explainer.explain_medical_text(text, steps=['generate'])\")\n",
    "    print()\n",
    "    \n",
    "    print(\"5Ô∏è‚É£ CUSTOM PIPELINE - Generate then clean\")\n",
    "    print(\"   result = explainer.explain_medical_text(text, steps=['generate', 'clean'])\")\n",
    "    print()\n",
    "    \n",
    "    print(\"‚úÖ BENEFITS:\")\n",
    "    print(\"   ‚Ä¢ Run only the steps you need\")\n",
    "    print(\"   ‚Ä¢ Debug individual steps\") \n",
    "    print(\"   ‚Ä¢ Compare raw vs cleaned outputs\")\n",
    "    print(\"   ‚Ä¢ Skip expensive cleaning for quick tests\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_modular_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330cd4de-e256-45db-94ae-348effe10813",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = MedicalTextExplainer(model, tokenizer, meddict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bca9324-f0e3-450a-a78e-e1ed454c2457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Running step: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Found 131 medical terms\n",
      "üîÑ Running step: generate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ü§ñ Generated 2731 character response\n",
      "‚úÖ Completed 2 steps: ['extract', 'generate']\n",
      "üßπ Cleaning raw output directly...\n",
      "   ‚úÖ Cleaned to 2610 characters\n"
     ]
    }
   ],
   "source": [
    "result = explainer.explain_medical_text(text, steps=['extract', 'generate'])\n",
    "cleaned_result = explainer.clean_raw_output(\n",
    "    raw_output=result['raw_output'],\n",
    "    original_prompt=result['prompt']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99dce79b-0628-42cc-8664-305633984f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "steps_run ['extract', 'generate']\n",
      "============================================\n",
      "available_steps ['extract', 'generate', 'clean']\n",
      "============================================\n",
      "terms_count 131\n",
      "============================================\n",
      "raw_output Dear [Patient's Name],\n",
      "\n",
      "I want to explain what happened to you during your stay here at [Hospital1 18]. You were an 81-year-old woman who had been struggling with a lung condition called emphysema, which is a problem with the air sacs in your lungs. You weren't using oxygen at home before this visit, but recently you had a flare-up of your emphysema and needed oxygen to help you breathe.\n",
      "\n",
      "When you arrived at our emergency room, your oxygen levels were low even with the help of a CPAP machine. We tried various treatments, including steroids, nebulizers, and medication, but nothing seemed to help. That's why we decided to admit you to the Intensive Care Unit (ICU) and later to [Doctor Last Name ]'s care.\n",
      "\n",
      "While in the ICU, we discovered that your airways were narrowing, which made it difficult for you to breathe properly. To help with this issue, we placed two silicone stents ‚Äì small tubes ‚Äì in your airways. One went into your left main stem bronchus and the other went into your trachea (windpipe). This procedure was done under general anesthesia, which means you were asleep during the operation.\n",
      "\n",
      "After the stent placement, we were able to gradually wean you off the ventilator and eventually extubate you (remove the breathing tube). You spent some time on a cool mist shovel mask and your oxygen levels improved. Once your oxygen levels were stable, we moved you to a regular hospital room and began weaning you off the steroids.\n",
      "\n",
      "We also addressed some other issues during your stay. Your blood pressure was a bit high, so we adjusted your medications to bring it under control. You had some episodes of chest pain, but tests showed that it wasn't related to a heart attack. We gave you medication to help with the pain and continue your previous medications for angina (chest pain due to poor blood flow to the heart).\n",
      "\n",
      "Additionally, we noticed that you had some muscle weakness, possibly due to steroid myopathy (muscle weakness caused by steroid use) and deconditioning (loss of muscle strength due to prolonged bed rest). We referred you to physical therapy to help strengthen your muscles.\n",
      "\n",
      "Overall, your stay with us was challenging, but we're pleased to say that you're on the road to recovery! After being stabilized, we discharged you to [Hospital1] for further rehabilitation. We recommend that you follow up with [Doctor First Name4 Last Name] within two weeks, as well as with the Interventional Pulmonology service for a follow-up appointment regarding your stents. If your muscle weakness doesn't improve within a week, we suggest seeing a neurologist.\n",
      "\n",
      "Take care and keep fighting, [Patient's Name]! We believe in your ability to overcome this challenge and return to your normal routine soon.</s>\n",
      "============================================\n",
      "prompt_length 43477\n",
      "============================================\n",
      "raw_output_length 2731\n"
     ]
    }
   ],
   "source": [
    "for k,v in result.items():\n",
    "    if k not in ['original_text', 'found_terms','prompt']:\n",
    "        print('='*44)\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ebb4233-0672-4c02-8932-e9a0382e3647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Admission Date:  [**2119-5-4**]              Discharge Date:   [**2119-5-25**]\\n\\n\\nService: CARDIOTHORACIC\\n\\nAllergies:\\nAmlodipine\\n\\nAttending:[**Last Name (NamePattern1) 1561**]\\nChief Complaint:\\n81 yo F smoker w/ COPD, severe TBM, s/p tracheobronchoplasty [**5-5**]\\ns/p perc trach [**5-13**]\\n\\nMajor Surgical or Invasive Procedure:\\nbronchoscopy 3/31,4/2,3,[**6-12**], [**5-17**], [**5-19**]\\ns/p trachealplasty [**5-5**]\\npercutaneous tracheostomy [**5-13**] after failed extubation\\ndown size trach on [**5-25**] to size 6 cuffless\\n\\n\\nHistory of Present Illness:\\nThis 81 year old woman has a history of COPD. Over the past five\\n\\nyears she has had progressive difficulties with her breathing.\\nIn\\n[**2118-6-4**] she was admitted to [**Hospital1 18**] for respiratory failure\\ndue\\nto a COPD exacerbation. Due to persistent hypoxemia, she\\nrequired\\nintubation and a eventual bronchoscopy on [**2118-6-9**] revealed marked\\n\\nnarrowing of the airways on expiration consistent with\\ntracheomalacia.\\nShe subsequently underwent placement of two\\nsilicone stents, one in the left main stem and one in the\\ntrachea. During the admission the patient had complaints of\\nchest\\npain and ruled out for an MI. She was subsequently discharged to\\n\\n[**Hospital1 **] for physical and pulmonary rehab. Repeat bronchoscopy\\non\\n[**2118-8-1**] revealed granulation tissue at the distal right lateral\\nwall of the tracheal stent. There was significant malacia of the\\n\\nperipheral and central airways with complete collapse of the\\nairways on coughing and forced expiration. Small nodules were\\nalso noted on the vocal cords. She has noticed improvement in\\nher\\nrespiratory status, but most recently has been in discussion\\nwith Dr. [**First Name4 (NamePattern1) 951**] [**Last Name (NamePattern1) 952**] regarding possible tracheobronchial plasty\\n\\nwith mesh. Tracheal stents d/c [**2119-4-19**] in anticipation of\\nsurgery.\\nIn terms of symptoms, she describes many years of intermittent\\nchest pain that she describes as left sided and occurring at any\\n\\ntime. Currently, she notices it about three times a week, and\\nstates that it seems to resolve after three nitroglycerin.\\nShe currently is dependent on oxygen and wears 1.5-2 liters\\naround the clock. She has frequent coughing and brings up \"dark\\nsputum\".\\n\\n\\n\\nPast Medical History:\\nCOPD flare [**6-7**] s/p intubation, s/p distal tracheal to Left Main\\nStem stents placed [**2118-6-9**]. Stents d/c\\'d [**2119-4-19**], CAD w/ atypical\\nangina (LAD 30%, RCA 30%, EF 63%), ^chol, hypothyroidism, htn,\\nhiatal hernia, lacunar CVA, s/p ped struck -> head injury & rib\\nfx, depression\\nPMH:\\nCOPD, s/p admit [**6-7**] for exacerbation requiring intubation\\ntracheobronchomalacia, s/p bronchial stenting\\nLarge hiatal hernia\\nLacunar CVA\\nHypothyroidism by records in CCC, although patient denies and is\\n\\nnot taking any medication\\nDepression\\nMVA, s/p head injury approximately 10 years ago\\nHypertension\\nHysterectomy\\n\\n\\nSocial History:\\nSocial History: The patient is married and worked as a clinical\\npsychologist. Her husband is a pediatric neurologist at\\n[**Hospital3 **]. They have several children, one of which is\\n\\na nurse.\\n\\n\\nFamily History:\\nFamily History: (+) FHx CAD; Father with an MI in his 40\\'s, died\\n\\nof a CVA at age 59\\n\\n\\nPhysical Exam:\\nAdmit H+P\\nGeneral-lovely 81 yr old feamle in NAD.\\nNeuro- intermittently anxious, MAE, PERRLA, L eye ptosis,\\nsymetrical smile, gossly intact.\\nHEENT-PERRLA, sclera anicteric, pharynx- no exud or erythema\\nResp-clear upper, diffuse ronchi, intermit exp wheezes\\nCor- RRR, No M, R, G\\nAbd- soft, NT, ND, no masses. Slight protrusion at area of\\nhiatal hernia\\nExt- no edema or clubbing\\n\\nBrief Hospital Course:\\n82 y/o female admitted [**2119-5-4**] for consideration of\\ntracheoplasty.\\nBronchoscopy done [**5-4**] confirming severe TBM. Underwent\\ntracheoplasty [**5-5**], complicated by resp failure d/t mucous\\nplugging, hypoxia requiring re-intubation resulting in prolonged\\nICU and hospital course. Also developed right upper extrem DVT\\nfrom mid line.\\n\\nPain- Epidural accidently d/c\\'d POD#1, pt briefly used dilaudid\\nPCA intermittently w/ fair pain control. Pt required\\nre-intubation for resp failure d/t secretions and PCA d/c at\\nthat time. Propofol for sedation while intubated. Sedation d/c\\'d\\n[**5-12**] for weaning trial w/ ETT- failed trial. Trach [**5-13**]-weaning\\nefforts as below. Minimal c/o pain since [**5-13**]. Presently pain\\nfree.\\n\\nNeuro- Initially intact- post op aggitation, inhibiting weaning\\nefforts [**5-16**]. Psych eval [**5-18**]-Started on zyprexa and ativan w/\\nimprovement in anxiety. Presently A+Ox3- cooperative and lovely.\\n\\nResp- Extubated POD#2 then required re-intub  [**5-7**] for hypoxia\\nd/t poor cough and mucous plugging. SIMV/PS alt w/CMV at night\\nx4-5d, with CPAP attempts during day.\\nBronchoscopy qd [**Date range (1) 1813**] for secretion management. Bronch [**5-9**]\\nrevealed swollen epiglottis, bronch [**5-10**] - good leak w/ ETT cuff\\ndeflated. Bronch [**5-13**] for eval/trach placement. Last bronch [**5-19**]\\nw/ min secretions present, sputum sent.\\n[**5-13**] perc trach done(#8 Portex- cuffed low pressure maintained to\\npreserve tracheoplasty site). [**5-13**] CPAP15/peep5 initiated post\\ntrach placement. Weaning ongoing.  [**Date range (1) 1814**]- Aggressive weaning\\nw/ increasing episodes of CPAP, progressing to Trach Mask.\\n[**2033-5-20**]-Trach mask overnight w/ no episodes of SOB, or\\nhemodynamic instability. Trach changed to #6 portex- capped and\\n[**Last Name (un) 1815**] well x48hrs on 2LNP. productive cough. Aggressive PT as\\nwell w/ OOB > chair [**Hospital1 **]-tid to total 4-6hr qd. Ambulation\\n~100-120 ft [**5-22**] w/ PT assist.\\n\\nID- Vancomycin started post-op for graft prophylaxis. Fever\\nspike [**2119-5-8**] w/ BAl & sputum sent> + MRSA. Vanco cont to [**4-7**]\\nweeks post trachealplasty. Fever low grade [**5-12**], [**5-15**]> cultured-\\nno new results. [**5-19**]- WBC 20.8 .\\n\\nCardiac-Hypertension controlled w/ hydralazine IV, then d/c and\\ncont controlled. HR 65-75 NSR. Avoiding B Blockers. Lasix 20mg\\nIV qd.\\n[**5-15**]- RUE redness and swelling at site of midline, RUE DVT by\\nultrasound, midline d/c; heparin gtt started and therapeutic\\nrange monitored. [**5-22**]  changed to Lovenox sq [**Hospital1 **]. Coags in good\\ncontrol [**5-23**] (48.2/13.8/1.2)\\nAccess- R midline placed [**2119-5-9**] for access- clotted [**2119-5-15**] and\\nd/c\\'d.  RUE redness and swelling and DVT via ultrasound. [**5-15**]- L\\nbrachial PICC line placed- TPN resumed.\\n\\nGI-Large hiatal hernia- unable to place enteral feeding tube at\\nbedside or underfluoro. Re-attempt [**5-17**] by EGD doboff tube\\nplaced distal esophagus, dislodged in 12hours and removed.\\n\\nNutrition- PPN/TPN initiated [**2119-5-8**]- [**2119-5-25**]. PICC placed\\n[**2119-5-15**]. Speech and Swallow eval [**5-22**]- rec change trach form #8\\nto #6 Portex to allow improved epiglotis and oropharyngeal\\nmovement to assist w/ swallowing. Then re-eval.  Trach changed\\n[**5-23**] to #6 cuffless portex trach. Passed repeat swallow eval and\\n[**Last Name (un) 1815**] diet of regular solids w/ thin liquids- CHIN TUCK to\\nswallow thin liquids. Give meds whole w/ apple sauce. WOULD\\nRECOMMEND repeat video swallow eval in [**8-17**] days to possibly\\neliminate chin tuck- see page 3 referral.\\n\\nEndo- Hypothyroid, maintained on levoxyl.\\n\\nMuscu/Skel- OOB> chair 4-6hours/day, PT consulting.\\n\\n\\nMedications on Admission:\\nadvair 250/50\", atrovent, imdur 60\\', lasix 40\\', lexapro 20\\',\\nlipitor 10\\', prilosec 20\\', mucinex 600\", synthroid 75\\', detrol\\nLA 4\\', ambien 5\\', trazadone 75\\', melatonin prn\\n\\nDischarge Medications:\\n1. Albuterol Sulfate 0.083 % Solution Sig: One (1)  Inhalation\\nQ6H (every 6 hours) as needed for wheezing.\\n2. Ipratropium Bromide 0.02 % Solution Sig: One (1)  Inhalation\\nQ6H (every 6 hours) as needed for wheezing.\\n3. Fluticasone-Salmeterol 250-50 mcg/Dose Disk with Device Sig:\\nOne (1) Disk with Device Inhalation [**Hospital1 **] (2 times a day).\\n4. Albuterol 90 mcg/Actuation Aerosol Sig: 1-2 Puffs Inhalation\\nQ6H (every 6 hours) as needed.\\n5. Ipratropium Bromide 18 mcg/Actuation Aerosol Sig: Two (2)\\nPuff Inhalation QID (4 times a day).\\n6. Acetaminophen 325 mg Tablet Sig: 1-2 Tablets PO Q4-6H (every\\n4 to 6 hours) as needed.\\n7. Sodium Chloride 0.65 % Aerosol, Spray Sig: [**2-5**] Sprays Nasal\\nQID (4 times a day) as needed.\\n8. Camphor-Menthol 0.5-0.5 % Lotion Sig: One (1) Appl Topical\\nTID (3 times a day) as needed.\\n9. Enoxaparin Sodium 60 mg/0.6mL Syringe Sig: One (1)\\nSubcutaneous Q12H (every 12 hours).\\n10. Trazodone HCl 50 mg Tablet Sig: 1.5 Tablets PO HS (at\\nbedtime) as needed.\\n11. Escitalopram Oxalate 10 mg Tablet Sig: Two (2) Tablet PO\\nDAILY (Daily).\\n12. Nystatin 100,000 unit/g Cream Sig: One (1) Appl Topical  [**Hospital1 **]\\n(2 times a day).\\n13. Pantoprazole Sodium 40 mg Tablet, Delayed Release (E.C.)\\nSig: One (1) Tablet, Delayed Release (E.C.) PO Q24H (every 24\\nhours).\\n14. Tolterodine Tartrate 2 mg Tablet Sig: One (1) Tablet PO BID\\n(2 times a day).\\n15. Levothyroxine Sodium 75 mcg Tablet Sig: One (1) Tablet PO\\nDAILY (Daily).\\n16. Heparin Lock Flush (Porcine) 100 unit/mL Syringe Sig: One\\n(1) ML Intravenous  DAILY (Daily) as needed.\\n\\n\\nDischarge Disposition:\\nExtended Care\\n\\nFacility:\\n[**Hospital3 7**] & Rehab Center - [**Hospital1 8**]\\n\\nDischarge Diagnosis:\\nCOPD, Coronary Artery Disease/atypical angina (LAD 30%, RCA 30%,\\nEF 63%), hypercholesterolemia, hypothyroidism, Hypertension,\\nhiatal hernia, Cerebral Vascular Accident,s/p Motor Vehicle\\nColision-> head injury & rib fracture.\\nTBM- s/p tracheoplasty.\\n\\n\\nDischarge Condition:\\ngood\\n\\nDischarge Instructions:\\nplease update Dr.[**Name (NI) 1816**] [**Telephone/Fax (1) 170**] office for:  fever,\\nshortness of breath, chest pain , productive cough or if you\\nhave any questions or concerns.\\n\\n\\nCompleted by:[**2119-5-25**]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1].TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bebc6fb-06a4-4ec8-b5ae-81f3690ed848",
   "metadata": {},
   "outputs": [],
   "source": [
    "allres=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e226643-1e3e-4b3b-9694-f678d6534190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'CHARTDATE', 'CATEGORY',\n",
       "       'DESCRIPTION', 'TEXT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55cb93ac-50ff-41b2-8495-cfede50d5853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Running step: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Found 131 medical terms\n",
      "üîÑ Running step: generate\n",
      "   ü§ñ Generated 2930 character response\n",
      "‚úÖ Completed 2 steps: ['extract', 'generate']\n",
      "üîÑ Running step: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Found 111 medical terms\n",
      "üîÑ Running step: generate\n",
      "   ü§ñ Generated 2958 character response\n",
      "‚úÖ Completed 2 steps: ['extract', 'generate']\n",
      "üîÑ Running step: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Found 153 medical terms\n",
      "üîÑ Running step: generate\n",
      "   ü§ñ Generated 3104 character response\n",
      "‚úÖ Completed 2 steps: ['extract', 'generate']\n",
      "üîÑ Running step: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Found 167 medical terms\n",
      "üîÑ Running step: generate\n",
      "   ü§ñ Generated 3153 character response\n",
      "‚úÖ Completed 2 steps: ['extract', 'generate']\n",
      "üîÑ Running step: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Found 82 medical terms\n",
      "üîÑ Running step: generate\n",
      "   ü§ñ Generated 2523 character response\n",
      "‚úÖ Completed 2 steps: ['extract', 'generate']\n",
      "üîÑ Running step: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Found 64 medical terms\n",
      "üîÑ Running step: generate\n",
      "   ü§ñ Generated 2091 character response\n",
      "‚úÖ Completed 2 steps: ['extract', 'generate']\n",
      "üîÑ Running step: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Found 102 medical terms\n",
      "üîÑ Running step: generate\n",
      "   ü§ñ Generated 2998 character response\n",
      "‚úÖ Completed 2 steps: ['extract', 'generate']\n",
      "üîÑ Running step: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Found 72 medical terms\n",
      "üîÑ Running step: generate\n",
      "   ü§ñ Generated 3700 character response\n",
      "‚úÖ Completed 2 steps: ['extract', 'generate']\n",
      "üîÑ Running step: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Found 86 medical terms\n",
      "üîÑ Running step: generate\n",
      "   ü§ñ Generated 2748 character response\n",
      "‚úÖ Completed 2 steps: ['extract', 'generate']\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    text=row['TEXT'] \n",
    "    result = explainer.explain_medical_text(text, steps=['extract', 'generate'])\n",
    "    allres.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b90527f-c0a8-43b5-a596-7858fe4ad878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d1e92aa-12c6-4c24-82c1-2398837a9848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['original_text', 'steps_run', 'available_steps', 'found_terms',\n",
       "       'terms_count', 'prompt', 'raw_output', 'prompt_length',\n",
       "       'raw_output_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(allres)\n",
    "results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d09b893-bbd1-4072-a282-06f7929ea49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b3657-49c7-487b-a5e9-b855ea79f616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
