{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yc/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "# from huggingface_hub import login\n",
    "\n",
    "# login(token=\"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\")\n",
    "\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat import flesch_kincaid_grade, flesch_reading_ease\n",
    "\n",
    "def calculate_readability_scores(text, term=None):\n",
    "    \"\"\"Calculate readability scores for a piece of text, optionally removing a term\"\"\"\n",
    "    scoring_text = text\n",
    "    \n",
    "    # Remove the term and its variations before scoring if provided\n",
    "    if term:\n",
    "        # Create variations of the term to remove (capitalized, lowercase)\n",
    "        term_variations = [term, term.lower(), term.capitalize()]\n",
    "        \n",
    "        for variation in term_variations:\n",
    "            scoring_text = scoring_text.replace(variation, \"\")\n",
    "        \n",
    "        # Clean up any double spaces created\n",
    "        scoring_text = \" \".join(scoring_text.split())\n",
    "    \n",
    "    fk_grade = flesch_kincaid_grade(scoring_text)\n",
    "    readability = flesch_reading_ease(scoring_text)\n",
    "    return {\n",
    "        \"fk_grade\": fk_grade,\n",
    "        \"readability\": readability,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9369"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def txt_to_dict(file_path):\n",
    "    data_dict = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(0, len(lines) - 1, 2):\n",
    "            key = lines[i].strip()    # Odd line are key\n",
    "            value = lines[i + 1].strip()  # Even line are value\n",
    "            data_dict[key] = value\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "txt_file_path = 'formaldef.txt' \n",
    "formaldic = txt_to_dict(txt_file_path)\n",
    "len(formaldic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meddict={}\n",
    "for k,v in formaldic.items():\n",
    "    meddict[k.split('Listen to pronunciation')[0].split('(')[0]]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.48s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Model Configuration\n",
    "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "# Load model with quantization\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map,\n",
    "    quantization_config=bnb_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Improved prompt template with clearer instruction formatting\n",
    "explanation_template = \"\"\"<s>[INST] You are a medical educator explaining complex medical terms.\n",
    "\n",
    "The term is: {term}\n",
    "\n",
    "The medical definition is: {definition}\n",
    "\n",
    "Your task:\n",
    "1. Explain this term in simple language a non-medical person would understand\n",
    "2. Avoid using technical jargon entirely\n",
    "3. Write at a middle school reading level (grades 7-8)\n",
    "4. Do not include examples\n",
    "5. Be concise (maximum 3 short sentences)\n",
    "6. Maintain medical accuracy\n",
    "\n",
    "IMPORTANT: Begin your answer with the actual explanation. Do not write any introductory text like \"Okay!\" or \"Here's my attempt...\" or \"Let me explain...\"\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "# Generation parameters\n",
    "generation_config = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"do_sample\": True  # Enable sampling for more creative responses\n",
    "}\n",
    "\n",
    "# Function to explain a medical term\n",
    "def explain_medical_term(term):\n",
    "    # Look up the term in the dictionary\n",
    "    if term in meddict:\n",
    "        definition = meddict[term]\n",
    "    else:\n",
    "        return f\"\"\n",
    "    \n",
    "    # Create prompt with the definition\n",
    "    prompt = explanation_template.format(term=term, definition=definition)\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Generate explanation\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=generation_config[\"max_new_tokens\"],\n",
    "            temperature=generation_config[\"temperature\"],\n",
    "            top_p=generation_config[\"top_p\"],\n",
    "            repetition_penalty=generation_config[\"repetition_penalty\"],\n",
    "            do_sample=generation_config[\"do_sample\"]\n",
    "        )\n",
    "    \n",
    "    # Decode the response - don't skip special tokens to handle chat format\n",
    "    explanation = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    \n",
    "    # Extract just the model's response part using string manipulation\n",
    "    # For Llama-2-chat models, responses typically follow [/INST]\n",
    "    if \"[/INST]\" in explanation:\n",
    "        explanation = explanation.split(\"[/INST]\")[1].strip()\n",
    "    else:\n",
    "        # Fallback - just remove the prompt\n",
    "        explanation = explanation.replace(prompt, \"\").strip()\n",
    "\n",
    "    # Remove any ending tokens\n",
    "    if \"</s>\" in explanation:\n",
    "        explanation = explanation.split(\"</s>\")[0].strip()\n",
    "    \n",
    "    return explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache() # reset context when try new prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TERM: filter\n",
      "--------------------------------------------------\n",
      "FORMAL DEFINITION:\n",
      "filter is A material or device that allows certain substances to pass through it\n",
      ", while keeping other substances out. Filters may be used in cigarettes to help \n",
      "trap tar and other harmful substances found in tobacco smoke. In medicine, filte\n",
      "r also means to remove toxins, poisons, or other harmful substances from the blo\n",
      "od. For example, the kidneys remove waste and extra water from the blood (as uri\n",
      "ne). The liver also removes harmful substances from the blood.\n",
      "\n",
      "--------------------------------------------------\n",
      "SIMPLIFIED EXPLANATION:\n",
      "A filter is something that helps keep bad things out of your body. Like when you\n",
      " breathe in smoke from a cigarette, a filter can catch the bad stuff and let the\n",
      " good air get through. In your body, filters like your kidneys and liver work to\n",
      "gether to take away the bad things in your blood, like toxins and waste. They ma\n",
      "ke sure only the good stuff stays in your body!\n",
      "\n",
      "--------------------------------------------------\n",
      "READABILITY METRICS:\n",
      "Metric                    Formal     Simplified Improvement\n",
      "------------------------------------------------------------\n",
      "Flesch-Kincaid Grade      9.1        5.3        3.8       \n",
      "Flesch Reading Ease       56.5       87.8       31.3      \n",
      "SMOG Index                11.2       7.2        4.0       \n",
      "Gunning Fog               8.1        6.9        1.2       \n",
      "Dale-Chall Score          7.4        5.9        1.5       \n",
      "------------------------------------------------------------\n",
      "Avg Word Length           4.36       3.75       0.61      \n",
      "Avg Syllables/Word        1.37       1.09       0.28      \n",
      "Long Words (%)            11.6       2.6        9.0       \n",
      "Type-Token Ratio          0.628      0.645      N/A       \n",
      "------------------------------------------------------------\n",
      "Educational Level         9th and 10th grade        5th and 6th grade\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('filter',\n",
       " 'filter is A material or device that allows certain substances to pass through it, while keeping other substances out. Filters may be used in cigarettes to help trap tar and other harmful substances found in tobacco smoke. In medicine, filter also means to remove toxins, poisons, or other harmful substances from the blood. For example, the kidneys remove waste and extra water from the blood (as urine). The liver also removes harmful substances from the blood.',\n",
       " 'A filter is something that helps keep bad things out of your body. Like when you breathe in smoke from a cigarette, a filter can catch the bad stuff and let the good air get through. In your body, filters like your kidneys and liver work together to take away the bad things in your blood, like toxins and waste. They make sure only the good stuff stays in your body!',\n",
       " {'formal': {'fk_grade': 9.1,\n",
       "   'flesch_ease': 56.45,\n",
       "   'smog': 11.2,\n",
       "   'gunning_fog': 8.08,\n",
       "   'dale_chall': 7.36,\n",
       "   'text_standard': '9th and 10th grade',\n",
       "   'word_count': 86,\n",
       "   'avg_word_length': 4.3604651162790695,\n",
       "   'avg_syllables_per_word': 1.372093023255814,\n",
       "   'type_token_ratio': 0.627906976744186,\n",
       "   'long_word_percentage': 11.627906976744185},\n",
       "  'simplified': {'fk_grade': 5.3,\n",
       "   'flesch_ease': 87.76,\n",
       "   'smog': 7.2,\n",
       "   'gunning_fog': 6.92,\n",
       "   'dale_chall': 5.87,\n",
       "   'text_standard': '5th and 6th grade',\n",
       "   'word_count': 76,\n",
       "   'avg_word_length': 3.75,\n",
       "   'avg_syllables_per_word': 1.0921052631578947,\n",
       "   'type_token_ratio': 0.6447368421052632,\n",
       "   'long_word_percentage': 2.631578947368421},\n",
       "  'improvements': {'fk_grade_reduction': 3.8,\n",
       "   'flesch_ease_improvement': 31.310000000000002,\n",
       "   'smog_reduction': 3.999999999999999,\n",
       "   'gunning_fog_reduction': 1.1600000000000001,\n",
       "   'dale_chall_reduction': 1.4900000000000002,\n",
       "   'word_length_reduction': 0.6104651162790695,\n",
       "   'syllable_reduction': 0.27998776009791926,\n",
       "   'long_word_percentage_reduction': 8.996328029375764}})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textstat import (flesch_kincaid_grade, flesch_reading_ease, \n",
    "                     smog_index, gunning_fog, dale_chall_readability_score,\n",
    "                     text_standard, syllable_count)\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Download NLTK resources (run once)\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "def comprehensive_readability_analysis(formal_text, simplified_text, term=None):\n",
    "    \"\"\"\n",
    "    Calculate multiple readability and complexity metrics for medical texts\n",
    "    \n",
    "    Args:\n",
    "        formal_text: The original medical definition\n",
    "        simplified_text: The simplified explanation\n",
    "        term: The medical term to exclude from analysis (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing all metrics and comparisons\n",
    "    \"\"\"\n",
    "    # Clean texts for analysis (remove the term if provided)\n",
    "    formal_clean = formal_text\n",
    "    simplified_clean = simplified_text\n",
    "    \n",
    "    if term:\n",
    "        term_variations = [term, term.lower(), term.capitalize()]\n",
    "        for variation in term_variations:\n",
    "            formal_clean = re.sub(r'\\b' + re.escape(variation) + r'\\b', '', formal_clean)\n",
    "            simplified_clean = re.sub(r'\\b' + re.escape(variation) + r'\\b', '', simplified_clean)\n",
    "        \n",
    "        # Clean up double spaces\n",
    "        formal_clean = ' '.join(formal_clean.split())\n",
    "        simplified_clean = ' '.join(simplified_clean.split())\n",
    "    \n",
    "    # Tokenize for word-level analysis\n",
    "    formal_words = word_tokenize(formal_clean.lower())\n",
    "    simplified_words = word_tokenize(simplified_clean.lower())\n",
    "    \n",
    "    # Calculate traditional readability metrics\n",
    "    metrics = {\n",
    "        \"formal\": {\n",
    "            \"fk_grade\": flesch_kincaid_grade(formal_clean),\n",
    "            \"flesch_ease\": flesch_reading_ease(formal_clean),\n",
    "            \"smog\": smog_index(formal_clean),\n",
    "            \"gunning_fog\": gunning_fog(formal_clean),\n",
    "            \"dale_chall\": dale_chall_readability_score(formal_clean),\n",
    "            \"text_standard\": text_standard(formal_clean),\n",
    "            \"word_count\": len(formal_words),\n",
    "            \"avg_word_length\": sum(len(word) for word in formal_words) / len(formal_words) if formal_words else 0,\n",
    "            \"avg_syllables_per_word\": syllable_count(formal_clean) / len(formal_words) if formal_words else 0,\n",
    "        },\n",
    "        \"simplified\": {\n",
    "            \"fk_grade\": flesch_kincaid_grade(simplified_clean),\n",
    "            \"flesch_ease\": flesch_reading_ease(simplified_clean),\n",
    "            \"smog\": smog_index(simplified_clean),\n",
    "            \"gunning_fog\": gunning_fog(simplified_clean),\n",
    "            \"dale_chall\": dale_chall_readability_score(simplified_clean),\n",
    "            \"text_standard\": text_standard(simplified_clean),\n",
    "            \"word_count\": len(simplified_words),\n",
    "            \"avg_word_length\": sum(len(word) for word in simplified_words) / len(simplified_words) if simplified_words else 0,\n",
    "            \"avg_syllables_per_word\": syllable_count(simplified_clean) / len(simplified_words) if simplified_words else 0,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Calculate lexical complexity measures\n",
    "    \n",
    "    # Type-Token Ratio (vocabulary diversity)\n",
    "    metrics[\"formal\"][\"type_token_ratio\"] = len(set(formal_words)) / len(formal_words) if formal_words else 0\n",
    "    metrics[\"simplified\"][\"type_token_ratio\"] = len(set(simplified_words)) / len(simplified_words) if simplified_words else 0\n",
    "    \n",
    "    # Long word percentage (words with 3+ syllables)\n",
    "    formal_long_words = sum(1 for word in formal_words if syllable_count(word) >= 3)\n",
    "    simplified_long_words = sum(1 for word in simplified_words if syllable_count(word) >= 3)\n",
    "    \n",
    "    metrics[\"formal\"][\"long_word_percentage\"] = formal_long_words / len(formal_words) * 100 if formal_words else 0\n",
    "    metrics[\"simplified\"][\"long_word_percentage\"] = simplified_long_words / len(simplified_words) * 100 if simplified_words else 0\n",
    "    \n",
    "    # Calculate improvements\n",
    "    metrics[\"improvements\"] = {\n",
    "        \"fk_grade_reduction\": metrics[\"formal\"][\"fk_grade\"] - metrics[\"simplified\"][\"fk_grade\"],\n",
    "        \"flesch_ease_improvement\": metrics[\"simplified\"][\"flesch_ease\"] - metrics[\"formal\"][\"flesch_ease\"],\n",
    "        \"smog_reduction\": metrics[\"formal\"][\"smog\"] - metrics[\"simplified\"][\"smog\"],\n",
    "        \"gunning_fog_reduction\": metrics[\"formal\"][\"gunning_fog\"] - metrics[\"simplified\"][\"gunning_fog\"],\n",
    "        \"dale_chall_reduction\": metrics[\"formal\"][\"dale_chall\"] - metrics[\"simplified\"][\"dale_chall\"],\n",
    "        \"word_length_reduction\": metrics[\"formal\"][\"avg_word_length\"] - metrics[\"simplified\"][\"avg_word_length\"],\n",
    "        \"syllable_reduction\": metrics[\"formal\"][\"avg_syllables_per_word\"] - metrics[\"simplified\"][\"avg_syllables_per_word\"],\n",
    "        \"long_word_percentage_reduction\": metrics[\"formal\"][\"long_word_percentage\"] - metrics[\"simplified\"][\"long_word_percentage\"],\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def print_readability_analysis(term, formal_definition, simplified_explanation):\n",
    "    \"\"\"Print detailed readability analysis with consistent formatting\"\"\"\n",
    "    \n",
    "    # Format both texts with consistent line breaks\n",
    "    char_limit = 80\n",
    "    \n",
    "    # Format formal definition with line breaks\n",
    "    formatted_definition = \"\"\n",
    "    for i in range(0, len(formal_definition), char_limit):\n",
    "        formatted_definition += formal_definition[i:i+char_limit] + \"\\n\"\n",
    "    \n",
    "    # Format simplified explanation with the same line breaks\n",
    "    formatted_explanation = \"\"\n",
    "    for i in range(0, len(simplified_explanation), char_limit):\n",
    "        formatted_explanation += simplified_explanation[i:i+char_limit] + \"\\n\"\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = comprehensive_readability_analysis(formal_definition, simplified_explanation, term)\n",
    "    \n",
    "    # Print term and texts\n",
    "    print(f\"\\nTERM: {term}\")\n",
    "    print(f\"{'-'*50}\")\n",
    "    print(f\"FORMAL DEFINITION:\")\n",
    "    print(formatted_definition)\n",
    "    print(f\"{'-'*50}\")\n",
    "    print(f\"SIMPLIFIED EXPLANATION:\")\n",
    "    print(formatted_explanation)\n",
    "    print(f\"{'-'*50}\")\n",
    "    \n",
    "    # Print basic metrics table\n",
    "    print(f\"READABILITY METRICS:\")\n",
    "    print(f\"{'Metric':<25} {'Formal':<10} {'Simplified':<10} {'Improvement':<10}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    \n",
    "    # Traditional readability scores\n",
    "    print(f\"{'Flesch-Kincaid Grade':<25} {metrics['formal']['fk_grade']:<10.1f} {metrics['simplified']['fk_grade']:<10.1f} {metrics['improvements']['fk_grade_reduction']:<10.1f}\")\n",
    "    print(f\"{'Flesch Reading Ease':<25} {metrics['formal']['flesch_ease']:<10.1f} {metrics['simplified']['flesch_ease']:<10.1f} {metrics['improvements']['flesch_ease_improvement']:<10.1f}\")\n",
    "    print(f\"{'SMOG Index':<25} {metrics['formal']['smog']:<10.1f} {metrics['simplified']['smog']:<10.1f} {metrics['improvements']['smog_reduction']:<10.1f}\")\n",
    "    print(f\"{'Gunning Fog':<25} {metrics['formal']['gunning_fog']:<10.1f} {metrics['simplified']['gunning_fog']:<10.1f} {metrics['improvements']['gunning_fog_reduction']:<10.1f}\")\n",
    "    print(f\"{'Dale-Chall Score':<25} {metrics['formal']['dale_chall']:<10.1f} {metrics['simplified']['dale_chall']:<10.1f} {metrics['improvements']['dale_chall_reduction']:<10.1f}\")\n",
    "    \n",
    "    # Lexical complexity\n",
    "    print(f\"{'-'*60}\")\n",
    "    print(f\"{'Avg Word Length':<25} {metrics['formal']['avg_word_length']:<10.2f} {metrics['simplified']['avg_word_length']:<10.2f} {metrics['improvements']['word_length_reduction']:<10.2f}\")\n",
    "    print(f\"{'Avg Syllables/Word':<25} {metrics['formal']['avg_syllables_per_word']:<10.2f} {metrics['simplified']['avg_syllables_per_word']:<10.2f} {metrics['improvements']['syllable_reduction']:<10.2f}\")\n",
    "    print(f\"{'Long Words (%)':<25} {metrics['formal']['long_word_percentage']:<10.1f} {metrics['simplified']['long_word_percentage']:<10.1f} {metrics['improvements']['long_word_percentage_reduction']:<10.1f}\")\n",
    "    print(f\"{'Type-Token Ratio':<25} {metrics['formal']['type_token_ratio']:<10.3f} {metrics['simplified']['type_token_ratio']:<10.3f} {'N/A':<10}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"{'-'*60}\")\n",
    "    print(f\"{'Educational Level':<25} {metrics['formal']['text_standard']:<25} {metrics['simplified']['text_standard']}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Usage in your explain_random_term function\n",
    "def explain_random_term():\n",
    "    random_term = random.choice(list(meddict.keys()))\n",
    "    formal_definition = f\"{random_term} is {meddict[random_term]}\"\n",
    "    explanation = explain_medical_term(random_term)\n",
    "    \n",
    "    # Print comprehensive analysis\n",
    "    metrics = print_readability_analysis(random_term, formal_definition, explanation)\n",
    "    \n",
    "    return random_term, formal_definition, explanation, metrics\n",
    "\n",
    "# Test with a random term\n",
    "explain_random_term()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def csv_to_dict(file_path):\n",
    "    data_dict = {}\n",
    "    with open(file_path, mode='r', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            if len(row) >= 3: \n",
    "                key, value = row[1].strip(), row[2].strip()\n",
    "                data_dict[key] = value\n",
    "    return data_dict\n",
    "\n",
    "csv_file_path = 'easydef.csv' \n",
    "easydic = csv_to_dict(csv_file_path)\n",
    "csv_file_path = 'easydef2.csv' \n",
    "easydic2 = csv_to_dict(csv_file_path)\n",
    "\n",
    "easydic=easydic|easydic2\n",
    "len(easydic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['adolescents and young adults (AYA)', 'biomarker testing', 'biopsy', 'chromosome', 'clinical trial', 'ejaculate', 'fertility', 'fertility preservation', 'gene', 'genetic mutation', 'gynecologic oncologist', 'hormone', 'inherited mutation', 'in vitro fertilization (IVF)', 'medical oncologist', 'menopause', 'mutation', 'oncofertility', 'oncologist', 'oocyte preservation', 'ovarian suppression', 'ovary', 'pathologist', 'prognosis', 'psychosocial', 'psychosocial support', 'radiation oncologist', 'radiation therapy', 'recurrence', 'refractory cancer', 'relapse', 'reproductive system', 'semen', 'side effect', 'sperm', 'sperm aspiration', 'sperm banking', 'sperm count', 'stem cell transplant (SCT)', '3D-CRT', 'adenocarcinoma', 'adjuvant treatment', 'alveoli', 'board certified', 'body plethysmograph', 'bronchioli', 'bronchoscope', 'bronchoscopy', 'bronchus', 'cancer screening', 'cancer stage', 'carcinoma', 'chemistry profile', 'chemoimmunotherapy', 'chemoradiation', 'chemotherapy', 'chest wall', 'chronic obstructive pulmonary disease (COPD)', 'clinical stage', 'complete blood count (CBC)', 'computed tomography (CT)', 'contrast', 'diagnosis', 'endobronchial ultrasound (EBUS)', 'endoscopic ultrasound (EUS)', 'esophagus', 'external beam radiation therapy (EBRT)', 'FDA', 'FDG', 'four-dimensional computed tomography (4D-CT)', 'gas diffusion', 'immunotherapy', 'intensity-modulated radiation therapy (IMRT)', 'invasion', 'large-cell lung carcinoma', 'lobe', 'lobectomy', 'low-dose computed tomography (LDCT)', 'lymph node', 'magnetic resonance imaging (MRI)', 'mediastinoscopy', 'mediastinum', 'medical history', 'metastasis', 'navigational bronchoscopy', 'NCCN', 'neoadjuvant therapy', 'nodule', 'non-small cell lung cancer (NSCLC)', 'non-solid nodule', 'part-solid nodule', 'pathologic stage', 'physical exam', 'pneumonectomy', 'positron emission tomography (PET)', 'positron emission tomography/computed tomography (PET/CT)', 'primary tumor', 'proton therapy', 'pulmonary function tests', 'pulmonologist', 'radial endobronchial ultrasound (EBUS) bronchoscopy', 'respiratory system', 'robot-assisted thoracoscopic surgery (RATS)', 'ROSE', 'segmentectomy', 'sleeve lobectomy', 'small cell lung cancer', 'solid nodule', 'spirometry', 'squamous cell carcinoma', 'stereotactic ablative radiotherapy (SABR)', 'superior sulcus tumor', 'supportive care', 'surgery', 'surgical margin', 'survivorship care', 'thoracic radiologist', 'targeted therapy', 'thoracic surgeon', 'three-dimensional conformal radiation therapy (3D-CRT)', 'transthoracic needle aspiration (TTNA)', 'ultrasound', 'wedge resection', 'adjuvant therapy', 'adrenal gland', 'aggressive cancer', 'allergic reaction', 'anus', 'appendix', 'biochemical test', 'bronchopulmonary', 'cancer grade', 'carcinoid syndrome', 'carcinoid tumor', 'colon', 'cortisol', 'Cushing syndrome', 'deoxyribonucleic acid (DNA)', 'duodenum', 'endoscope', 'enucleation', 'first-line or front-line therapy', 'gastrin', 'gastrointestinal (GI) tract', 'genetic testing', 'glucagon', 'hereditary', 'hives', 'hypothalamus', 'ileum', 'imaging', 'immune system', 'insulin', 'jejunum', 'liver', 'lung', 'multiple endocrine neoplasia (MEN)', 'neoadjuvant treatment', 'neuroendocrine cells', 'neuroendocrine tumor (NET)', 'observation', 'palliative care', 'pancreas', 'pelvis', 'peptide receptor radionuclide therapy (PRRT)', 'pineal gland', 'pituitary gland', 'primary treatment', 'progression', 'prostate', 'radiation therapy (RT)', 'radiopharmaceutical', 'rectum', 'serotonin', 'somatostatin', 'somatostatin receptor (SSTR) scintigraphy', 'stomach', 'testicle', 'thymus', 'tumor marker', 'ulcer', 'vasoactive intestinal polypeptide (VIP)', 'x-ray', 'AJCC', 'biomarker', 'continuation maintenance', 'core needle biopsy', 'DNA', 'ECOG', 'gene rearrangement', 'immunohistochemistry (IHC)', 'maintenance therapy', 'NOS', 'performance status', 'pericardiocentesis', 'platinum-doublet chemotherapy', 'rapid on-site evaluation (ROSE)', 'small cell lung cancer (SCLC)', 'switch maintenance', 'trachea', 'VATS', 'ABCDE rule', 'advanced melanoma', 'anesthesia', 'asymmetry', 'best supportive care', 'BRAF mutations', 'Breslow thickness', 'broad-spectrum sunscreen', 'completion lymph node dissection (CLND)', 'computed tomography (CT) scan', 'dermal mitotic rate', 'dermatologist', 'dermis', 'distant metastasis', 'DNA (deoxyribonucleic acid)', 'epidermis', 'excision', 'excisional biopsy', 'fine-needle aspiration (FNA) biopsy', 'follow-up tests', 'general anesthesia', 'genes', 'infusion', 'in-transit metastases', 'lymphedema', 'lymph node basin', 'lymph vessels', 'microsatellites', 'resectable', 'sentinel lymph node biopsy (SLNB)', 'stereotactic radiosurgery (SRS)', 'sun protection factor (SPF)', 'talimogene laherparepvec (T-VEC)', 'tumor-infiltrating lymphocyte (TIL) therapy', 'ulceration', 'allogeneic hematopoietic cell transplant (allogenic HCT)', 'autologous hematopoietic cell transplant (autologous HCT)', 'biosimilar', 'bone marrow', 'bone marrow aspiration', 'bone marrow biopsy', 'complete response (CR)', 'flow cytometry (FCM)', 'fluorescence in situ hybridization (FISH)', 'gastroenterologist', 'H. pylori (Helicobacter pylori)', 'hematopathologist', 'hematopoietic cell transplant (HCT)', 'histology', 'human leukocyte antigen (HLA)', 'immunophenotyping', 'induction', 'involved-site radiation therapy (ISRT)', 'karyotype', 'lactate dehydrogenase (LDH)', 'lymph', 'lymphadenopathy', 'lymphatic system', 'lymphocyte', 'lymphoid', 'maintenance', 'monitoring', 'partial response (PR)', 'peripheral blood (PB)', 'platelet (PLT)', 'polymerase chain reaction (PCR)', 'recovery', 'red blood cell (RBC)', 'remission', 'spleen', 'splenectomy', 'translocation', 'tumor lysis syndrome (TLS)', 'white blood cell (WBC)', 'adrenal cortex', 'adrenalectomy', 'adrenocortical carcinoma (ACC)', 'Conn syndrome', 'genetic assessment', 'hypercortisolism', 'hypertension', 'paraganglioma', 'pheochromocytoma', 'primary aldosteronism', 'sporadic', 'Advanced-stage prostate cancer', 'Androgen deprivation therapy (ADT)', 'Anti-androgen', 'Castration', 'Computed tomography (CT)', 'Digital rectal exam', 'Early-stage prostate cancer', 'Enlarged prostate', 'Erectile dysfunction', 'External beam radiation therapy (EBRT)', 'Genetic mutation', 'Hormone therapy', 'Life expectancy', 'Luteinizing hormone-releasing hormone (LHRH) agonist', 'Lymphatic system', 'Lymph nodes', 'Metastasis', 'Metastatic prostate cancer', 'Observation', 'Orchiectomy', 'Palliative therapy', 'Pathologist', 'Pelvic lymph node dissection (PLND)', 'Positron emission tomography (PET)', 'Prostate-specific antigen (PSA)', 'Prostate-specific membrane antigen (PSMA)', 'PSA persistence', 'PSA recurrence', 'Radiation therapy', 'Radical prostatectomy', 'Recurrence', 'Regional prostate cancer', 'Risk factor', 'Seminal vesicles', 'Supportive care', 'Absolute neutrophil count (ANC)', 'Antibody', 'B cell', 'Blast', 'Blood stem cell', 'Lymph node', 'Neutrophil', 'Platelet (PLT)', 'Red blood cell (RBC)', 'T cell', 'Acute lymphoblastic leukemia (ALL)', 'Allogeneic', 'Autologous', 'BCR::ABL1 protein', 'Chemotherapy', 'Consolidation', 'Induction', 'Maintenance', 'Minimal residual disease (MRD)', 'Myelosuppression', 'Progression', 'Refractory', 'Regimen', 'Remission', 'Resistance', 'Subtype', 'Bone marrow biopsy', 'Bone marrow aspirate', 'Chromosomes', 'Contrast', 'Cytogenetics', 'Deoxyribonucleic acid (DNA)', 'Liver function test (LFT)', 'Polymerase chain reaction (PCR)', 'Scrotal ultrasound', 'Hematopoietic cell transplant (HCT)', 'Immunotherapy', 'Infusion', 'Radiation therapy (RT)', 'Targeted therapy', 'Steroid', 'Systemic therapy', 'Palliative care', 'Adolescent and young adult (AYA)', 'Bone marrow', 'Donor', 'Extramedullary', 'Gene', 'Hematologist', 'Hematopathologist', 'Human leukocyte antigen (HLA)', 'Oncologist', 'basal cell carcinoma', 'baseline', 'border irregularity', 'combination regimen', 'deep margin status', 'bacillus Calmette-Guérin (BCG)', 'bone scan', 'carcinoma in situ (CIS)', 'consolidation therapy', 'continent urinary reservoir', 'cystectomy', 'cystoscopy', 'dose-dense chemotherapy', 'hematuria', 'ileal conduit', 'intravesical therapy', 'local therapy', 'muscle-invasive', 'neobladder', 'non–muscle-invasive', 'radical cystectomy', 'resection', 'stage', 'surveillance', 'systemic therapy', 'transurethral resection of bladder tumor (TURBT)', 'trimodal therapy', 'ureters', 'ureteroscopy', 'urinary diversion', 'urine cytology', 'urogram', 'urothelial carcinoma', 'urothelium', 'Accelerated Partial Breast Irradiation (APBI)', 'Anti-estrogen', 'Areola', 'Aromatase Inhibitor (AI)', 'Axillary Lymph Node (ALN)', 'Axillary Lymph Node Dissection (ALND)', 'Bilateral Diagnostic Mammogram', 'Bilateral Oophorectomy', 'Biosimilar', 'Bone Mineral Density', 'Bone Scan', 'Boost', 'Breast-Conserving Surgery (BCS)', 'Breast Implant', 'Breast Reconstruction', 'Clinical Breast Exam (CBE)', 'Clinical Stage (c)', 'Core Needle Biopsy (CNB)', 'Ductal Carcinoma', 'Estrogen', 'Fine-Needle Aspiration (FNA)', 'Hormone Receptor-Positive Cancer (HR+)', 'CT scan', 'Diagnostic mammogram', 'MRI scan', 'PET scan', 'Endocrine therapy', 'Invasive breast cancer', 'Lumpectomy', 'Mammogram', 'Mastectomy', 'vacuum-assisted core biopsy (VACB)', 'volume displacement', 'whole breast radiation therapy (WBRT)', 'aphasia', 'B-cell aplasia', 'capillary leak syndrome', 'cerebral edema', 'chimeric antigen receptor (CAR) T-cell therapy', 'convulsive status epilepticus', 'corticosteroids', 'cytokine release syndrome (CRS)', 'delirium', 'hypogammaglobulinemia', 'hypotension', 'hypoxia', 'immune effector cell-associated hemophagocytic lymphohistiocytosis-like syndrome (IEC-HS)', 'immune effector cell-associated neurotoxicity syndrome (ICANS)', 'intravenous immunoglobulin (IVIG)', 'osmotic therapy', 'Risk Evaluation and Mitigation Strategy (REMS)', 'seizure', 'tocilizumab (Actemra)', 'vasopressor', 'abdomen', 'adenosquamous carcinoma', 'biomarkers', 'brachytherapy', 'cervical intraepithelial neoplasia (CIN)', 'cervix', 'cone biopsy', 'ectocervix', 'endocervix', 'extrafascial hysterectomy', 'fallopian tube', 'human papillomavirus (HPV)', 'lymph nodes', 'lymphovascular space invasion (LVSI)', 'modified radical hysterectomy', 'neuroendocrine carcinoma of the cervix (NECC)', 'neuropathy', 'oophoropexy', 'parametrium', 'pelvic exam', 'pelvic exenteration', 'platinum-based chemotherapy', 'radical hysterectomy', 'radiologist', 'squamo-columnar junction', 'surgical menopause', 'trachelectomy', 'uterus', 'vagina', 'Ablation', 'Adenocarcinoma', 'Adenoma', 'Biomarkers', 'CAPEOX', 'Carcinoembryonic antigen (CEA)', 'Carcinoma in situ', 'Colectomy', 'Colon', 'Colonoscopy', 'Colostomy', 'Embolization', 'Familial adenomatous polyposis (FAP)', 'FOLFIRI', 'FOLFIRINOX', 'FOLFOX', 'Interventional oncology/radiology', 'Large intestine (bowel)', 'Lymphadenectomy', 'Metastasectomy', 'Mismatch repair deficiency (dMMR)/high microsatellite instability (MSI-H)', 'Mismatch repair proficient (pMMR)/microsatellite stable (MSS)', 'POLE/POLD1 mutation', 'Polyp', 'Portal vein embolization', 'Stereotactic body radiation therapy (SBRT)', 'Unresectable', '', 'ablation', 'absolute neutrophil count', 'acute lymphoblastic leukemia', 'adenoma', 'adrenocortical carcinoma', 'stage IV prostate cancer', 'aggressive', 'AJCC staging system', 'allergic response', 'allogeneic', 'allogeneic stem cell transplant', 'androgen deprivation', 'antiandrogen', 'antibody', 'antiestrogen', 'areola', 'aromatase inhibitor', 'autologous', 'autologous stem cell transplant', 'axillary lymph node', 'axillary lymph node dissection', 'bacillus Calmette-Guérin', 'BCR::ABL1 fusion protein', 'diagnostic mammogram', 'oophorectomy', 'biosimilar drug', 'blast', 'blood stem cell', 'bone mineral density', 'BRAF gene', 'breast implant', 'breast reconstruction', 'breast-conserving surgery', 'sunscreen', 'bronchiole', 'grade', 'screening', 'CAPOX', 'carcinoembryonic antigen', 'carcinoma in situ', 'castration', 'cervical intraepithelial neoplasia', 'CAR T-cell therapy', 'chronic obstructive pulmonary disease', 'clinical breast exam', 'colectomy', 'colonoscopy', 'colostomy', 'combination therapy', 'complete blood count', 'complete response', 'lymph node dissection', 'computed tomography scan', 'continent reservoir', 'contrast material', 'cytogenetics', 'cytokine release syndrome', 'deoxyribonucleic acid', 'mitotic rate', 'digital rectal examination', 'donor', 'ductal carcinoma', 'NCI clinical trials cooperative group', 'ejaculation', 'embolization', 'endocrine therapy', 'endoscopic ultrasound', 'enlarged prostate', 'erectile dysfunction', 'estrogen', 'surgical excision', 'external beam radiation therapy', 'simple hysterectomy', 'familial adenomatous polyposis', '18F-fludeoxyglucose', 'fine-needle aspiration biopsy', 'first-line therapy', 'flow cytometry', 'fluorescence in situ hybridization', 'gastrointestinal tract', 'hematologist', 'stem cell transplant', 'hormone therapy', 'human leukocyte antigen', 'human papillomavirus', 'immunohistochemistry', 'in vitro fertilization', 'induction therapy', 'germline mutation', 'intensity-modulated radiation therapy', 'in-transit metastasis', 'intravenous immunoglobulin', 'intravesical chemotherapy', 'invasive cancer', 'invasive breast cancer', 'karyotyping', 'lactate dehydrogenase', 'large intestine', 'large cell carcinoma', 'liver function test', 'low-dose computed tomography', 'lumpectomy', 'LHRH agonist', 'lymphatic basin', 'lymph vessel', 'lymphadenectomy', 'magnetic resonance imaging', 'mammogram', 'mastectomy', 'metastasectomy', 'microsatellite', 'minimal residual disease', 'mismatch repair deficiency', 'monitor', 'MRI', 'multiple endocrine neoplasia syndrome', 'myelosuppression', 'neuroendocrine tumor', 'neuroendocrine', 'neutrophil', 'non-small cell lung cancer', 'oocyte cryopreservation', 'orchiectomy', 'palliative therapy', 'partial response', 'pathological staging', 'peptide receptor radionuclide therapy', 'peripheral blood', 'physical examination', 'platelet', 'polymerase chain reaction', 'polyp', 'positron emission tomography scan', 'positron emission tomography-computed tomography scan', 'prostate-specific antigen', 'prostate-specific membrane antigen', 'proton beam radiation therapy', 'pulmonary function test', 'radical prostatectomy', 'red blood cell', 'refractory', 'regimen', 'clinical resistance', 'risk factor', 'Rapid On-Site Evaluation (ROSE)', 'seminal vesicle', 'sentinel lymph node biopsy', 'somatostatin receptor scintigraphy', 'Spirometry', 'sporadic cancer', 'squamocolumnar junction', 'SABR', 'stereotactic body radiation therapy', 'stereotactic radiosurgery', 'steroid', 'cancer subtype', 'sun protection factor', 'pulmonary sulcus tumor', 'margin', 'survivorship care plan', 'talimogene laherparepvec', '3-dimensional conformal radiation therapy', 'tocilizumab', 'Transthoracic Needle Biopsy', 'tumor lysis syndrome', 'TIL therapy', 'unresectable', 'ureter', 'intravenous urogram', 'stage 0 transitional cell carcinoma in situ of the renal pelvis and ureter', 'vacuum-assisted core biopsy', 'vasoactive intestinal peptide', 'white blood cell'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easydic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharedmeddict={}\n",
    "for k in easydic.keys():\n",
    "# for k in ['adolescents and young adults (AYA)', 'biomarker testing', 'biopsy', 'chromosome', 'clinical trial']:\n",
    "    if k in meddict.keys():\n",
    "        sharedmeddict[k]=meddict[k]\n",
    "len(sharedmeddict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat import (flesch_kincaid_grade, flesch_reading_ease, \n",
    "                     smog_index, gunning_fog, dale_chall_readability_score,\n",
    "                     text_standard, syllable_count)\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Download NLTK resources (run once)\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "def comprehensive_readability_analysis(formal_text, simplified_text, term=None):\n",
    "    \"\"\"\n",
    "    Calculate multiple readability and complexity metrics for medical texts\n",
    "    \n",
    "    Args:\n",
    "        formal_text: The original medical definition\n",
    "        simplified_text: The simplified explanation\n",
    "        term: The medical term to exclude from analysis (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing all metrics and comparisons\n",
    "    \"\"\"\n",
    "    # Clean texts for analysis (remove the term if provided)\n",
    "    formal_clean = formal_text\n",
    "    simplified_clean = simplified_text\n",
    "    \n",
    "    if term:\n",
    "        term_variations = [term, term.lower(), term.capitalize()]\n",
    "        for variation in term_variations:\n",
    "            formal_clean = re.sub(r'\\b' + re.escape(variation) + r'\\b', '', formal_clean)\n",
    "            simplified_clean = re.sub(r'\\b' + re.escape(variation) + r'\\b', '', simplified_clean)\n",
    "        \n",
    "        # Clean up double spaces\n",
    "        formal_clean = ' '.join(formal_clean.split())\n",
    "        simplified_clean = ' '.join(simplified_clean.split())\n",
    "    \n",
    "    # Tokenize for word-level analysis\n",
    "    formal_words = word_tokenize(formal_clean.lower())\n",
    "    simplified_words = word_tokenize(simplified_clean.lower())\n",
    "    \n",
    "    # Calculate traditional readability metrics\n",
    "    metrics = {\n",
    "        \"formal\": {\n",
    "            \"fk_grade\": flesch_kincaid_grade(formal_clean),\n",
    "            \"flesch_ease\": flesch_reading_ease(formal_clean),\n",
    "            \"smog\": smog_index(formal_clean),\n",
    "            \"gunning_fog\": gunning_fog(formal_clean),\n",
    "            \"dale_chall\": dale_chall_readability_score(formal_clean),\n",
    "            \"text_standard\": text_standard(formal_clean),\n",
    "            \"word_count\": len(formal_words),\n",
    "            \"avg_word_length\": sum(len(word) for word in formal_words) / len(formal_words) if formal_words else 0,\n",
    "            \"avg_syllables_per_word\": syllable_count(formal_clean) / len(formal_words) if formal_words else 0,\n",
    "        },\n",
    "        \"simplified\": {\n",
    "            \"fk_grade\": flesch_kincaid_grade(simplified_clean),\n",
    "            \"flesch_ease\": flesch_reading_ease(simplified_clean),\n",
    "            \"smog\": smog_index(simplified_clean),\n",
    "            \"gunning_fog\": gunning_fog(simplified_clean),\n",
    "            \"dale_chall\": dale_chall_readability_score(simplified_clean),\n",
    "            \"text_standard\": text_standard(simplified_clean),\n",
    "            \"word_count\": len(simplified_words),\n",
    "            \"avg_word_length\": sum(len(word) for word in simplified_words) / len(simplified_words) if simplified_words else 0,\n",
    "            \"avg_syllables_per_word\": syllable_count(simplified_clean) / len(simplified_words) if simplified_words else 0,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Calculate lexical complexity measures\n",
    "    \n",
    "    # Type-Token Ratio (vocabulary diversity)\n",
    "    metrics[\"formal\"][\"type_token_ratio\"] = len(set(formal_words)) / len(formal_words) if formal_words else 0\n",
    "    metrics[\"simplified\"][\"type_token_ratio\"] = len(set(simplified_words)) / len(simplified_words) if simplified_words else 0\n",
    "    \n",
    "    # Long word percentage (words with 3+ syllables)\n",
    "    formal_long_words = sum(1 for word in formal_words if syllable_count(word) >= 3)\n",
    "    simplified_long_words = sum(1 for word in simplified_words if syllable_count(word) >= 3)\n",
    "    \n",
    "    metrics[\"formal\"][\"long_word_percentage\"] = formal_long_words / len(formal_words) * 100 if formal_words else 0\n",
    "    metrics[\"simplified\"][\"long_word_percentage\"] = simplified_long_words / len(simplified_words) * 100 if simplified_words else 0\n",
    "    \n",
    "    # Calculate improvements\n",
    "    metrics[\"improvements\"] = {\n",
    "        \"fk_grade_reduction\": metrics[\"formal\"][\"fk_grade\"] - metrics[\"simplified\"][\"fk_grade\"],\n",
    "        \"flesch_ease_improvement\": metrics[\"simplified\"][\"flesch_ease\"] - metrics[\"formal\"][\"flesch_ease\"],\n",
    "        \"smog_reduction\": metrics[\"formal\"][\"smog\"] - metrics[\"simplified\"][\"smog\"],\n",
    "        \"gunning_fog_reduction\": metrics[\"formal\"][\"gunning_fog\"] - metrics[\"simplified\"][\"gunning_fog\"],\n",
    "        \"dale_chall_reduction\": metrics[\"formal\"][\"dale_chall\"] - metrics[\"simplified\"][\"dale_chall\"],\n",
    "        \"word_length_reduction\": metrics[\"formal\"][\"avg_word_length\"] - metrics[\"simplified\"][\"avg_word_length\"],\n",
    "        \"syllable_reduction\": metrics[\"formal\"][\"avg_syllables_per_word\"] - metrics[\"simplified\"][\"avg_syllables_per_word\"],\n",
    "        \"long_word_percentage_reduction\": metrics[\"formal\"][\"long_word_percentage\"] - metrics[\"simplified\"][\"long_word_percentage\"],\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def get_readability_analysis_row(term, formal_definition, simplified_explanation):\n",
    "    \"\"\"\n",
    "    Get readability analysis as a row for a dataframe\n",
    "    \n",
    "    Args:\n",
    "        term: The medical term\n",
    "        formal_definition: The original medical definition\n",
    "        simplified_explanation: The simplified explanation\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing all metrics as a flat structure for dataframe row\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = comprehensive_readability_analysis(formal_definition, simplified_explanation, term)\n",
    "    \n",
    "    # Create a flat dictionary for the dataframe row\n",
    "    row = {\n",
    "        \"term\": term,\n",
    "        \"formal_definition\": formal_definition,\n",
    "        \"simplified_explanation\": simplified_explanation,\n",
    "        \n",
    "        # Formal metrics\n",
    "        \"formal_fk_grade\": metrics[\"formal\"][\"fk_grade\"],\n",
    "        \"formal_flesch_ease\": metrics[\"formal\"][\"flesch_ease\"],\n",
    "        \"formal_smog\": metrics[\"formal\"][\"smog\"],\n",
    "        \"formal_gunning_fog\": metrics[\"formal\"][\"gunning_fog\"],\n",
    "        \"formal_dale_chall\": metrics[\"formal\"][\"dale_chall\"],\n",
    "        \"formal_text_standard\": metrics[\"formal\"][\"text_standard\"],\n",
    "        \"formal_word_count\": metrics[\"formal\"][\"word_count\"],\n",
    "        \"formal_avg_word_length\": metrics[\"formal\"][\"avg_word_length\"],\n",
    "        \"formal_avg_syllables_per_word\": metrics[\"formal\"][\"avg_syllables_per_word\"],\n",
    "        \"formal_type_token_ratio\": metrics[\"formal\"][\"type_token_ratio\"],\n",
    "        \"formal_long_word_percentage\": metrics[\"formal\"][\"long_word_percentage\"],\n",
    "        \n",
    "        # Simplified metrics\n",
    "        \"simplified_fk_grade\": metrics[\"simplified\"][\"fk_grade\"],\n",
    "        \"simplified_flesch_ease\": metrics[\"simplified\"][\"flesch_ease\"],\n",
    "        \"simplified_smog\": metrics[\"simplified\"][\"smog\"],\n",
    "        \"simplified_gunning_fog\": metrics[\"simplified\"][\"gunning_fog\"],\n",
    "        \"simplified_dale_chall\": metrics[\"simplified\"][\"dale_chall\"],\n",
    "        \"simplified_text_standard\": metrics[\"simplified\"][\"text_standard\"],\n",
    "        \"simplified_word_count\": metrics[\"simplified\"][\"word_count\"],\n",
    "        \"simplified_avg_word_length\": metrics[\"simplified\"][\"avg_word_length\"],\n",
    "        \"simplified_avg_syllables_per_word\": metrics[\"simplified\"][\"avg_syllables_per_word\"],\n",
    "        \"simplified_type_token_ratio\": metrics[\"simplified\"][\"type_token_ratio\"],\n",
    "        \"simplified_long_word_percentage\": metrics[\"simplified\"][\"long_word_percentage\"],\n",
    "        \n",
    "        # Improvements\n",
    "        \"improvement_fk_grade\": metrics[\"improvements\"][\"fk_grade_reduction\"],\n",
    "        \"improvement_flesch_ease\": metrics[\"improvements\"][\"flesch_ease_improvement\"],\n",
    "        \"improvement_smog\": metrics[\"improvements\"][\"smog_reduction\"],\n",
    "        \"improvement_gunning_fog\": metrics[\"improvements\"][\"gunning_fog_reduction\"],\n",
    "        \"improvement_dale_chall\": metrics[\"improvements\"][\"dale_chall_reduction\"],\n",
    "        \"improvement_word_length\": metrics[\"improvements\"][\"word_length_reduction\"],\n",
    "        \"improvement_syllables\": metrics[\"improvements\"][\"syllable_reduction\"],\n",
    "        \"improvement_long_word_percentage\": metrics[\"improvements\"][\"long_word_percentage_reduction\"],\n",
    "    }\n",
    "    \n",
    "    return row\n",
    "\n",
    "def explain_all_terms(meddict, explain_medical_term_func, output_file=\"readability_resultsv2.pkl\"):\n",
    "    \"\"\"\n",
    "    Analyze all terms in the medical dictionary and save results to a pickle file\n",
    "    \n",
    "    Args:\n",
    "        meddict: Dictionary of medical terms and their definitions\n",
    "        explain_medical_term_func: Function that generates simplified explanations\n",
    "        output_file: Path to save the results pickle file\n",
    "    \"\"\"\n",
    "    # Create empty list to store results\n",
    "    results = []\n",
    "    \n",
    "    # Create empty dataframe\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Get timestamp for unique backup files\n",
    "    timestamp = int(time.time())\n",
    "    \n",
    "    # Total number of terms\n",
    "    total_terms = len(meddict)\n",
    "    print(f\"Starting analysis of {total_terms} terms...\")\n",
    "    \n",
    "    # Function to print progress bar\n",
    "    def print_progress_bar(iteration, total, prefix='Progress:', suffix='Complete', length=50, fill='█'):\n",
    "        percent = (\"{0:.1f}\").format(100 * (iteration / float(total)))\n",
    "        filled_length = int(length * iteration // total)\n",
    "        bar = fill * filled_length + '-' * (length - filled_length)\n",
    "        sys.stdout.write(f'\\r{prefix} |{bar}| {percent}% {suffix} ({iteration}/{total})')\n",
    "        sys.stdout.flush()\n",
    "        # Print new line on complete\n",
    "        if iteration == total:\n",
    "            print()\n",
    "    \n",
    "    # Initialize progress bar\n",
    "    print_progress_bar(0, total_terms)\n",
    "    \n",
    "    # Process each term\n",
    "    for i, (term, definition) in enumerate(meddict.items()):\n",
    "        try:\n",
    "            # Generate formal definition and simplified explanation\n",
    "            formal_definition = f\"{term} is {definition}\"\n",
    "            simplified_explanation = explain_medical_term_func(term)\n",
    "            \n",
    "            # Get analysis as a row\n",
    "            row = get_readability_analysis_row(term, formal_definition, simplified_explanation)\n",
    "            \n",
    "            # Append to results\n",
    "            results.append(row)\n",
    "            \n",
    "            # Update dataframe\n",
    "            df = pd.DataFrame(results)\n",
    "            \n",
    "            # Save after each term (for robustness)\n",
    "            df.to_pickle(output_file)\n",
    "            \n",
    "            # Create a backup every 10 terms\n",
    "            if (i + 1) % 10 == 0:\n",
    "                backup_file = f\"readability_results_backup_{timestamp}_{i+1}.pkl\"\n",
    "                df.to_pickle(backup_file)\n",
    "                print(f\"\\nBackup saved to {backup_file}\")\n",
    "            \n",
    "            # Update progress bar\n",
    "            print_progress_bar(i + 1, total_terms)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing term '{term}': {str(e)}\")\n",
    "            # Save current results before continuing\n",
    "            if results:\n",
    "                error_backup = f\"readability_results_error_{timestamp}.pkl\"\n",
    "                pd.DataFrame(results).to_pickle(error_backup)\n",
    "                print(f\"\\nError encountered! Saved progress before error to {error_backup}\")\n",
    "    \n",
    "    # Final save\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_pickle(output_file)\n",
    "    \n",
    "    print(f\"Analysis complete. Results saved to {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage example:\n",
    "# First, make sure meddict and explain_medical_term are defined\n",
    "# meddict = {...}  # Your medical dictionary\n",
    "# Then run:\n",
    "# results_df = explain_all_terms(meddict, explain_medical_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis of 374 terms...\n",
      "Progress: |█-------------------------------------------------| 2.4% Complete (9/374)\n",
      "Backup saved to readability_results_backup_1742481931_10.pkl\n",
      "Progress: |██------------------------------------------------| 5.1% Complete (19/374)\n",
      "Backup saved to readability_results_backup_1742481931_20.pkl\n",
      "Progress: |███-----------------------------------------------| 7.8% Complete (29/374)\n",
      "Backup saved to readability_results_backup_1742481931_30.pkl\n",
      "Progress: |█████---------------------------------------------| 10.4% Complete (39/374)\n",
      "Backup saved to readability_results_backup_1742481931_40.pkl\n",
      "Progress: |██████--------------------------------------------| 13.1% Complete (49/374)\n",
      "Backup saved to readability_results_backup_1742481931_50.pkl\n",
      "Progress: |███████-------------------------------------------| 15.8% Complete (59/374)\n",
      "Backup saved to readability_results_backup_1742481931_60.pkl\n",
      "Progress: |█████████-----------------------------------------| 18.4% Complete (69/374)\n",
      "Backup saved to readability_results_backup_1742481931_70.pkl\n",
      "Progress: |██████████----------------------------------------| 21.1% Complete (79/374)\n",
      "Backup saved to readability_results_backup_1742481931_80.pkl\n",
      "Progress: |███████████---------------------------------------| 23.8% Complete (89/374)\n",
      "Backup saved to readability_results_backup_1742481931_90.pkl\n",
      "Progress: |█████████████-------------------------------------| 26.5% Complete (99/374)\n",
      "Backup saved to readability_results_backup_1742481931_100.pkl\n",
      "Progress: |██████████████------------------------------------| 29.1% Complete (109/374)\n",
      "Backup saved to readability_results_backup_1742481931_110.pkl\n",
      "Progress: |███████████████-----------------------------------| 31.8% Complete (119/374)\n",
      "Backup saved to readability_results_backup_1742481931_120.pkl\n",
      "Progress: |█████████████████---------------------------------| 34.5% Complete (129/374)\n",
      "Backup saved to readability_results_backup_1742481931_130.pkl\n",
      "Progress: |██████████████████--------------------------------| 37.2% Complete (139/374)\n",
      "Backup saved to readability_results_backup_1742481931_140.pkl\n",
      "Progress: |███████████████████-------------------------------| 39.8% Complete (149/374)\n",
      "Backup saved to readability_results_backup_1742481931_150.pkl\n",
      "Progress: |█████████████████████-----------------------------| 42.5% Complete (159/374)\n",
      "Backup saved to readability_results_backup_1742481931_160.pkl\n",
      "Progress: |██████████████████████----------------------------| 45.2% Complete (169/374)\n",
      "Backup saved to readability_results_backup_1742481931_170.pkl\n",
      "Progress: |███████████████████████---------------------------| 47.9% Complete (179/374)\n",
      "Backup saved to readability_results_backup_1742481931_180.pkl\n",
      "Progress: |█████████████████████████-------------------------| 50.5% Complete (189/374)\n",
      "Backup saved to readability_results_backup_1742481931_190.pkl\n",
      "Progress: |██████████████████████████------------------------| 53.2% Complete (199/374)\n",
      "Backup saved to readability_results_backup_1742481931_200.pkl\n",
      "Progress: |███████████████████████████-----------------------| 55.9% Complete (209/374)\n",
      "Backup saved to readability_results_backup_1742481931_210.pkl\n",
      "Progress: |█████████████████████████████---------------------| 58.6% Complete (219/374)\n",
      "Backup saved to readability_results_backup_1742481931_220.pkl\n",
      "Progress: |██████████████████████████████--------------------| 61.2% Complete (229/374)\n",
      "Backup saved to readability_results_backup_1742481931_230.pkl\n",
      "Progress: |███████████████████████████████-------------------| 63.9% Complete (239/374)\n",
      "Backup saved to readability_results_backup_1742481931_240.pkl\n",
      "Progress: |█████████████████████████████████-----------------| 66.6% Complete (249/374)\n",
      "Backup saved to readability_results_backup_1742481931_250.pkl\n",
      "Progress: |██████████████████████████████████----------------| 69.3% Complete (259/374)\n",
      "Backup saved to readability_results_backup_1742481931_260.pkl\n",
      "Progress: |███████████████████████████████████---------------| 71.9% Complete (269/374)\n",
      "Backup saved to readability_results_backup_1742481931_270.pkl\n",
      "Progress: |█████████████████████████████████████-------------| 74.6% Complete (279/374)\n",
      "Backup saved to readability_results_backup_1742481931_280.pkl\n",
      "Progress: |██████████████████████████████████████------------| 77.3% Complete (289/374)\n",
      "Backup saved to readability_results_backup_1742481931_290.pkl\n",
      "Progress: |███████████████████████████████████████-----------| 79.9% Complete (299/374)\n",
      "Backup saved to readability_results_backup_1742481931_300.pkl\n",
      "Progress: |█████████████████████████████████████████---------| 82.6% Complete (309/374)\n",
      "Backup saved to readability_results_backup_1742481931_310.pkl\n",
      "Progress: |██████████████████████████████████████████--------| 85.3% Complete (319/374)\n",
      "Backup saved to readability_results_backup_1742481931_320.pkl\n",
      "Progress: |███████████████████████████████████████████-------| 88.0% Complete (329/374)\n",
      "Backup saved to readability_results_backup_1742481931_330.pkl\n",
      "Progress: |█████████████████████████████████████████████-----| 90.6% Complete (339/374)\n",
      "Backup saved to readability_results_backup_1742481931_340.pkl\n",
      "Progress: |██████████████████████████████████████████████----| 93.3% Complete (349/374)\n",
      "Backup saved to readability_results_backup_1742481931_350.pkl\n",
      "Progress: |███████████████████████████████████████████████---| 96.0% Complete (359/374)\n",
      "Backup saved to readability_results_backup_1742481931_360.pkl\n",
      "Progress: |█████████████████████████████████████████████████-| 98.7% Complete (369/374)\n",
      "Backup saved to readability_results_backup_1742481931_370.pkl\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete (374/374)\n",
      "Analysis complete. Results saved to readability_resultsv2.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>formal_definition</th>\n",
       "      <th>simplified_explanation</th>\n",
       "      <th>formal_fk_grade</th>\n",
       "      <th>formal_flesch_ease</th>\n",
       "      <th>formal_smog</th>\n",
       "      <th>formal_gunning_fog</th>\n",
       "      <th>formal_dale_chall</th>\n",
       "      <th>formal_text_standard</th>\n",
       "      <th>formal_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>simplified_type_token_ratio</th>\n",
       "      <th>simplified_long_word_percentage</th>\n",
       "      <th>improvement_fk_grade</th>\n",
       "      <th>improvement_flesch_ease</th>\n",
       "      <th>improvement_smog</th>\n",
       "      <th>improvement_gunning_fog</th>\n",
       "      <th>improvement_dale_chall</th>\n",
       "      <th>improvement_word_length</th>\n",
       "      <th>improvement_syllables</th>\n",
       "      <th>improvement_long_word_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biomarker testing</td>\n",
       "      <td>biomarker testing is A laboratory method that ...</td>\n",
       "      <td>Biomarker testing is a way for doctors to chec...</td>\n",
       "      <td>11.5</td>\n",
       "      <td>55.58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>13.60</td>\n",
       "      <td>9.30</td>\n",
       "      <td>11th and 12th grade</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>2.020202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.44</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.71</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.082504</td>\n",
       "      <td>0.106245</td>\n",
       "      <td>7.468849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>biopsy is The removal of cells or tissues for ...</td>\n",
       "      <td>Biopsy is when a doctor takes a small piece of...</td>\n",
       "      <td>10.2</td>\n",
       "      <td>53.51</td>\n",
       "      <td>12.5</td>\n",
       "      <td>11.61</td>\n",
       "      <td>8.69</td>\n",
       "      <td>8th and 9th grade</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>6.410256</td>\n",
       "      <td>3.4</td>\n",
       "      <td>25.08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.122711</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>6.288156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chromosome</td>\n",
       "      <td>chromosome is Part of a cell that contains gen...</td>\n",
       "      <td>Chromosomes are like the instruction manuals i...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>61.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.03</td>\n",
       "      <td>7th and 8th grade</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>15.853659</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-7.92</td>\n",
       "      <td>-13.4</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.238070</td>\n",
       "      <td>-0.005832</td>\n",
       "      <td>-2.810180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clinical trial</td>\n",
       "      <td>clinical trial is A type of research study tha...</td>\n",
       "      <td>Clinical trials are research studies that test...</td>\n",
       "      <td>7.7</td>\n",
       "      <td>60.01</td>\n",
       "      <td>10.5</td>\n",
       "      <td>10.40</td>\n",
       "      <td>10.70</td>\n",
       "      <td>10th and 11th grade</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.41</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>5.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fertility</td>\n",
       "      <td>fertility is The ability to produce children.</td>\n",
       "      <td>Fertility refers to the ability of an individu...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>48.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.07</td>\n",
       "      <td>9.20</td>\n",
       "      <td>7th and 8th grade</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>13.043478</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-6.06</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>-0.192547</td>\n",
       "      <td>0.064182</td>\n",
       "      <td>1.242236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>intravenous urogram</td>\n",
       "      <td>intravenous urogram is An x-ray image of the k...</td>\n",
       "      <td>An intravenous urogram is a special kind of X-...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>61.06</td>\n",
       "      <td>11.2</td>\n",
       "      <td>10.88</td>\n",
       "      <td>10.33</td>\n",
       "      <td>10th and 11th grade</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>2.061856</td>\n",
       "      <td>1.1</td>\n",
       "      <td>13.67</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.115651</td>\n",
       "      <td>7.029053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>stage 0 transitional cell carcinoma in situ of...</td>\n",
       "      <td>stage 0 transitional cell carcinoma in situ of...</td>\n",
       "      <td>Stage 0 transitional cell carcinoma in situ of...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>60.04</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.29</td>\n",
       "      <td>8.31</td>\n",
       "      <td>9th and 10th grade</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>10.909091</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.94</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>-0.386576</td>\n",
       "      <td>-0.036024</td>\n",
       "      <td>-3.432455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>vacuum-assisted core biopsy</td>\n",
       "      <td>vacuum-assisted core biopsy is A procedure in ...</td>\n",
       "      <td>A vacuum-assisted core biopsy is when a doctor...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>66.33</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.76</td>\n",
       "      <td>8.84</td>\n",
       "      <td>8th and 9th grade</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>1.1</td>\n",
       "      <td>13.78</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.671892</td>\n",
       "      <td>0.239274</td>\n",
       "      <td>7.522002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>vasoactive intestinal peptide</td>\n",
       "      <td>vasoactive intestinal peptide is A hormone fou...</td>\n",
       "      <td>Vasoactive intestinal peptide (VIP) is a speci...</td>\n",
       "      <td>8.4</td>\n",
       "      <td>58.28</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.28</td>\n",
       "      <td>9.75</td>\n",
       "      <td>8th and 9th grade</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>10.101010</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>4.60</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.161506</td>\n",
       "      <td>0.023825</td>\n",
       "      <td>-2.492314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>white blood cell</td>\n",
       "      <td>white blood cell is A type of blood cell that ...</td>\n",
       "      <td>White blood cells are like tiny superheroes in...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>74.08</td>\n",
       "      <td>10.6</td>\n",
       "      <td>10.08</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8th and 9th grade</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635659</td>\n",
       "      <td>6.976744</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>2.07</td>\n",
       "      <td>-0.025306</td>\n",
       "      <td>-0.029022</td>\n",
       "      <td>2.940611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  term  \\\n",
       "0                                    biomarker testing   \n",
       "1                                               biopsy   \n",
       "2                                           chromosome   \n",
       "3                                       clinical trial   \n",
       "4                                            fertility   \n",
       "..                                                 ...   \n",
       "369                                intravenous urogram   \n",
       "370  stage 0 transitional cell carcinoma in situ of...   \n",
       "371                        vacuum-assisted core biopsy   \n",
       "372                      vasoactive intestinal peptide   \n",
       "373                                   white blood cell   \n",
       "\n",
       "                                     formal_definition  \\\n",
       "0    biomarker testing is A laboratory method that ...   \n",
       "1    biopsy is The removal of cells or tissues for ...   \n",
       "2    chromosome is Part of a cell that contains gen...   \n",
       "3    clinical trial is A type of research study tha...   \n",
       "4        fertility is The ability to produce children.   \n",
       "..                                                 ...   \n",
       "369  intravenous urogram is An x-ray image of the k...   \n",
       "370  stage 0 transitional cell carcinoma in situ of...   \n",
       "371  vacuum-assisted core biopsy is A procedure in ...   \n",
       "372  vasoactive intestinal peptide is A hormone fou...   \n",
       "373  white blood cell is A type of blood cell that ...   \n",
       "\n",
       "                                simplified_explanation  formal_fk_grade  \\\n",
       "0    Biomarker testing is a way for doctors to chec...             11.5   \n",
       "1    Biopsy is when a doctor takes a small piece of...             10.2   \n",
       "2    Chromosomes are like the instruction manuals i...              7.2   \n",
       "3    Clinical trials are research studies that test...              7.7   \n",
       "4    Fertility refers to the ability of an individu...              8.0   \n",
       "..                                                 ...              ...   \n",
       "369  An intravenous urogram is a special kind of X-...              9.4   \n",
       "370  Stage 0 transitional cell carcinoma in situ of...              9.8   \n",
       "371  A vacuum-assisted core biopsy is when a doctor...              7.3   \n",
       "372  Vasoactive intestinal peptide (VIP) is a speci...              8.4   \n",
       "373  White blood cells are like tiny superheroes in...              6.4   \n",
       "\n",
       "     formal_flesch_ease  formal_smog  formal_gunning_fog  formal_dale_chall  \\\n",
       "0                 55.58         12.3               13.60               9.30   \n",
       "1                 53.51         12.5               11.61               8.69   \n",
       "2                 61.33          0.0               10.00              12.03   \n",
       "3                 60.01         10.5               10.40              10.70   \n",
       "4                 48.47          0.0                9.07               9.20   \n",
       "..                  ...          ...                 ...                ...   \n",
       "369               61.06         11.2               10.88              10.33   \n",
       "370               60.04         10.4               10.29               8.31   \n",
       "371               66.33          9.6                8.76               8.84   \n",
       "372               58.28          9.3                8.28               9.75   \n",
       "373               74.08         10.6               10.08               9.12   \n",
       "\n",
       "    formal_text_standard  formal_word_count  ...  simplified_type_token_ratio  \\\n",
       "0    11th and 12th grade                137  ...                     0.717172   \n",
       "1      8th and 9th grade                126  ...                     0.717949   \n",
       "2      7th and 8th grade                 23  ...                     0.658537   \n",
       "3    10th and 11th grade                 40  ...                     0.833333   \n",
       "4      7th and 8th grade                  7  ...                     0.695652   \n",
       "..                   ...                ...  ...                          ...   \n",
       "369  10th and 11th grade                110  ...                     0.731959   \n",
       "370   9th and 10th grade                107  ...                     0.818182   \n",
       "371    8th and 9th grade                101  ...                     0.722222   \n",
       "372    8th and 9th grade                 92  ...                     0.676768   \n",
       "373    8th and 9th grade                121  ...                     0.635659   \n",
       "\n",
       "     simplified_long_word_percentage  improvement_fk_grade  \\\n",
       "0                           2.020202                   3.0   \n",
       "1                           6.410256                   3.4   \n",
       "2                          15.853659                  -3.0   \n",
       "3                           6.666667                  -0.6   \n",
       "4                          13.043478                  -4.4   \n",
       "..                               ...                   ...   \n",
       "369                         2.061856                   1.1   \n",
       "370                        10.909091                   1.2   \n",
       "371                         1.388889                   1.1   \n",
       "372                        10.101010                  -0.3   \n",
       "373                         6.976744                   0.2   \n",
       "\n",
       "     improvement_flesch_ease  improvement_smog  improvement_gunning_fog  \\\n",
       "0                      18.44               5.1                     3.71   \n",
       "1                      25.08               3.0                     2.19   \n",
       "2                      -7.92             -13.4                    -0.50   \n",
       "3                       9.10               0.8                    -0.01   \n",
       "4                      -6.06             -13.0                    -4.95   \n",
       "..                       ...               ...                      ...   \n",
       "369                    13.67               4.0                     1.24   \n",
       "370                     2.94              -0.8                     0.41   \n",
       "371                    13.78               3.6                     1.55   \n",
       "372                     4.60              -1.9                    -1.30   \n",
       "373                     5.93               1.0                     1.37   \n",
       "\n",
       "     improvement_dale_chall  improvement_word_length  improvement_syllables  \\\n",
       "0                      1.21                 0.082504               0.106245   \n",
       "1                      1.97                 0.122711               0.115385   \n",
       "2                      5.29                 0.238070              -0.005832   \n",
       "3                      1.41                -0.083333               0.041667   \n",
       "4                     -2.43                -0.192547               0.064182   \n",
       "..                      ...                      ...                    ...   \n",
       "369                    1.62                 0.218182               0.115651   \n",
       "370                   -0.89                -0.386576              -0.036024   \n",
       "371                    1.75                 0.671892               0.239274   \n",
       "372                    0.77                 0.161506               0.023825   \n",
       "373                    2.07                -0.025306              -0.029022   \n",
       "\n",
       "    improvement_long_word_percentage  \n",
       "0                           7.468849  \n",
       "1                           6.288156  \n",
       "2                          -2.810180  \n",
       "3                           5.833333  \n",
       "4                           1.242236  \n",
       "..                               ...  \n",
       "369                         7.029053  \n",
       "370                        -3.432455  \n",
       "371                         7.522002  \n",
       "372                        -2.492314  \n",
       "373                         2.940611  \n",
       "\n",
       "[374 rows x 33 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = explain_all_terms(sharedmeddict, explain_medical_term)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
