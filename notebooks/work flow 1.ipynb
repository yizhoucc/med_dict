{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503c81c2-012a-4e15-a255-a4a3e4c576d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece protobuf datasets transformers trl textstat peft bitsandbytes --quiet\n",
    "!pip install -U bitsandbytes accelerate --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c967d-ea35-4d4e-8ddc-f39328032b1a",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e3b7919-277b-47b9-95b9-eab518373862",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-party data and ML libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Hugging Face ecosystem\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "# Fine-tuning and optimization\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Text analysis and readability metrics\n",
    "from textstat import (\n",
    "    flesch_kincaid_grade, \n",
    "    flesch_reading_ease,\n",
    "    smog_index, \n",
    "    gunning_fog, \n",
    "    dale_chall_readability_score,\n",
    "    text_standard, \n",
    "    syllable_count\n",
    ")\n",
    "\n",
    "# Optional: Uncomment if needed\n",
    "from huggingface_hub import login\n",
    "login(token=\"\")  # Move token to environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd4555-473d-48cd-bc86-60a4c41da0a8",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d74a59c-b625-4944-8a79-aea69bc6cd8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c69ae230834d2e87b74967ba8fcbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5e2c4424b04016beeff8a877f76add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22ebfd449414c878c06ae4dcd18462e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92579d8eb024e8da7acf4250760512a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be88227c1aa840b794429780b47cde0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe4f339358d488b86a4ba2c39d975f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63596b0ebe9f4af7adce5f63de267009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63098a3702e549a1ac16e88fcf506e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0837c91f9554b0d9fab660e3852a21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df97ce3865b4dc5b2e3e6cd67011d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd33675059654d3a96ba704cbce084c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ae25e8ddcd486091c753eba6b8954e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Configuration\n",
    "# model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "# Recommended upgrade - Llama 3.1 8B\n",
    "# model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Or try Mistral 7B\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "# Load model with quantization\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=device_map,\n",
    "#     quantization_config=bnb_config\n",
    "# )\n",
    "\n",
    "# full precision\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map,\n",
    "    torch_dtype=torch.float16  # Use half precision instead\n",
    ")\n",
    "\n",
    "# # 8 precision\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=device_map,\n",
    "#     load_in_8bit=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1c388-57f9-41b0-87d1-25a9ad884430",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf6281f4-7ebb-48fd-a08b-4271349ededf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_readability_scores(text, term=None):\n",
    "    \"\"\"Calculate readability scores for a piece of text, optionally removing a term\"\"\"\n",
    "    scoring_text = text\n",
    "    \n",
    "    # Remove the term and its variations before scoring if provided\n",
    "    if term:\n",
    "        # Create variations of the term to remove (capitalized, lowercase)\n",
    "        term_variations = [term, term.lower(), term.capitalize()]\n",
    "        \n",
    "        for variation in term_variations:\n",
    "            scoring_text = scoring_text.replace(variation, \"\")\n",
    "        \n",
    "        # Clean up any double spaces created\n",
    "        scoring_text = \" \".join(scoring_text.split())\n",
    "    \n",
    "    fk_grade = flesch_kincaid_grade(scoring_text)\n",
    "    readability = flesch_reading_ease(scoring_text)\n",
    "    return {\n",
    "        \"fk_grade\": fk_grade,\n",
    "        \"readability\": readability,\n",
    "    }\n",
    "def txt_to_dict(file_path):\n",
    "    data_dict = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(0, len(lines) - 1, 2):\n",
    "            key = lines[i].strip()    # Odd line are key\n",
    "            value = lines[i + 1].strip()  # Even line are value\n",
    "            data_dict[key] = value\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "txt_file_path = 'formaldef.txt' \n",
    "formaldic = txt_to_dict(txt_file_path)\n",
    "len(formaldic)\n",
    "\n",
    "meddict={}\n",
    "for k,v in formaldic.items():\n",
    "    meddict[k.split('Listen to pronunciation')[0].split('(')[0]]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc3ba8-e388-43a3-b0d2-347f71c2b862",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34119805-0771-45a9-ac20-79e23affb9f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# promt, single term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7eb4e6f-2c30-4f9d-a79e-11efada26fe7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏥 Medical Term Explanation Demo\n",
      "==================================================\n",
      "\n",
      "1. Term: A33\n",
      "------------------------------\n",
      "A33 is a special kind of protein made in labs, similar to our immune system's natural defense against germs. It helps find and stick to cancer cells, like a magnet. This tool can help doctors detect or fight cancer more effectively.\n",
      "==================================================\n",
      "\n",
      "2. Term: A6\n",
      "------------------------------\n",
      "A6 is an experimental substance we're looking into for treating cancer. It's like a tiny part of a natural protein that helps break down blood clots. In simpler terms, it stops new blood vessels from growing (antiangiogenesis) and prevents cancer cells from spreading (antimetastatic). We call it urokinase plasminogen activator (uPA)-derived peptide A6.\n",
      "==================================================\n",
      "\n",
      "3. Term: Aap\n",
      "------------------------------\n",
      "The AAP, or alanine aminopeptidase, is an enzyme usually found in healthy kidneys. If you have issues with your kidneys, this enzyme might show up more than usual in your pee. Doctors use its presence to check for harm done to the kidneys from medicines or other substances. They also look for it to help diagnose some kidney and liver problems.\n",
      "==================================================\n",
      "\n",
      "4. Term: Aat Deficiency\n",
      "------------------------------\n",
      "Alpha-1 antitrypsin deficiency is a genetic condition where your body doesn't produce enough of a protective protein called alpha-1 antitrypsin, or it produces an incorrect version of it. This protein usually keeps our organs, particularly the liver and lungs, safe from harm. If you have this deficiency, you might develop serious lung diseases like emphysema and bronchiectasis, liver issues such as cirrhosis, hepatitis, and even liver cancer, and sometimes skin problems with painful lumps. The problem starts due to a change in a specific gene called SERPINA1. It's often known simply as alpha-1 antitrypsin deficiency.\n",
      "==================================================\n",
      "\n",
      "5. Term: Abarelix\n",
      "------------------------------\n",
      "Abarelix is a medicine used to lower testosterone levels in men with an advanced type of prostate cancer that doesn't respond well to other treatments. It works by blocking the body's natural signals that tell the testicles to produce testosterone, similar to how a stop sign stops cars from moving. This medication is known as Plenaxis.\n"
     ]
    }
   ],
   "source": [
    "# Medical Term Explanation System\n",
    "# Converts complex medical terminology into simple, accessible language\n",
    "\n",
    "# Improved prompt template with clearer instruction formatting\n",
    "explanation_template = \"\"\"<s>[INST] You are a medical educator who explains complex medical terms in simple language.\n",
    "\n",
    "Medical term: {term}\n",
    "Medical definition: {definition}\n",
    "\n",
    "Instructions:\n",
    "1. Explain this term using everyday language that anyone can understand\n",
    "2. Avoid all medical jargon and technical terms\n",
    "3. Write at a middle school reading level (grades 7-8)\n",
    "4. Keep it concise - maximum 3 short sentences\n",
    "5. Be medically accurate but accessible\n",
    "6. Start immediately with the explanation (no introductory phrases)\n",
    "\n",
    "[/INST]\"\"\"\n",
    "\n",
    "# Optimized generation parameters for clear, concise explanations\n",
    "generation_config = {\n",
    "    \"max_new_tokens\": 150,           # Reduced for concise responses\n",
    "    \"temperature\": 0.3,              # Lower for more consistent, focused output\n",
    "    \"top_p\": 0.85,                   # Slightly reduced for better coherence\n",
    "    \"repetition_penalty\": 1.15,      # Higher to avoid repetition\n",
    "    \"do_sample\": True,               # Enable sampling for natural language\n",
    "    \"pad_token_id\": tokenizer.eos_token_id  # Handle padding properly\n",
    "}\n",
    "\n",
    "def find_term_in_dict(term):\n",
    "    \"\"\"\n",
    "    Find a term in the medical dictionary using various case formats.\n",
    "    \n",
    "    Args:\n",
    "        term (str): The term to search for\n",
    "    \n",
    "    Returns:\n",
    "        str or None: The definition if found, None otherwise\n",
    "    \"\"\"\n",
    "    # Try different case formats\n",
    "    search_formats = [\n",
    "        term,                           # Original case\n",
    "        term.lower(),                   # lowercase\n",
    "        term.upper(),                   # UPPERCASE  \n",
    "        term.title(),                   # Title Case\n",
    "        term.capitalize(),              # Capitalized\n",
    "    ]\n",
    "    \n",
    "    for search_term in search_formats:\n",
    "        if search_term in meddict:\n",
    "            return meddict[search_term]\n",
    "    \n",
    "    # If still not found, try partial matching for terms with special characters\n",
    "    for key in meddict.keys():\n",
    "        if key.lower() == term.lower():\n",
    "            return meddict[key]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def explain_medical_term(term, definition=None):\n",
    "    \"\"\"\n",
    "    Generate a simple explanation for a medical term.\n",
    "    \n",
    "    Args:\n",
    "        term (str): The medical term to explain\n",
    "        definition (str, optional): Medical definition. If None, looks up in meddict\n",
    "    \n",
    "    Returns:\n",
    "        str: Simple explanation suitable for general audience\n",
    "    \"\"\"\n",
    "    # Look up definition if not provided\n",
    "    if definition is None:\n",
    "        definition = find_term_in_dict(term)\n",
    "        if definition is None:\n",
    "            return f\"❌ Term '{term}' not found in medical dictionary.\"\n",
    "    \n",
    "    # Create formatted prompt\n",
    "    prompt = explanation_template.format(term=term, definition=definition)\n",
    "    \n",
    "    try:\n",
    "        # Tokenize input\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "        \n",
    "        # Generate explanation\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                **generation_config\n",
    "            )\n",
    "        \n",
    "        # Decode and clean response\n",
    "        full_response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "        \n",
    "        # Extract just the explanation part\n",
    "        explanation = extract_explanation(full_response, prompt)\n",
    "        \n",
    "        return explanation.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"❌ Error generating explanation: {str(e)}\"\n",
    "\n",
    "def extract_explanation(full_response, prompt):\n",
    "    \"\"\"\n",
    "    Extract the model's explanation from the full response.\n",
    "    \n",
    "    Args:\n",
    "        full_response (str): Complete model output\n",
    "        prompt (str): Original prompt\n",
    "    \n",
    "    Returns:\n",
    "        str: Cleaned explanation text\n",
    "    \"\"\"\n",
    "    explanation = full_response\n",
    "    \n",
    "    # Remove the prompt part\n",
    "    if \"[/INST]\" in explanation:\n",
    "        explanation = explanation.split(\"[/INST]\", 1)[1]\n",
    "    else:\n",
    "        # Fallback: remove original prompt\n",
    "        explanation = explanation.replace(prompt, \"\")\n",
    "    \n",
    "    # Clean up special tokens and artifacts\n",
    "    cleanup_patterns = [\n",
    "        \"</s>\",\n",
    "        \"<s>\",\n",
    "        \"[INST]\",\n",
    "        \"[/INST]\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in cleanup_patterns:\n",
    "        explanation = explanation.replace(pattern, \"\")\n",
    "    \n",
    "    # Remove common response artifacts\n",
    "    artifacts = [\n",
    "        \"Here's the explanation:\",\n",
    "        \"Let me explain:\",\n",
    "        \"The explanation is:\",\n",
    "        \"Okay!\",\n",
    "        \"Sure!\",\n",
    "        \"Here's my explanation:\"\n",
    "    ]\n",
    "    \n",
    "    for artifact in artifacts:\n",
    "        if explanation.lower().startswith(artifact.lower()):\n",
    "            explanation = explanation[len(artifact):].strip()\n",
    "    \n",
    "    return explanation\n",
    "\n",
    "def demo_explanations(num_terms=5):\n",
    "    \"\"\"\n",
    "    Demonstrate the explanation system with sample medical terms.\n",
    "    \n",
    "    Args:\n",
    "        num_terms (int): Number of terms to demonstrate\n",
    "    \"\"\"\n",
    "    print(\"🏥 Medical Term Explanation Demo\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get sample terms that actually exist\n",
    "    available_terms = []\n",
    "    for term in list(meddict.keys())[:20]:  # Check more terms to find valid ones\n",
    "        if find_term_in_dict(term) is not None:\n",
    "            available_terms.append(term)\n",
    "        if len(available_terms) >= num_terms:\n",
    "            break\n",
    "    \n",
    "    if len(available_terms) == 0:\n",
    "        print(\"❌ No valid terms found in dictionary\")\n",
    "        return\n",
    "    \n",
    "    for i, term in enumerate(available_terms[:num_terms], 1):\n",
    "        print(f\"\\n{i}. Term: {term.title()}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        explanation = explain_medical_term(term)\n",
    "        print(f\"{explanation}\")\n",
    "        \n",
    "        if i < len(available_terms[:num_terms]):\n",
    "            print(\"=\" * 50)\n",
    "\n",
    "# Advanced function with readability scoring\n",
    "def explain_with_metrics(term, definition=None):\n",
    "    \"\"\"\n",
    "    Generate explanation with readability metrics.\n",
    "    \n",
    "    Args:\n",
    "        term (str): Medical term\n",
    "        definition (str, optional): Medical definition\n",
    "    \n",
    "    Returns:\n",
    "        dict: Explanation with readability scores\n",
    "    \"\"\"\n",
    "    explanation = explain_medical_term(term, definition)\n",
    "    \n",
    "    if explanation.startswith(\"❌\"):\n",
    "        return {\"explanation\": explanation, \"metrics\": None}\n",
    "    \n",
    "    # Calculate readability metrics\n",
    "    try:\n",
    "        metrics = {\n",
    "            \"flesch_reading_ease\": flesch_reading_ease(explanation),\n",
    "            \"flesch_kincaid_grade\": flesch_kincaid_grade(explanation),\n",
    "            \"word_count\": len(explanation.split()),\n",
    "            \"sentence_count\": explanation.count('.') + explanation.count('!') + explanation.count('?')\n",
    "        }\n",
    "        \n",
    "        # Determine reading level\n",
    "        grade_level = metrics[\"flesch_kincaid_grade\"]\n",
    "        if grade_level <= 8:\n",
    "            level_assessment = \"✅ Appropriate (Middle school level)\"\n",
    "        elif grade_level <= 10:\n",
    "            level_assessment = \"⚠️ Slightly high (Early high school)\"\n",
    "        else:\n",
    "            level_assessment = \"❌ Too complex (Advanced high school+)\"\n",
    "            \n",
    "        metrics[\"level_assessment\"] = level_assessment\n",
    "        \n",
    "    except Exception as e:\n",
    "        metrics = {\"error\": f\"Could not calculate metrics: {str(e)}\"}\n",
    "    \n",
    "    return {\n",
    "        \"explanation\": explanation,\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "# Run demonstration\n",
    "def debug_dictionary(sample_size=10):\n",
    "    \"\"\"\n",
    "    Debug function to examine the structure of meddict.\n",
    "    \n",
    "    Args:\n",
    "        sample_size (int): Number of sample keys to examine\n",
    "    \"\"\"\n",
    "    print(\"🔍 Medical Dictionary Debug Info\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    keys = list(meddict.keys())\n",
    "    print(f\"Total terms in dictionary: {len(keys)}\")\n",
    "    print(f\"\\nFirst {sample_size} keys:\")\n",
    "    \n",
    "    for i, key in enumerate(keys[:sample_size]):\n",
    "        print(f\"{i+1:2d}. '{key}' -> {len(meddict[key])} chars\")\n",
    "    \n",
    "    # Check for specific problematic terms\n",
    "    problematic_terms = ['A33', 'A6', 'AAP', 'AAT deficiency', 'abarelix']\n",
    "    print(f\"\\nChecking problematic terms:\")\n",
    "    \n",
    "    for term in problematic_terms:\n",
    "        result = find_term_in_dict(term)\n",
    "        if result:\n",
    "            print(f\"✅ Found '{term}': {result[:50]}...\")\n",
    "        else:\n",
    "            print(f\"❌ Not found: '{term}'\")\n",
    "            # Look for similar keys\n",
    "            similar = [k for k in keys if term.lower() in k.lower()][:3]\n",
    "            if similar:\n",
    "                print(f\"   Similar keys: {similar}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_explanations(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eefaba-320e-4774-afc9-48e7af43786c",
   "metadata": {},
   "source": [
    "chatgpt baseline.\n",
    "\n",
    "A33\n",
    "A33 is a protein found on the surface of certain cells in the intestines and some types of cancer. Doctors can target it to help find or treat these cancers. It acts like a flag that helps identify where the cancer cells are.\n",
    "\n",
    "A6\n",
    "A6 is a small part of a protein that can help stop cancer from spreading. It works by blocking signals that tell cancer cells to move. Scientists are studying it to see if it can be used as a treatment.\n",
    "\n",
    "AAP\n",
    "AAP stands for American Academy of Pediatrics. It’s a group of doctors who focus on keeping children healthy. They create guidelines to help parents and doctors care for kids.\n",
    "\n",
    "AAT deficiency\n",
    "AAT deficiency is a condition where the body doesn't make enough of a protein that protects the lungs. Without it, the lungs can get damaged more easily, especially by smoking or pollution. It can also affect the liver in some people.\n",
    "\n",
    "Abarelix\n",
    "Abarelix is a medicine that lowers certain hormones in the body. It is mainly used to treat prostate cancer by stopping the cancer from growing. It works by blocking signals from the brain that tell the body to make these hormones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a445b4-0a2b-45d1-9892-42f775ef20b8",
   "metadata": {},
   "source": [
    "# prompt, paragraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c2222c0-0f85-4ea9-abb3-283edb543491",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\"Admission Date:  [**2118-6-2**]       Discharge Date:  [**2118-6-14**]\n",
    "\n",
    "Date of Birth:                    Sex:  F\n",
    "\n",
    "Service:  MICU and then to [**Doctor Last Name **] Medicine\n",
    "\n",
    "HISTORY OF PRESENT ILLNESS:  This is an 81-year-old female\n",
    "with a history of emphysema (not on home O2), who presents\n",
    "with three days of shortness of breath thought by her primary\n",
    "care doctor to be a COPD flare.  Two days prior to admission,\n",
    "she was started on a prednisone taper and one day prior to\n",
    "admission she required oxygen at home in order to maintain\n",
    "oxygen saturation greater than 90%.  She has also been on\n",
    "levofloxacin and nebulizers, and was not getting better, and\n",
    "presented to the [**Hospital1 18**] Emergency Room.\n",
    "\n",
    "In the [**Hospital3 **] Emergency Room, her oxygen saturation was\n",
    "100% on CPAP.  She was not able to be weaned off of this\n",
    "despite nebulizer treatment and Solu-Medrol 125 mg IV x2.\n",
    "\n",
    "Review of systems is negative for the following:  Fevers,\n",
    "chills, nausea, vomiting, night sweats, change in weight,\n",
    "gastrointestinal complaints, neurologic changes, rashes,\n",
    "palpitations, orthopnea.  Is positive for the following:\n",
    "Chest pressure occasionally with shortness of breath with\n",
    "exertion, some shortness of breath that is positionally\n",
    "related, but is improved with nebulizer treatment.\n",
    "\n",
    "PAST MEDICAL HISTORY:\n",
    "1. COPD.  Last pulmonary function tests in [**2117-11-3**]\n",
    "demonstrated a FVC of 52% of predicted, a FEV1 of 54% of\n",
    "predicted, a MMF of 23% of predicted, and a FEV1:FVC ratio of\n",
    "67% of predicted, that does not improve with bronchodilator\n",
    "treatment.  The FVC, however, does significantly improve with\n",
    "bronchodilator treatment consistent with her known reversible\n",
    "air flow obstruction in addition to an underlying restrictive\n",
    "ventilatory defect.  The patient has never been on home\n",
    "oxygen prior to this recent episode.  She has never been on\n",
    "steroid taper or been intubated in the past.\n",
    "2. Lacunar CVA.  MRI of the head in [**2114-11-4**]\n",
    "demonstrates \"mild degree of multiple small foci of high T2\n",
    "signal within the white matter of both cerebral hemispheres\n",
    "as well as the pons, in the latter region predominantly to\n",
    "the right of midline.  The abnormalities, while nonspecific\n",
    "in etiology, are most likely secondary to chronic\n",
    "microvascular infarction.  There is no mass, lesion, shift of\n",
    "the normal midline strictures or hydrocephalus.  The major\n",
    "vascular flow patterns are preserved.  There is moderate\n",
    "right maxillary, moderate bilateral ethmoid, mild left\n",
    "maxillary, minimal right sphenoid, and frontal sinus mucosal\n",
    "thickening.  These abnormalities could represent an allergic\n",
    "or some other type of inflammatory process.  Additionally\n",
    "noted is a moderately enlarged subtotally empty sella\n",
    "turcica\".\n",
    "3. Angina:  Most recent stress test was in [**2118-1-3**]\n",
    "going for four minutes with a rate pressure product of\n",
    "10,000, 64% of maximum predicted heart rate without evidence\n",
    "of ischemic EKG changes or symptoms.  The imaging portion of\n",
    "the study demonstrated no evidence of myocardial ischemia and\n",
    "a calculated ejection fraction of 84%.  The patient denies\n",
    "angina at rest and gets angina with walking a few blocks.\n",
    "Are alleviated by sublingual nitroglycerin.\n",
    "4. Hypothyroidism on Synthroid.\n",
    "5. Depression on Lexapro.\n",
    "6. Motor vehicle accident with head injury approximately 10\n",
    "years ago.\n",
    "\n",
    "MEDICATIONS ON ADMISSION:\n",
    "1. Hydrochlorothiazide 25 q.d.\n",
    "2. Prednisone 60 mg, 50 mg, 40 mg, 20 mg.\n",
    "3. Levofloxacin 500 mg q.d.\n",
    "4. Imdur 60 mg q.d.\n",
    "5. Synthroid 75 mcg q.d.\n",
    "6. Pulmicort nebulizer b.i.d.\n",
    "7. Albuterol nebulizer q.4. prn.\n",
    "8. Lexapro 10 mg q.d.\n",
    "9. Protonix 40 mg q.d.\n",
    "10. Aspirin 81 mg q.d.\n",
    "\n",
    "ALLERGIES:  Norvasc leads to lightheadedness and headache.\n",
    "\n",
    "FAMILY HISTORY:  Noncontributory.\n",
    "\n",
    "SOCIAL HISTORY:  Lives with her husband, Dr. [**Known lastname 1809**] an\n",
    "eminent Pediatric Neurologist at [**Hospital3 1810**].  The\n",
    "patient is a prior smoker, but has not smoked in over 10\n",
    "years.  She has no known alcohol use and she is a full code.\n",
    "\n",
    "PHYSICAL EXAM AT TIME OF ADMISSION:  Blood pressure 142/76,\n",
    "heart rate 100 and regular, respirations at 17-21, and 97%\n",
    "axillary temperature.  She was saturating at 100% on CPAP\n",
    "with dry mucous membranes.  An elderly female in no apparent\n",
    "distress.  Pupils are equal, round, and reactive to light and\n",
    "accommodation.  Extraocular movements are intact.  Oropharynx\n",
    "difficult to assess due to CPAP machine.  No evidence of\n",
    "jugular venous pressure, however, the strap from the CPAP\n",
    "machine obscures the neck exam.  Cranial nerves II through\n",
    "XII are grossly intact.  Neck is supple without\n",
    "lymphadenopathy.  Heart exam:  Tachycardic, regular, obscured\n",
    "by loud bilateral wheezing with increase in the expiratory\n",
    "phase as well as profuse scattered rhonchi throughout the\n",
    "lung fields.  Positive bowel sounds, soft, nontender,\n",
    "nondistended, obese, no masses.  Mild edema of the lower\n",
    "extremities without clubbing or cyanosis, no rashes.  There\n",
    "is a right hand hematoma.  Strength is assessed as [**5-9**] in the\n",
    "lower extremities, [**5-9**] in the upper extremities with a normal\n",
    "mental status and cognition.\n",
    "\n",
    "LABORATORY STUDIES:  White count 19, hematocrit 41, platelets\n",
    "300.  Chem-7:  127, 3.6, 88, 29, 17, 0.6, 143.  Troponin was\n",
    "negative.  CKs were negative times three.  Initial blood gas\n",
    "showed a pH of 7.4, pO2 of 66, pCO2 of 54.\n",
    "\n",
    "Chest x-ray demonstrates a moderate sized hiatal hernia,\n",
    "segmental atelectasis, left lower lobe infiltrate versus\n",
    "segmental atelectasis.\n",
    "\n",
    "EKG shows normal sinus rhythm at 113 beats per minute, normal\n",
    "axis, no evidence of ST-T wave changes.\n",
    "\n",
    "BRIEF SUMMARY OF HOSPITAL COURSE:\n",
    "1. COPD/dyspnea/pneumonia:  The patient was initially placed\n",
    "on an aggressive steroid taper and admitted to the Medical\n",
    "Intensive Care Unit due to her difficulty with oxygenation\n",
    "despite CPAP machine.  She was also given nebulizer\n",
    "treatments q.4h. as well as chest PT.  The nebulizers were\n",
    "increased to q.1h. due to the fact that she continued to have\n",
    "labored breathing.\n",
    "\n",
    "Due to persistent respiratory failure and labored breathing,\n",
    "the patient was intubated on [**2118-6-7**] in order to improve\n",
    "oxygenation, ventilation, and ability to suction.  A\n",
    "bronchoscopy was performed on [**2118-6-7**], which demonstrated\n",
    "marked narrowing of the airways with expiration consistent\n",
    "with tracheomalacia.\n",
    "\n",
    "On [**2118-6-9**], two silicone stents were placed, one in the left\n",
    "main stem (12 x 25 and one in the trachea 16 x 40) by Dr.\n",
    "[**First Name (STitle) **] [**Name (STitle) **] under rigid bronchoscopy with general anesthesia.\n",
    "\n",
    "On [**2118-6-11**], the patient was extubated to a cool mist shovel\n",
    "mask and her oxygen was titrated down to 2 liters nasal\n",
    "cannula at which time she was transferred to the medical\n",
    "floor.  On the medical floor, the steroids were weaned to off\n",
    "on [**2118-6-14**], and the patient was saturating at 97% on 2\n",
    "liters, 92% on room air.\n",
    "\n",
    "On [**2118-6-14**], the patient was seen again by the Interventional\n",
    "Pulmonology service, who agreed that she looked much improved\n",
    "and recommended that she go to pulmonary rehabilitation with\n",
    "followup within six weeks' time status post placement of\n",
    "stents in respiratory failure.\n",
    "\n",
    "2. Cardiovascular:  The patient was ruled out for a MI.  She\n",
    "did have another episode on the medical floor of chest pain,\n",
    "which showed no evidence of EKG changes and negative\n",
    "troponin, negative CKs x3.  She was continued on aspirin,\n",
    "Imdur, and diltiazem for rate control per her outpatient\n",
    "regimen.\n",
    "\n",
    "3. Hypertension:  She was maintained on diltiazem and\n",
    "hydrochlorothiazide with adequate blood pressure control and\n",
    "normalization of electrolytes.\n",
    "\n",
    "4. Hematuria:  The patient had intermittent hematuria likely\n",
    "secondary to Foley placement.  The Foley catheter was\n",
    "discontinued on [**2118-6-14**].  She had serial urinalyses, which\n",
    "were all negative for signs of infection.\n",
    "\n",
    "5. Hyperglycemia:  Patient was placed on insulin-sliding\n",
    "scale due to hyperglycemia, which was steroid induced.  This\n",
    "worked quite well and her glucose came back to normal levels\n",
    "once the steroids were tapered to off.\n",
    "\n",
    "6. Leukocytosis:  Patient did have a profound leukocytosis of\n",
    "20 to 22 during much of her hospital course.  As the steroids\n",
    "were tapered to off, her white blood cell count on [**2118-6-14**]\n",
    "was 15,000.  It was felt that the leukocytosis was secondary\n",
    "to both steroids as well as question of a left lower lobe\n",
    "pneumonia.\n",
    "\n",
    "7. For the left lower lobe pneumonia, the patient had\n",
    "initially received a course of levofloxacin 500 p.o. q.d.\n",
    "from [**2118-6-4**] to [**2118-6-10**].  This was restarted on [**2118-6-12**]\n",
    "for an additional seven day course given the fact that she\n",
    "still had the leukocytosis and still had marked rales at the\n",
    "left lower lobe.\n",
    "\n",
    "8. Hypothyroidism:  The patient was continued on outpatient\n",
    "medical regimen.\n",
    "\n",
    "9. Depression:  The patient was continued on Lexapro per\n",
    "outpatient regimen.  It is recommended that she follow up\n",
    "with a therapist as an outpatient due to the fact that she\n",
    "did have a blunted affect throughout much of the hospital\n",
    "course, and did appear clinically to be depressed.\n",
    "\n",
    "10. Prophylaxis:  She was maintained on proton-pump inhibitor\n",
    "with subQ Heparin.\n",
    "\n",
    "11. Sore throat:  The patient did have a sore throat for much\n",
    "of the hospital course post extubation.  This was treated\n",
    "with Cepacol lozenges as well as KBL liquid (a solution\n",
    "containing Kaopectate, Bismuth, and lidocaine) at bedtime.\n",
    "\n",
    "12. Communication/code status:  The patient was full code\n",
    "throughout her hospital course, and communication was\n",
    "maintained with the patient and her husband.\n",
    "\n",
    "13. Muscle weakness:  The patient did have profound muscle\n",
    "weakness and was evaluated by Physical Therapy, and was found\n",
    "to have impaired functional mobility, impaired\n",
    "musculoskeletal performance, impaired gas exchange, impaired\n",
    "endurance, impaired ventilation, and needed help with supine\n",
    "to sit.  However, she was able to tolerate sitting in a chair\n",
    "for approximately one hour.\n",
    "\n",
    "On motor exam, her flexors and extensors of the lower\n",
    "extremities were [**4-8**] at the knee, [**4-8**] at the ankle, [**4-8**] at\n",
    "the elbows, and [**4-8**] hips.  It was felt that this weakness was\n",
    "most likely due to a combination of steroid myopathy as well\n",
    "as muscle atrophy secondary to deconditioning after a\n",
    "prolonged hospital course.\n",
    "\n",
    "14. Speech/swallow:  The patient had a Speech and Swallow\n",
    "evaluation showing no evidence of dysphagia, no evidence of\n",
    "vocal cord damage status post tracheal stent placement.\n",
    "\n",
    "DISCHARGE CONDITION:  The patient was able to oxygenate on\n",
    "room air at 93% at the time of discharge.  She was profoundly\n",
    "weak, but was no longer tachycardic and had a normal blood\n",
    "pressure.  Her respirations were much improved albeit with\n",
    "transmitted upper airway sounds.\n",
    "\n",
    "DISCHARGE STATUS:  The patient will be discharged to [**Hospital1 **]\n",
    "for both pulmonary and physical rehabilitation.\n",
    "\n",
    "DISCHARGE MEDICATIONS:\n",
    "1. Levothyroxine 75 mcg p.o. q.d.\n",
    "2. Citalopram 10 mg p.o. q.d.\n",
    "3. Aspirin 81 mg p.o. q.d.\n",
    "4. Fluticasone 110 mcg two puffs inhaled b.i.d.\n",
    "5. Salmeterol Diskus one inhalation b.i.d.\n",
    "6. Acetaminophen 325-650 mg p.o. q.4-6h. prn.\n",
    "7. Ipratropium bromide MDI two puffs inhaled q.2h. prn.\n",
    "8. Albuterol 1-2 puffs inhaled q.2h. prn.\n",
    "9. Zolpidem tartrate 5 mg p.o. q.h.s. prn.\n",
    "10. Isosorbide dinitrate 10 mg p.o. t.i.d.\n",
    "11. Diltiazem 60 mg p.o. q.i.d.\n",
    "12. Pantoprazole 40 mg p.o. q.24h.\n",
    "13. Trazodone 25 mg p.o. q.h.s. prn.\n",
    "14. SubQ Heparin 5000 units subcutaneous b.i.d. until such\n",
    "time that the patient is able to get out of bed twice a day.\n",
    "15. Cepacol lozenges q.2h. prn.\n",
    "16. Levofloxacin 500 mg p.o. q.d. for a seven day course to\n",
    "be completed on [**2118-6-21**].\n",
    "17. Kaopectate/Benadryl/lidocaine 5 mL p.o. b.i.d. prn, not\n",
    "to be given around mealtimes for concern of dysphagia induced\n",
    "by lidocaine.\n",
    "18. Lorazepam 0.5-2 mg IV q.6h. prn.\n",
    "\n",
    "FOLLOW-UP PLANS:  The patient is recommended to followup with\n",
    "Dr. [**First Name4 (NamePattern1) **] [**Last Name (NamePattern1) 1407**], [**Telephone/Fax (1) 1408**] within two weeks of leaving\n",
    "of the hospital.  She is also recommended to followup with\n",
    "the Interventional Pulmonary service for followup status post\n",
    "stent placement.  She is also recommended to followup with a\n",
    "neurologist if her muscle weakness does not improve within\n",
    "one week on physical therapy with concern for steroid-induced\n",
    "myopathy.\n",
    "\n",
    "FINAL DIAGNOSES:\n",
    "1. Tracheomalacia status post tracheal and left main stem\n",
    "bronchial stent placement.\n",
    "2. Hypertension.\n",
    "3. Hypothyroidism.\n",
    "4. Restrictive lung defect.\n",
    "5. Depression.\n",
    "\n",
    "\n",
    "                     DR.[**Last Name (STitle) **],[**First Name3 (LF) **] 12-207\n",
    "\n",
    "\n",
    "Dictated By:[**Last Name (NamePattern1) 1811**]\n",
    "MEDQUIST36\n",
    "\n",
    "D:  [**2118-6-14**]  11:30\n",
    "T:  [**2118-6-14**]  11:33\n",
    "JOB#:  [**Job Number 1812**]\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d5214f6-5ac9-4799-bc18-cfeb96d6deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 MODULAR MEDICAL EXPLANATION SYSTEM\n",
      "============================================================\n",
      "📋 Available Step Combinations:\n",
      "\n",
      "1️⃣ FULL PIPELINE - All steps (default)\n",
      "   result = explainer.explain_medical_text(text)\n",
      "   result = explainer.explain_medical_text(text, steps=['extract', 'generate', 'clean'])\n",
      "\n",
      "2️⃣ SKIP CLEANING - Raw model output\n",
      "   result = explainer.explain_medical_text(text, steps=['extract', 'generate'])\n",
      "\n",
      "3️⃣ ONLY EXTRACT - Just find medical terms\n",
      "   result = explainer.explain_medical_text(text, steps=['extract'])\n",
      "\n",
      "4️⃣ GENERATE ONLY - Skip extraction\n",
      "   result = explainer.explain_medical_text(text, steps=['generate'])\n",
      "\n",
      "5️⃣ CUSTOM PIPELINE - Generate then clean\n",
      "   result = explainer.explain_medical_text(text, steps=['generate', 'clean'])\n",
      "\n",
      "✅ BENEFITS:\n",
      "   • Run only the steps you need\n",
      "   • Debug individual steps\n",
      "   • Compare raw vs cleaned outputs\n",
      "   • Skip expensive cleaning for quick tests\n"
     ]
    }
   ],
   "source": [
    "# Modular Medical Text Explanation System\n",
    "# Returns clean dict with configurable steps: extract, generate, clean\n",
    "\n",
    "import re\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "class MedicalTextExplainer:\n",
    "    def __init__(self, model, tokenizer, meddict):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.meddict = meddict\n",
    "        \n",
    "        # Improved generation config for better outputs\n",
    "        self.generation_config = {\n",
    "            \"max_new_tokens\": 999,              # Increased for fuller explanations\n",
    "            \"temperature\": 0.3,\n",
    "            \"top_p\": 0.85,\n",
    "            \"repetition_penalty\": 1.15,\n",
    "            \"do_sample\": True,\n",
    "            \"pad_token_id\": tokenizer.eos_token_id,\n",
    "            \"eos_token_id\": tokenizer.eos_token_id,  # Ensure proper stopping\n",
    "            \"early_stopping\": True,              # Stop when EOS token is generated\n",
    "        }\n",
    "        \n",
    "        # Define available steps\n",
    "        self.available_steps = ['extract', 'generate', 'clean']\n",
    "        self.step_functions = {\n",
    "            'extract': self._step_extract_terms,\n",
    "            'generate': self._step_generate_explanation,\n",
    "            'clean': self._step_clean_response\n",
    "        }\n",
    "    \n",
    "    def explain_medical_text(self, text, steps=['extract', 'generate', 'clean']):\n",
    "        \"\"\"\n",
    "        Modular main function that runs configurable steps.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input medical text\n",
    "            steps (list): List of steps to run. Options: ['extract', 'generate', 'clean']\n",
    "                         - 'extract': Extract medical terms from text\n",
    "                         - 'generate': Generate explanation from model  \n",
    "                         - 'clean': Clean the raw output\n",
    "        \n",
    "        Returns:\n",
    "            dict: Contains results from each step that was run\n",
    "        \"\"\"\n",
    "        \n",
    "        # Validate steps\n",
    "        invalid_steps = [step for step in steps if step not in self.available_steps]\n",
    "        if invalid_steps:\n",
    "            raise ValueError(f\"Invalid steps: {invalid_steps}. Available steps: {self.available_steps}\")\n",
    "        \n",
    "        # Initialize result with original text\n",
    "        result = {\n",
    "            'original_text': text,\n",
    "            'steps_run': steps.copy(),\n",
    "            'available_steps': self.available_steps.copy()\n",
    "        }\n",
    "        \n",
    "        # Run each step in sequence, passing result between steps\n",
    "        for step in steps:\n",
    "            print(f\"🔄 Running step: {step}\")\n",
    "            result = self.step_functions[step](result)\n",
    "        \n",
    "        print(f\"✅ Completed {len(steps)} steps: {steps}\")\n",
    "        return result\n",
    "    \n",
    "    def _step_extract_terms(self, result):\n",
    "        \"\"\"Step 1: Extract medical terms from text.\"\"\"\n",
    "        text = result['original_text']\n",
    "        found_terms = self.extract_medical_terms(text)\n",
    "        \n",
    "        result.update({\n",
    "            'found_terms': found_terms,\n",
    "            'terms_count': len(found_terms)\n",
    "        })\n",
    "        \n",
    "        print(f\"   📋 Found {len(found_terms)} medical terms\")\n",
    "        return result\n",
    "    \n",
    "    def _step_generate_explanation(self, result):\n",
    "        \"\"\"Step 2: Generate explanation using model.\"\"\"\n",
    "        text = result['original_text']\n",
    "        \n",
    "        # Use found terms if extract step was run, otherwise extract them now\n",
    "        if 'found_terms' in result:\n",
    "            found_terms = result['found_terms']\n",
    "        else:\n",
    "            print(\"   ⚠️  Terms not extracted yet, extracting now...\")\n",
    "            found_terms = self.extract_medical_terms(text)\n",
    "            result['found_terms'] = found_terms\n",
    "        \n",
    "        # Create prompt and generate\n",
    "        prompt = self.create_prompt(text, found_terms)\n",
    "        raw_output = self._generate_raw_response(prompt)\n",
    "        \n",
    "        result.update({\n",
    "            'prompt': prompt,\n",
    "            'raw_output': raw_output,\n",
    "            'prompt_length': len(prompt),\n",
    "            'raw_output_length': len(raw_output)\n",
    "        })\n",
    "        \n",
    "        print(f\"   🤖 Generated {len(raw_output)} character response\")\n",
    "        return result\n",
    "    \n",
    "    def _step_clean_response(self, result):\n",
    "        \"\"\"Step 3: Clean the raw model output.\"\"\"\n",
    "        \n",
    "        # Check if we have raw output to clean\n",
    "        if 'raw_output' not in result:\n",
    "            raise ValueError(\"No raw_output found. Must run 'generate' step before 'clean' step.\")\n",
    "        \n",
    "        raw_output = result['raw_output']\n",
    "        original_prompt = result.get('prompt', '')\n",
    "        \n",
    "        # Clean the response\n",
    "        cleaned_output = self.model_clean_response(raw_output, original_prompt)\n",
    "        cleaning_prompt = self.create_cleaning_prompt(raw_output, original_prompt)\n",
    "        \n",
    "        result.update({\n",
    "            'cleaning_prompt': cleaning_prompt,\n",
    "            'cleaned_output': cleaned_output,\n",
    "            'cleaned_length': len(cleaned_output)\n",
    "        })\n",
    "        \n",
    "        print(f\"   🧹 Cleaned to {len(cleaned_output)} characters\")\n",
    "        return result\n",
    "    \n",
    "    def extract_medical_terms(self, text):\n",
    "        \"\"\"\n",
    "        Enhanced medical term extraction to catch more terms from complex texts.\n",
    "        \"\"\"\n",
    "        found_terms = {}\n",
    "        \n",
    "        # Strategy 1: Single words (improved regex for medical terms)\n",
    "        words = re.findall(r'\\b[A-Za-z]+(?:[-\\'][A-Za-z]+)*\\b', text)\n",
    "        for word in words:\n",
    "            definition = self.find_term_in_dict(word)\n",
    "            if definition:\n",
    "                found_terms[word] = definition\n",
    "        \n",
    "        # Strategy 2: Multi-word terms (expanded range for complex medical phrases)\n",
    "        for n in range(2, 6):  # Increased from 5 to 6 for longer medical phrases\n",
    "            n_grams = self.get_n_grams(text, n)\n",
    "            for phrase in n_grams:\n",
    "                definition = self.find_term_in_dict(phrase)\n",
    "                if definition:\n",
    "                    found_terms[phrase] = definition\n",
    "        \n",
    "        # Strategy 3: Medical abbreviations (enhanced pattern)\n",
    "        abbreviations = re.findall(r'\\b[A-Z]{2,8}\\b', text)  # Increased from 6 to 8\n",
    "        for abbrev in abbreviations:\n",
    "            definition = self.find_term_in_dict(abbrev)\n",
    "            if definition:\n",
    "                found_terms[abbrev] = definition\n",
    "        \n",
    "        # Strategy 4: Medical procedures and conditions with specific patterns\n",
    "        medical_patterns = [\n",
    "            r'\\b\\w+oscopy\\b',          # bronchoscopy, endoscopy, etc.\n",
    "            r'\\b\\w+ectomy\\b',          # appendectomy, etc.\n",
    "            r'\\b\\w+itis\\b',            # bronchitis, arthritis, etc.\n",
    "            r'\\b\\w+osis\\b',            # fibrosis, stenosis, etc.\n",
    "            r'\\b\\w+emia\\b',            # anemia, septicemia, etc.\n",
    "            r'\\b\\w+pathy\\b',           # myopathy, neuropathy, etc.\n",
    "            r'\\b\\w+malacia\\b',         # tracheomalacia, etc.\n",
    "        ]\n",
    "        \n",
    "        for pattern in medical_patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                definition = self.find_term_in_dict(match)\n",
    "                if definition:\n",
    "                    found_terms[match] = definition\n",
    "        \n",
    "        # Strategy 5: Medication names (often end in specific suffixes)\n",
    "        medication_patterns = [\n",
    "            r'\\b\\w+cillin\\b',          # penicillin, amoxicillin, etc.\n",
    "            r'\\b\\w+mycin\\b',           # streptomycin, etc.\n",
    "            r'\\b\\w+floxacin\\b',        # levofloxacin, ciprofloxacin, etc.\n",
    "            r'\\b\\w+sone\\b',            # prednisone, cortisone, etc.\n",
    "            r'\\b\\w+pam\\b',             # lorazepam, etc.\n",
    "        ]\n",
    "        \n",
    "        for pattern in medication_patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                definition = self.find_term_in_dict(match)\n",
    "                if definition:\n",
    "                    found_terms[match] = definition\n",
    "        \n",
    "        return found_terms\n",
    "    \n",
    "    def get_n_grams(self, text, n):\n",
    "        \"\"\"Generate n-grams from text.\"\"\"\n",
    "        words = re.findall(r'\\b[A-Za-z]+\\b', text.lower())\n",
    "        n_grams = []\n",
    "        for i in range(len(words) - n + 1):\n",
    "            phrase = ' '.join(words[i:i+n])\n",
    "            n_grams.append(phrase)\n",
    "        return n_grams\n",
    "    \n",
    "    def find_term_in_dict(self, term):\n",
    "        \"\"\"Find term in medical dictionary.\"\"\"\n",
    "        search_formats = [\n",
    "            term, term.lower(), term.upper(), term.title(), term.capitalize()\n",
    "        ]\n",
    "        \n",
    "        for search_term in search_formats:\n",
    "            if search_term in self.meddict:\n",
    "                return self.meddict[search_term]\n",
    "        \n",
    "        # Partial matching\n",
    "        for key in self.meddict.keys():\n",
    "            if key.lower() == term.lower():\n",
    "                return self.meddict[key]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def create_prompt(self, original_text, found_terms):\n",
    "        \"\"\"\n",
    "        Create the exact prompt that will be sent to the model.\n",
    "        Enhanced with better instructions for patient-focused explanations.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Format found terms for inclusion in prompt\n",
    "        terms_section = \"\"\n",
    "        if found_terms:\n",
    "            terms_section = \"Found medical terms and their definitions:\\n\"\n",
    "            for term, definition in found_terms.items():\n",
    "                terms_section += f\"- {term}: {definition}\\n\"\n",
    "        else:\n",
    "            terms_section = \"No medical terms found in dictionary.\\n\"\n",
    "        \n",
    "        # Enhanced prompt with direct patient addressing\n",
    "        prompt = f\"\"\"<s>[INST] You are a medical doctor and educator who explains medical information directly to patients in simple, caring language.\n",
    "\n",
    "Original medical text:\n",
    "\"{original_text}\"\n",
    "\n",
    "{terms_section}\n",
    "\n",
    "Your task:\n",
    "1. Address the patient directly using \"you\" and \"your\" (e.g., \"You have a condition called...\" not \"This is a story about...\")\n",
    "2. Explain the medical content in simple, everyday language that anyone can understand\n",
    "3. For EVERY medical term found above, provide a clear explanation using middle school level words\n",
    "4. Be accurate, reassuring, and caring in tone\n",
    "5. Organize your explanation clearly: condition → what happened → treatments → outcome\n",
    "6. Include key procedures and treatments mentioned in the text (e.g., code status related procedures, procedures, medications, and test results)\n",
    "7. Explain why treatments were necessary and how they helped\n",
    "8. End with encouraging words about recovery and next steps\n",
    "\n",
    "Please provide your patient-focused explanation now:\n",
    "\n",
    "[/INST]\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def _generate_raw_response(self, prompt):\n",
    "        \"\"\"\n",
    "        Generate raw response from model (separated from cleaning).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Tokenize input\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(self.model.device)\n",
    "            input_length = inputs[\"input_ids\"].shape[1]\n",
    "            \n",
    "            # Generate response\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    inputs[\"input_ids\"],\n",
    "                    attention_mask=inputs[\"attention_mask\"],\n",
    "                    **self.generation_config\n",
    "                )\n",
    "            \n",
    "            # Extract only the NEW tokens (response), not the input prompt\n",
    "            response_tokens = outputs[0][input_length:]  # Skip input tokens\n",
    "            raw_output = self.tokenizer.decode(response_tokens, skip_special_tokens=False)\n",
    "            \n",
    "            return raw_output\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"❌ Error generating response: {str(e)}\"\n",
    "    \n",
    "    def model_clean_response(self, raw_response, original_prompt):\n",
    "        \"\"\"\n",
    "        Enhanced cleaning with better instructions for patient-focused, structured output.\n",
    "        \"\"\"\n",
    "        \n",
    "        # If response is very short or error, return as-is\n",
    "        if len(raw_response.strip()) < 10 or raw_response.startswith(\"❌\"):\n",
    "            return raw_response\n",
    "        \n",
    "        cleaning_prompt = f\"\"\"<s>[INST] You are a medical text editor. Clean up this patient explanation to make it perfect.\n",
    "\n",
    "ORIGINAL PROMPT GIVEN TO MODEL:\n",
    "{original_prompt}\n",
    "\n",
    "RAW MODEL OUTPUT TO CLEAN:\n",
    "\"{raw_response}\"\n",
    "\n",
    "CLEANING INSTRUCTIONS:\n",
    "1. Remove any special tokens like <s>, </s>, [INST], [/INST]\n",
    "2. Fix any anonymization issues - use \"you\" and \"your\" consistently instead of \"[**Patient Name**]\" \n",
    "3. Remove any incomplete sentences at the end\n",
    "4. Remove repetitive or garbled text\n",
    "5. Ensure direct patient addressing throughout (\"You have...\" not \"The patient has...\")\n",
    "6. Organize clearly: Your condition → What happened → Treatments → Outcome → Next steps\n",
    "7. Make sure all medical terms mentioned are properly explained in simple language\n",
    "8. Keep the caring, reassuring tone\n",
    "9. Ensure it flows naturally and is easy to read\n",
    "10. End on an encouraging, positive note about recovery\n",
    "11. Do not skip medical procedures related to code status (intubation, extubation, and Cardiopulmonary Resuscitation)\n",
    "\n",
    "Return only the clean, patient-focused explanation:\n",
    "\n",
    "[/INST]\"\"\"\n",
    "        \n",
    "        try:\n",
    "            inputs = self.tokenizer(cleaning_prompt, return_tensors=\"pt\", truncation=True).to(self.model.device)\n",
    "            input_length = inputs[\"input_ids\"].shape[1]\n",
    "            \n",
    "            # Use enhanced generation config for cleaning\n",
    "            cleaning_config = {\n",
    "                \"max_new_tokens\": 600,  # Increased for more complete cleaning\n",
    "                \"temperature\": 0.1,\n",
    "                \"top_p\": 0.9,\n",
    "                \"repetition_penalty\": 1.1,\n",
    "                \"do_sample\": True,\n",
    "                \"pad_token_id\": self.tokenizer.eos_token_id,\n",
    "                \"eos_token_id\": self.tokenizer.eos_token_id,\n",
    "                \"early_stopping\": True,\n",
    "            }\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    inputs[\"input_ids\"],\n",
    "                    attention_mask=inputs[\"attention_mask\"],\n",
    "                    **cleaning_config\n",
    "                )\n",
    "            \n",
    "            # Extract only the cleaned response\n",
    "            response_tokens = outputs[0][input_length:]\n",
    "            cleaned = self.tokenizer.decode(response_tokens, skip_special_tokens=True)\n",
    "            \n",
    "            # Post-process to fix common issues\n",
    "            cleaned = self.post_process_patient_text(cleaned.strip())\n",
    "            \n",
    "            return cleaned\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Fallback to enhanced cleaning if model cleaning fails\n",
    "            return self.enhanced_fallback_clean(raw_response)\n",
    "    \n",
    "    def post_process_patient_text(self, text):\n",
    "        \"\"\"\n",
    "        Post-process the cleaned text to ensure patient-focused language.\n",
    "        \"\"\"\n",
    "        # Fix anonymization placeholders\n",
    "        anonymization_fixes = [\n",
    "            (r'\\[?\\*?\\*?Patient Name\\*?\\*?\\]?', 'you'),\n",
    "            (r'\\[?\\*?\\*?Patient\\*?\\*?\\]?', 'you'),\n",
    "            (r'the patient', 'you'),\n",
    "            (r'The patient', 'You'),\n",
    "            (r'This patient', 'You'),\n",
    "            (r'this patient', 'you'),\n",
    "            (r'A patient', 'You'),\n",
    "            (r'a patient', 'you'),\n",
    "        ]\n",
    "        \n",
    "        for pattern, replacement in anonymization_fixes:\n",
    "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "        \n",
    "        # Fix common grammar issues after pronoun replacement\n",
    "        text = re.sub(r'\\byou was\\b', 'you were', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\byou has\\b', 'you have', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\byou is\\b', 'you are', text, flags=re.IGNORECASE)\n",
    "        \n",
    "        # Remove story-like introductions\n",
    "        story_patterns = [\n",
    "            r'^This is a story about.*?\\.',\n",
    "            r'^Let me tell you about.*?\\.',\n",
    "            r'^Here\\'s what happened.*?\\.',\n",
    "        ]\n",
    "        \n",
    "        for pattern in story_patterns:\n",
    "            text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.DOTALL)\n",
    "        \n",
    "        # Clean up extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = text.strip()\n",
    "        \n",
    "        # Ensure it starts with \"You\" if it doesn't already\n",
    "        if not text.lower().startswith('you'):\n",
    "            text = 'You ' + text.lower()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def enhanced_fallback_clean(self, raw_output):\n",
    "        \"\"\"\n",
    "        Enhanced fallback cleaning with patient-focused improvements.\n",
    "        \"\"\"\n",
    "        cleaned = raw_output\n",
    "        \n",
    "        # Remove special tokens\n",
    "        cleanup_patterns = [\"</s>\", \"<s>\", \"[INST]\", \"[/INST]\"]\n",
    "        for pattern in cleanup_patterns:\n",
    "            cleaned = cleaned.replace(pattern, \"\")\n",
    "        \n",
    "        # Apply patient-focused post-processing\n",
    "        cleaned = self.post_process_patient_text(cleaned)\n",
    "        \n",
    "        # Remove incomplete sentences more intelligently\n",
    "        sentences = re.split(r'[.!?]+', cleaned)\n",
    "        complete_sentences = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if len(sentence) > 10 and not sentence.endswith(('and', 'or', 'but', 'the', 'a', 'an')):\n",
    "                complete_sentences.append(sentence)\n",
    "        \n",
    "        if complete_sentences:\n",
    "            result = '. '.join(complete_sentences) + '.'\n",
    "            # Fix double periods\n",
    "            result = re.sub(r'\\.+', '.', result)\n",
    "            return result\n",
    "        \n",
    "        return cleaned\n",
    "    \n",
    "    def create_cleaning_prompt(self, raw_response, original_prompt):\n",
    "        \"\"\"\n",
    "        Create the enhanced cleaning prompt for transparency.\n",
    "        \"\"\"\n",
    "        return f\"\"\"<s>[INST] You are a medical text editor. Clean up this patient explanation to make it perfect.\n",
    "\n",
    "ORIGINAL PROMPT GIVEN TO MODEL:\n",
    "{original_prompt}\n",
    "\n",
    "RAW MODEL OUTPUT TO CLEAN:\n",
    "\"{raw_response}\"\n",
    "\n",
    "CLEANING INSTRUCTIONS:\n",
    "1. Remove any special tokens like <s>, </s>, [INST], [/INST]\n",
    "2. Fix any anonymization issues - use \"you\" and \"your\" consistently instead of \"[**Patient Name**]\" \n",
    "3. Remove any incomplete sentences at the end\n",
    "4. Remove repetitive or garbled text\n",
    "5. Ensure direct patient addressing throughout (\"You have...\" not \"The patient has...\")\n",
    "6. Organize clearly: Your condition → What happened → Treatments → Outcome → Next steps\n",
    "7. Make sure all medical terms mentioned are properly explained in simple language\n",
    "8. Keep the caring, reassuring tone\n",
    "9. Ensure it flows naturally and is easy to read\n",
    "10. End on an encouraging, positive note about recovery\n",
    "\n",
    "Return only the clean, patient-focused explanation:\n",
    "\n",
    "[/INST]\"\"\"\n",
    "\n",
    "    def clean_raw_output(self, raw_output, original_prompt=\"\"):\n",
    "        \"\"\"\n",
    "        Directly clean a raw output with optional original prompt context.\n",
    "        \n",
    "        Args:\n",
    "            raw_output (str): Raw model output to clean\n",
    "            original_prompt (str): Original prompt for context (optional)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Cleaning results\n",
    "        \"\"\"\n",
    "        print(\"🧹 Cleaning raw output directly...\")\n",
    "        \n",
    "        cleaned_output = self.model_clean_response(raw_output, original_prompt)\n",
    "        cleaning_prompt = self.create_cleaning_prompt(raw_output, original_prompt)\n",
    "        \n",
    "        result = {\n",
    "            'raw_output': raw_output,\n",
    "            'original_prompt': original_prompt,\n",
    "            'cleaning_prompt': cleaning_prompt,\n",
    "            'cleaned_output': cleaned_output,\n",
    "            'cleaned_length': len(cleaned_output)\n",
    "        }\n",
    "        \n",
    "        print(f\"   ✅ Cleaned to {len(cleaned_output)} characters\")\n",
    "        return result\n",
    "        \"\"\"\n",
    "        Create the enhanced cleaning prompt for transparency.\n",
    "        \"\"\"\n",
    "        return f\"\"\"<s>[INST] You are a medical text editor. Clean up this patient explanation to make it perfect.\n",
    "\n",
    "ORIGINAL PROMPT GIVEN TO MODEL:\n",
    "{original_prompt}\n",
    "\n",
    "RAW MODEL OUTPUT TO CLEAN:\n",
    "\"{raw_response}\"\n",
    "\n",
    "CLEANING INSTRUCTIONS:\n",
    "1. Remove any special tokens like <s>, </s>, [INST], [/INST]\n",
    "2. Fix any anonymization issues - use \"you\" and \"your\" consistently instead of \"[**Patient Name**]\" \n",
    "3. Remove any incomplete sentences at the end\n",
    "4. Remove repetitive or garbled text\n",
    "5. Ensure direct patient addressing throughout (\"You have...\" not \"The patient has...\")\n",
    "6. Organize clearly: Your condition → What happened → Treatments → Outcome → Next steps\n",
    "7. Make sure all medical terms mentioned are properly explained in simple language\n",
    "8. Keep the caring, reassuring tone\n",
    "9. Ensure it flows naturally and is easy to read\n",
    "10. End on an encouraging, positive note about recovery\n",
    "\n",
    "Return only the clean, patient-focused explanation:\n",
    "\n",
    "[/INST]\"\"\"\n",
    "\n",
    "# Demo and usage examples\n",
    "def demo_modular_system():\n",
    "    \"\"\"Demonstrate the new modular step system.\"\"\"\n",
    "    \n",
    "    print(\"🔧 MODULAR MEDICAL EXPLANATION SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"📋 Available Step Combinations:\")\n",
    "    print()\n",
    "    \n",
    "    print(\"1️⃣ FULL PIPELINE - All steps (default)\")\n",
    "    print(\"   result = explainer.explain_medical_text(text)\")\n",
    "    print(\"   result = explainer.explain_medical_text(text, steps=['extract', 'generate', 'clean'])\")\n",
    "    print()\n",
    "    \n",
    "    print(\"2️⃣ SKIP CLEANING - Raw model output\")\n",
    "    print(\"   result = explainer.explain_medical_text(text, steps=['extract', 'generate'])\")\n",
    "    print()\n",
    "    \n",
    "    print(\"3️⃣ ONLY EXTRACT - Just find medical terms\")\n",
    "    print(\"   result = explainer.explain_medical_text(text, steps=['extract'])\")\n",
    "    print()\n",
    "    \n",
    "    print(\"4️⃣ GENERATE ONLY - Skip extraction\")\n",
    "    print(\"   result = explainer.explain_medical_text(text, steps=['generate'])\")\n",
    "    print()\n",
    "    \n",
    "    print(\"5️⃣ CUSTOM PIPELINE - Generate then clean\")\n",
    "    print(\"   result = explainer.explain_medical_text(text, steps=['generate', 'clean'])\")\n",
    "    print()\n",
    "    \n",
    "    print(\"✅ BENEFITS:\")\n",
    "    print(\"   • Run only the steps you need\")\n",
    "    print(\"   • Debug individual steps\") \n",
    "    print(\"   • Compare raw vs cleaned outputs\")\n",
    "    print(\"   • Skip expensive cleaning for quick tests\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_modular_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "330cd4de-e256-45db-94ae-348effe10813",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = MedicalTextExplainer(model, tokenizer, meddict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3bca9324-f0e3-450a-a78e-e1ed454c2457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Running step: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   📋 Found 131 medical terms\n",
      "🔄 Running step: generate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   🤖 Generated 2973 character response\n",
      "✅ Completed 2 steps: ['extract', 'generate']\n",
      "🧹 Cleaning raw output directly...\n",
      "   ✅ Cleaned to 2603 characters\n"
     ]
    }
   ],
   "source": [
    "result = explainer.explain_medical_text(text, steps=['extract', 'generate'])\n",
    "cleaned_result = explainer.clean_raw_output(\n",
    "    raw_output=result['raw_output'], \n",
    "    original_prompt=result['prompt']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "99dce79b-0628-42cc-8664-305633984f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "steps_run ['extract', 'generate']\n",
      "============================================\n",
      "available_steps ['extract', 'generate', 'clean']\n",
      "============================================\n",
      "terms_count 131\n",
      "============================================\n",
      "raw_output Dear [Patient's Name],\n",
      "\n",
      "I want to explain your recent stay in the hospital and what happened to you. You are an 81-year-old woman who has been living with emphysema, a condition that affects your lungs and makes it difficult to breathe. About three days before coming to the hospital, you started feeling short of breath, and your primary care doctor thought it might be a flare-up of your emphysema.\n",
      "\n",
      "To help with your breathing, your doctor prescribed prednisone, a medication that reduces inflammation in your lungs. Unfortunately, your condition didn't improve, and you needed oxygen at home to keep your oxygen levels above 90%. Despite receiving oxygen, nebulizer treatments, and a strong dose of solumedrol, a type of steroid, in the emergency room, your oxygen levels remained low.\n",
      "\n",
      "When you arrived at the hospital, your oxygen levels were 100% on continuous positive airway pressure (CPAP), a machine that delivers pressurized air to help you breathe. However, even with CPAP, your lungs were struggling to work properly. Doctors decided to admit you to the Medical Intensive Care Unit (MICU) because of your difficulty breathing.\n",
      "\n",
      "While in the MICU, doctors discovered that your airways were narrowing during exhalation, a condition called tracheomalacia. To help with this problem, two silicone stents were placed in your airways, one in the left main stem and one in the trachea. These stents help keep your airways open and allow you to breathe easier.\n",
      "\n",
      "After the stent placement, you were moved to a regular hospital room, where your oxygen levels improved, and you were eventually able to breathe on your own. Your steroid treatment was gradually reduced, and you were discharged from the hospital on room air, meaning you were breathing without needing extra oxygen.\n",
      "\n",
      "During your hospital stay, you also had a few other issues. You experienced some muscle weakness, which was likely due to a combination of steroid myopathy (a side effect of the steroids) and deconditioning (meaning you hadn't been moving much due to your illness). You were referred to pulmonary rehabilitation to help strengthen your muscles and improve your overall lung function.\n",
      "\n",
      "Additionally, you had a sore throat after being extubated (when the breathing tube was removed), which was treated with lozenges and a solution containing kaopectate, bismuth, and lidocaine. You were also prescribed several medications to manage your other health conditions, such as hypertension (high blood pressure), hypothyroidism (underactive thyroid), depression, and acid reflux.\n",
      "\n",
      "Overall, your hospital stay was complicated, but the team of doctors worked hard to address your breathing difficulties and ensure you received the best possible care. You are now home and recovering, and I encourage you to continue with your prescribed medications and follow-up appointments as scheduled. Keep up the good work, and don't hesitate to reach out if you have any questions or concerns. Take care!</s>\n",
      "============================================\n",
      "prompt_length 43477\n",
      "============================================\n",
      "raw_output_length 2973\n"
     ]
    }
   ],
   "source": [
    "for k,v in result.items():\n",
    "    if k not in ['original_text', 'found_terms','prompt']:\n",
    "        print('='*44)\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb4233-0672-4c02-8932-e9a0382e3647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bebc6fb-06a4-4ec8-b5ae-81f3690ed848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
