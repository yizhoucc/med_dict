{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4dd4555-473d-48cd-bc86-60a4c41da0a8",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2c708e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yc/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "with open(\"hf.token\", \"r\") as f:\n",
    "    hftoken = f.read().strip()  \n",
    "\n",
    "import os\n",
    "cache_dir = \"/mnt/c/Users/yc/.cache/huggingface\"\n",
    "os.environ['HF_HOME'] = cache_dir\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=hftoken)  # Move token to environment variable\n",
    "\n",
    "from ult import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d74a59c-b625-4944-8a79-aea69bc6cd8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:22<00:00, 20.66s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "device_map = {\"\": 0}\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1c388-57f9-41b0-87d1-25a9ad884430",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf6281f4-7ebb-48fd-a08b-4271349ededf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def txt_to_dict(file_path):\n",
    "    data_dict = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(0, len(lines) - 1, 2):\n",
    "            key = lines[i].strip()    # Odd line are key\n",
    "            value = lines[i + 1].strip()  # Even line are value\n",
    "            data_dict[key] = value\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "txt_file_path = 'data/formaldef.txt'\n",
    "formaldic = txt_to_dict(txt_file_path)\n",
    "len(formaldic)\n",
    "\n",
    "meddict={}\n",
    "for k,v in formaldic.items():\n",
    "    meddict[k.split('Listen to pronunciation')[0].split('(')[0]]=v\n",
    "filename= 'data/filtered_medical_dictionary.csv'\n",
    "eighth_grade_words=set()\n",
    "with open(filename, 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)  # Skip the header row\n",
    "    for row in reader:\n",
    "        if row:  # Make sure row is not empty\n",
    "            eighth_grade_words.add(row[0])  # Add the word (first column)\n",
    "filtered_meddict = {word: explanation for word, explanation in meddict.items() \n",
    "                   if word in eighth_grade_words}\n",
    "meddict=filtered_meddict\n",
    "# load data\n",
    "df = pd.read_csv('data/CORAL/coral-expert-curated-medical-oncology-reports-to-advance-language-model-inference-1.0/coral/unannotated/data/breastca_unannotated.csv')\n",
    "# df = df.sample(1, random_state=42)\n",
    "df=df.iloc[[83, 53]] \n",
    "test_note=df.iloc[0]['note_text']\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfa3a9d",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73b11536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e12ecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- 1. Creating Base KV Cache from long text... ---\n",
      "  Tokenizing and running forward pass to get base cache...\n",
      "Base KV Cache created. Ready for 'branching' extractions.\n",
      " --- 2. Running EFFICIENT 'Branching' Extractions ---\n",
      " Extracting: Reason_for_Visit...\n",
      "  Raw Output: {   \"Reason for Visit\": \"Follow-up\" }\n",
      " Extracting: What_We_Found...\n",
      "  Raw Output: {   \"Imaging\": {     \"Diagnostic mammogram\": \"irregular mass (6.7 x 5.2 x 3.7 cm) in upper outer quadrant of left breast,\n",
      "middle to posterior third\",     \"Left breast ultrasound\": \"multiple irregular masses with probable ductal extension between them\",     \"Left\n",
      "axillary ultrasound\": \"at least 5 abnormally thickened lymph nodes\",     \"CT CAP\": \"spiculated left breast mass (5 x 3 cm); multiple left\n",
      "axillary LN (ex - 1.2 x 1.0 cm); no evidence of distant metastases, but subtle sclerotic lesion of left posterior 7th rib\",     \"Bone scan\":\n",
      "\"non-specific small mild focal uptake of posterior left 7th rib\",     \"PET/CT\": \"suspicious FDG-avid lytic lesion in left pedicle of T6\",\n",
      "\"Brain MRI\": \"no evidence of distant metastasis\"   },   \"Labs\": {     \"Hepatitis B\": \"HBV (Hepatitis B) - negative\",     \"Influenza\": \"INFS\n",
      "PRES FREE 18YRS-ADULT (Influenza) - negative\",\n",
      " Extracting: Treatment_Summary...\n",
      "  Raw Output: {   \"medications\": {     \"calcium citrate/vitamin D3\": \"CITRACAL + D MAXIMUM ORAL\",     \"candesartan\": \"4 mg tablet, 2 times\n",
      "daily\",     \"letrozole\": \"2.5 mg tablet, daily\",     \"leuprolide\": \"7.5 mg, every 30 days\",     \"melatonin\": \"20 mg, nightly\",\n",
      "\"multivitamin\": \"tablet, daily\",     \"oxycodone\": \"5 mg, every 12 hours as needed\",     \"trazodone\": \"50 mg, nightly\",     \"zoledronic\n",
      "acid\": \"every 3 months\"   },   \"recent changes\": {     \"stopped\": [       \"LORazepam\",       \"naloxone\",       \"acetaminophen\",\n",
      "\"docusate sodium\",       \"hydrocortisone\"     ]   },   \"supportive meds\": {     \"bowel regimen\": \"calcium 1250 mg daily, vitamin D 1000 to\n",
      "2000 units daily\"   },   \"blood transfusion\": \"None\" }\n",
      " Extracting: What_We_Discussed...\n",
      "  Raw Output: {   \"goals_of_treatment\": \"prolongation of life, while maintaining a good quality of life without excessive toxicities\",\n",
      "\"treatment_plan\": \"continue leuprolide every 4 weeks, continue letrozole, referred to radiation oncology, repeat PET/CT in ~3-4 months after\n",
      "radiation, start palbociclib after radiation\",   \"response\": \"stable\",   \"side_effects\": \"joint pain and myalgias, tingling and sensory\n",
      "change, hot flashes\",   \"clinical_trials\": \"not mentioned\" }\n",
      " Extracting: medication_plan...\n",
      "  Raw Output: {   \"medication_plan\": {     \"continue\": {       \"leuprolide\": \"every 4 weeks\",       \"letrozole\": \"daily\",       \"zoledronic\n",
      "acid\": \"every 3 months\",       \"calcium\": \"1250 mg daily\",       \"vitamin D\": \"1000 to 2000 units daily\"     },     \"start\": {\n",
      "\"palbociclib\": \"after radiation\",       \"acupuncture\": \"immediately\"     },     \"discontinue\": {       \"oxyCODONE\": \"as needed\",\n",
      "\"LORazepam\": \"twice a day\",       \"naloxone\": \"as needed\",       \"acetaminophen\": \"every 8 hours\",       \"docusate sodium\": \"twice a day\"\n",
      "}   } }\n",
      " Extracting: imaging_plan...\n",
      "  Raw Output: {   \"PET/CT\": \"in ~3-4 months after radiation\",   \"DEXA scan\": \"re-ordered\",   \"MRI\": \"Brain MRI: no evidence of distant\n",
      "metastasis (08/03/17)\",   \"Bone scan\": \"Bone scan: non-specific small mild focal uptake of posterior left 7th rib (07/23/17)\" }\n",
      " Extracting: lab_plan...\n",
      "  Raw Output: {   \"lab_plan\": {     \"DEXA scan\": \"re-ordered\",     \"PET/CT\": \"in ~3-4 months after radiation\",     \"CBC\": \"not specified\",\n",
      "\"CMP\": \"not specified\",     \"tumor markers\": \"not specified\",     \"coagulation profile\": \"not specified\"   } }\n",
      " Extracting: genetic_testing_plan...\n",
      "  Raw Output: {   \"BRCA2 mutation\": \"positive\" }\n",
      " Extracting: procedure_plan...\n",
      "  Raw Output: {   \"surgery\": \"post-mastectomy radiation\",   \"radiation therapy\": \"post-mastectomy radiation\",   \"interventional procedures\":\n",
      "\"PET/CT in ~3-4 months after radiation\",   \"medication start\": \"palbociclib after radiation\" }\n",
      " Extracting: Admin_Notes...\n",
      "  Raw Output: {   \"Patient ID\": \"***** *****\",   \"Date of Service\": \"04/30/18\",   \"Code Status\": \"Patient Active\" }\n",
      " --- 3. All extractions complete. ---\n",
      " --- FINAL EXTRACTED DATA ---\n",
      "{   \"Reason_for_Visit\": {     \"Reason for Visit\": \"Follow-up\"   },   \"What_We_Found\": {     \"error\": \"Failed to parse JSON\",     \"raw\": \"{\\n\n",
      "\\\"Imaging\\\": {\\n    \\\"Diagnostic mammogram\\\": \\\"irregular mass (6.7 x 5.2 x 3.7 cm) in upper outer quadrant of left breast, middle to\n",
      "posterior third\\\",\\n    \\\"Left breast ultrasound\\\": \\\"multiple irregular masses with probable ductal extension between them\\\",\\n    \\\"Left\n",
      "axillary ultrasound\\\": \\\"at least 5 abnormally thickened lymph nodes\\\",\\n    \\\"CT CAP\\\": \\\"spiculated left breast mass (5 x 3 cm); multiple\n",
      "left axillary LN (ex - 1.2 x 1.0 cm); no evidence of distant metastases, but subtle sclerotic lesion of left posterior 7th rib\\\",\\n\n",
      "\\\"Bone scan\\\": \\\"non-specific small mild focal uptake of posterior left 7th rib\\\",\\n    \\\"PET/CT\\\": \\\"suspicious FDG-avid lytic lesion in\n",
      "left pedicle of T6\\\",\\n    \\\"Brain MRI\\\": \\\"no evidence of distant metastasis\\\"\\n  },\\n  \\\"Labs\\\": {\\n    \\\"Hepatitis B\\\": \\\"HBV (Hepatitis\n",
      "B) - negative\\\",\\n    \\\"Influenza\\\": \\\"INFS PRES FREE 18YRS-ADULT (Influenza) - negative\\\",\"   },   \"Treatment_Summary\": {\n",
      "\"medications\": {       \"calcium citrate/vitamin D3\": \"CITRACAL + D MAXIMUM ORAL\",       \"candesartan\": \"4 mg tablet, 2 times daily\",\n",
      "\"letrozole\": \"2.5 mg tablet, daily\",       \"leuprolide\": \"7.5 mg, every 30 days\",       \"melatonin\": \"20 mg, nightly\",       \"multivitamin\":\n",
      "\"tablet, daily\",       \"oxycodone\": \"5 mg, every 12 hours as needed\",       \"trazodone\": \"50 mg, nightly\",       \"zoledronic acid\": \"every 3\n",
      "months\"     },     \"recent changes\": {       \"stopped\": [         \"LORazepam\",         \"naloxone\",         \"acetaminophen\",\n",
      "\"docusate sodium\",         \"hydrocortisone\"       ]     },     \"supportive meds\": {       \"bowel regimen\": \"calcium 1250 mg daily, vitamin D\n",
      "1000 to 2000 units daily\"     },     \"blood transfusion\": \"None\"   },   \"What_We_Discussed\": {     \"goals_of_treatment\": \"prolongation of\n",
      "life, while maintaining a good quality of life without excessive toxicities\",     \"treatment_plan\": \"continue leuprolide every 4 weeks,\n",
      "continue letrozole, referred to radiation oncology, repeat PET/CT in ~3-4 months after radiation, start palbociclib after radiation\",\n",
      "\"response\": \"stable\",     \"side_effects\": \"joint pain and myalgias, tingling and sensory change, hot flashes\",     \"clinical_trials\": \"not\n",
      "mentioned\"   },   \"medication_plan\": {     \"medication_plan\": {       \"continue\": {         \"leuprolide\": \"every 4 weeks\",\n",
      "\"letrozole\": \"daily\",         \"zoledronic acid\": \"every 3 months\",         \"calcium\": \"1250 mg daily\",         \"vitamin D\": \"1000 to 2000\n",
      "units daily\"       },       \"start\": {         \"palbociclib\": \"after radiation\",         \"acupuncture\": \"immediately\"       },\n",
      "\"discontinue\": {         \"oxyCODONE\": \"as needed\",         \"LORazepam\": \"twice a day\",         \"naloxone\": \"as needed\",\n",
      "\"acetaminophen\": \"every 8 hours\",         \"docusate sodium\": \"twice a day\"       }     }   },   \"imaging_plan\": {     \"PET/CT\": \"in ~3-4\n",
      "months after radiation\",     \"DEXA scan\": \"re-ordered\",     \"MRI\": \"Brain MRI: no evidence of distant metastasis (08/03/17)\",     \"Bone\n",
      "scan\": \"Bone scan: non-specific small mild focal uptake of posterior left 7th rib (07/23/17)\"   },   \"lab_plan\": {     \"lab_plan\": {\n",
      "\"DEXA scan\": \"re-ordered\",       \"PET/CT\": \"in ~3-4 months after radiation\",       \"CBC\": \"not specified\",       \"CMP\": \"not specified\",\n",
      "\"tumor markers\": \"not specified\",       \"coagulation profile\": \"not specified\"     }   },   \"genetic_testing_plan\": {     \"BRCA2 mutation\":\n",
      "\"positive\"   },   \"procedure_plan\": {     \"surgery\": \"post-mastectomy radiation\",     \"radiation therapy\": \"post-mastectomy radiation\",\n",
      "\"interventional procedures\": \"PET/CT in ~3-4 months after radiation\",     \"medication start\": \"palbociclib after radiation\"   },\n",
      "\"Admin_Notes\": {     \"Patient ID\": \"***** *****\",     \"Date of Service\": \"04/30/18\",     \"Code Status\": \"Patient Active\"   } }\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import Dict, Optional, Tuple\n",
    "import json\n",
    "import gc\n",
    "\n",
    "def run_model_with_cache_manual(\n",
    "    prompt_text: str, \n",
    "    model, \n",
    "    tokenizer, \n",
    "    generation_config: Dict, \n",
    "    kv_cache: Optional[Tuple[torch.Tensor]] = None\n",
    ") -> Tuple[str, Tuple[torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Memory-efficient manual generation with proper cleanup.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Tokenize the new input text\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    \n",
    "    # 2. Setup generation parameters\n",
    "    max_new_tokens = generation_config.get(\"max_new_tokens\", 256)\n",
    "    eos_token_id = generation_config.get(\"eos_token_id\", tokenizer.eos_token_id)\n",
    "    do_sample = generation_config.get(\"do_sample\", False)\n",
    "    \n",
    "    # 3. Determine the starting position and build attention mask\n",
    "    if kv_cache is not None:\n",
    "        past_seq_len = kv_cache[0][0].shape[2]\n",
    "        \n",
    "        # Build full attention mask ONCE upfront\n",
    "        attention_mask_cached = torch.ones((1, past_seq_len), dtype=torch.long, device=model.device)\n",
    "        attention_mask_new = inputs.get(\"attention_mask\", torch.ones_like(input_ids))\n",
    "        attention_mask = torch.cat([attention_mask_cached, attention_mask_new], dim=1)\n",
    "    else:\n",
    "        attention_mask = inputs.get(\"attention_mask\", torch.ones_like(input_ids))\n",
    "    \n",
    "    # 4. First forward pass to process the new prompt\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            past_key_values=kv_cache,\n",
    "            use_cache=True\n",
    "        )\n",
    "    \n",
    "    current_cache = outputs.past_key_values\n",
    "    next_token_logits = outputs.logits[:, -1, :]\n",
    "    \n",
    "    # Clear outputs to free memory\n",
    "    del outputs\n",
    "    \n",
    "    # 5. Pre-allocate list for generated tokens\n",
    "    generated_tokens = []\n",
    "    \n",
    "    # 6. Generation loop\n",
    "    for step in range(max_new_tokens):\n",
    "        # Sample next token\n",
    "        if do_sample:\n",
    "            temperature = generation_config.get(\"temperature\", 1.0)\n",
    "            probs = torch.softmax(next_token_logits / temperature, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            # Greedy decoding\n",
    "            next_token = torch.argmax(next_token_logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        # Store the token value\n",
    "        token_id = next_token.item()\n",
    "        generated_tokens.append(token_id)\n",
    "        \n",
    "        # Check for EOS\n",
    "        if token_id == eos_token_id:\n",
    "            break\n",
    "        \n",
    "        # Prepare for next iteration - extend attention mask efficiently\n",
    "        # Instead of concatenating, create a new mask of the right size\n",
    "        new_length = attention_mask.shape[1] + 1\n",
    "        new_attention_mask = torch.ones((1, new_length), dtype=torch.long, device=model.device)\n",
    "        \n",
    "        # Free old attention mask\n",
    "        del attention_mask\n",
    "        attention_mask = new_attention_mask\n",
    "        \n",
    "        # Forward pass with the new token\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=next_token,\n",
    "                attention_mask=attention_mask,\n",
    "                past_key_values=current_cache,\n",
    "                use_cache=True\n",
    "            )\n",
    "        \n",
    "        # Update cache and logits\n",
    "        current_cache = outputs.past_key_values\n",
    "        next_token_logits = outputs.logits[:, -1, :]\n",
    "        \n",
    "        # Clean up\n",
    "        del outputs, next_token\n",
    "    \n",
    "    # 7. Decode the generated tokens\n",
    "    raw_output = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    # 8. Cleanup\n",
    "    del attention_mask, next_token_logits, generated_tokens\n",
    "    \n",
    "    return raw_output.strip(), current_cache\n",
    "\n",
    "\n",
    "# --- EXAMPLE USAGE WITH MEMORY MANAGEMENT ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Shared generation config - REDUCED max_new_tokens to save memory\n",
    "    gen_config = {\n",
    "        \"max_new_tokens\": 256,  # Reduced from 256\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "        \"do_sample\": False\n",
    "    }\n",
    "\n",
    "    myprint(\"\\n--- 1. Creating Base KV Cache from long text... ---\")\n",
    "    \n",
    "    base_prompt = (\n",
    "        f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n\"\n",
    "        f\"You are a medical data extraction expert. You will be given a long medical note. \"\n",
    "        f\"Your task is to answer a series of questions about it, one by one. \"\n",
    "        f\"Respond *only* with the extracted data in JSON format.\"\n",
    "        f\"<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "        f\"Here is the medical note:\\n\\n\"\n",
    "        f\"--- BEGIN NOTE ---\\n{test_note}\\n--- END NOTE ---\"\n",
    "        f\"\\n\\nI will now ask you to extract specific sections. \"\n",
    "        f\"Please wait for my first extraction task.\"\n",
    "        f\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        f\"{{\\\"status\\\": \\\"Understood. I have read the note and am ready.\\\"}}\"\n",
    "    )\n",
    "    \n",
    "    myprint(\"  Tokenizing and running forward pass to get base cache...\")\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(base_prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=inputs[\"input_ids\"], \n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            use_cache=True\n",
    "        )\n",
    "        \n",
    "        base_cache = outputs.past_key_values\n",
    "        \n",
    "        # Clean up\n",
    "        del inputs, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    myprint(\"Base KV Cache created. Ready for 'branching' extractions.\")\n",
    "\n",
    "    # --- 2. Define the \"Branching\" Extraction Tasks ---\n",
    "    extraction_prompts = {\n",
    "        \"Reason_for_Visit\": \"Extract 'Reason for Visit' (e.g., new patient, chemo, toxicity, surveillance, lab review, etc.).\",\n",
    "        \"What_We_Found\": \"Extract 'What We Found' (e.g., summary of imaging, key labs, performance status, new findings).\",\n",
    "        \"Treatment_Summary\": \"Extract 'Treatment Summary' (e.g., current medications, recent changes, supportive meds, bowel regimen, blood transfusion).\",\n",
    "        \"What_We_Discussed\": \"Extract 'What We Discussed / Decided' (e.g., goals of treatment, response, side effects, clinical trials).\",\n",
    "        \"medication_plan\": \"Extract future medication plan (including changes to current medications, supportive meds, bowel regimen, blood transfusion)\",\n",
    "        \"imaging_plan\": \"Extract future imaging plan (such as CT/MRl/PET/ultrasound/ DEXA scan)\",\n",
    "        \"lab_plan\": \"Extract future lab plan (such as CBC, CMP, tumor markers, coagulation profile, etc. specify frequency and rationale)\",\n",
    "        \"genetic_testing_plan\": \"Extract future molecular or genetic testing plan (tumor sequencing, germline panel, liquid biopsy)\",\n",
    "        \"procedure_plan\": \"Extract future procedure plan (such as Surgery, Radiation therapy, interventional procedures)\",\n",
    "        \"Admin_Notes\": \"Extract 'Administrative / Practical Notes' (e.g., refills, code status).\"\n",
    "    }\n",
    "\n",
    "    extracted_data = {}\n",
    "\n",
    "    myprint(\"\\n--- 2. Running EFFICIENT 'Branching' Extractions ---\")\n",
    "\n",
    "    for key, task in extraction_prompts.items():\n",
    "        myprint(f\"\\nExtracting: {key}...\")\n",
    "        \n",
    "        task_prompt = (\n",
    "            f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "            f\"TASK: {task}\\n\\nRespond *only* with a JSON object.\"\n",
    "            f\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        )\n",
    "\n",
    "        # Use the SAME base_cache for each extraction\n",
    "        answer, returned_cache = run_model_with_cache_manual(\n",
    "            task_prompt, \n",
    "            model, \n",
    "            tokenizer, \n",
    "            gen_config, \n",
    "            kv_cache=base_cache\n",
    "        )\n",
    "        \n",
    "        # CRITICAL: Explicitly delete the returned cache to free memory\n",
    "        del returned_cache\n",
    "        \n",
    "        # Force garbage collection and clear GPU cache\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        myprint(f\"  Raw Output: {answer}\")\n",
    "        \n",
    "        try:\n",
    "            clean_answer = answer.strip().strip(\"```json\").strip(\"```\").strip()\n",
    "            extracted_data[key] = json.loads(clean_answer)\n",
    "        except json.JSONDecodeError:\n",
    "            extracted_data[key] = {\"error\": \"Failed to parse JSON\", \"raw\": answer}\n",
    "\n",
    "    myprint(\"\\n--- 3. All extractions complete. ---\")\n",
    "    myprint(\"\\n--- FINAL EXTRACTED DATA ---\")\n",
    "    myprint(json.dumps(extracted_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15fe5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[]\n",
    "\n",
    "for row in df.itertuples():\n",
    "    test_note=row.note_text\n",
    "    gen_config = {\n",
    "    \"max_new_tokens\": 512,  # <-- Increased from 150 to 512\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"do_sample\": False\n",
    "    }\n",
    "\n",
    "    # myprint(\"\\n--- 1. Creating Base KV Cache from long text... ---\")\n",
    "\n",
    "    base_prompt = (\n",
    "        f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n\"\n",
    "        f\"You are a medical data extraction expert. You will be given a long medical note. \"\n",
    "        f\"Your task is to answer a series of questions about it, one by one. \"\n",
    "        # FIX 2: Stricter instruction in system prompt\n",
    "        f\"Respond *only* with the valid JSON object requested. Do not add markdown backticks or any other text.\"\n",
    "        f\"<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "        f\"Here is the medical note:\\n\\n\"\n",
    "        f\"--- BEGIN NOTE ---\\n{test_note}\\n--- END NOTE ---\"\n",
    "        f\"\\n\\nI will now ask you to extract specific sections. \"\n",
    "        f\"Please wait for my first extraction task.\"\n",
    "        f\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        f\"{{\\\"status\\\": \\\"Understood. I have read the note and am ready.\\\"}}\"\n",
    "    )\n",
    "\n",
    "    # myprint(\"  Tokenizing and running forward pass to get base cache...\")\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(base_prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        # This logic to create the base_cache is correct\n",
    "        outputs = model(\n",
    "            input_ids=inputs[\"input_ids\"], \n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            use_cache=True\n",
    "        )\n",
    "        \n",
    "        base_cache = outputs.past_key_values\n",
    "        \n",
    "        # Clean up\n",
    "        del inputs, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    # myprint(\"Base KV Cache created. Ready for 'branching' extractions.\")\n",
    "\n",
    "    # --- FIX 3: Define STRICT SCHEMAS for each extraction task ---\n",
    "    # This is the most important \"prompt engineering\" fix.\n",
    "    # We are telling the model *exactly* what keys to use.\n",
    "    extraction_prompts = {\n",
    "        \"Reason_for_Visit\": \"\"\"\n",
    "    TASK: Extract 'Reason for Visit'.\n",
    "    Respond *only* with a JSON object using this exact schema:\n",
    "    {\n",
    "    \"visit_type\": \"e.g., New patient, Surveillance, Side effect management\",\n",
    "    \"summary\": \"A brief summary of the reason for visit.\"\n",
    "    }\n",
    "    \"\"\",\n",
    "        \"What_We_Found\": \"\"\"\n",
    "    TASK: Extract 'What We Found'.\n",
    "    Respond *only* with a JSON object using this exact schema:\n",
    "    {\n",
    "    \"imaging_summary\": \"Summary of most recent imaging.\",\n",
    "    \"lab_summary\": \"Summary of key lab results.\",\n",
    "    \"performance_status\": \"e.g., ECOG 0, Stable\",\n",
    "    \"findings\": \"Summary of new findings or disease status.\"\n",
    "    }\n",
    "    \"\"\",\n",
    "        \"Treatment_Summary\": \"\"\"\n",
    "    TASK: Extract 'Treatment Summary'.\n",
    "    Respond *only* with a JSON object using this exact schema:\n",
    "    {\n",
    "    \"current_meds\": \"List of current oncologic medications or regimens.\",\n",
    "    \"recent_changes\": \"Any holds, dose reductions, or switches.\",\n",
    "    \"supportive_meds\": \"List of supportive medications.\"\n",
    "    }\n",
    "    \"\"\",\n",
    "        \"What_We_Discussed\": \"\"\"\n",
    "    TASK: Extract 'What We Discussed / Decided'.\n",
    "    Respond *only* with a JSON object using this exact schema:\n",
    "    {\n",
    "    \"goals_of_treatment\": \"e.g., Curative, Palliative, Surveillance\",\n",
    "    \"response_assessment\": \"How the cancer is responding.\",\n",
    "    \"side_effects_discussed\": \"Which side effects were discussed.\",\n",
    "    \"other_discussions\": \"e.g., Clinical trials, palliative care\"\n",
    "    }\n",
    "    \"\"\",\n",
    "        \"Plan_Going_Forward\": \"\"\"\n",
    "    TASK: Extract 'Plan Going Forward'.\n",
    "    Respond *only* with a JSON object using this exact schema:\n",
    "    {\n",
    "    \"medication_plan\": \"e.g., Continue, Start, Stop\",\n",
    "    \"imaging_plan\": \"Which scans and when.\",\n",
    "    \"lab_plan\": \"Which labs and when.\",\n",
    "    \"referrals\": \"List of any new referrals.\",\n",
    "    \"follow_up\": \"When the next visit is.\"\n",
    "    }\n",
    "    \"\"\",\n",
    "        \"Admin_Notes\": \"\"\"\n",
    "    TASK: Extract 'Administrative / Practical Notes'.\n",
    "    Respond *only* with a JSON object using this exact schema:\n",
    "    {\n",
    "    \"refills\": \"Any medications refilled.\",\n",
    "    \"code_status\": \"e.g., Full code, DNR\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    }\n",
    "\n",
    "    extracted_data = {}\n",
    "\n",
    "    # myprint(\"\\n--- 2. Running EFFICIENT 'Branching' Extractions ---\")\n",
    "\n",
    "    # (Assuming `run_model_with_cache_manual` is your function `run_model_with_cache`)\n",
    "    # If not, please rename this call to `run_model_with_cache`\n",
    "    run_model_function = run_model_with_cache_manual \n",
    "\n",
    "    for key, task in extraction_prompts.items():\n",
    "        # myprint(f\"\\nExtracting: {key}...\")\n",
    "        \n",
    "        # --- FIX 4: Remove the BOS token from the loop ---\n",
    "        # The base_cache *already* contains the BOS token.\n",
    "        # Adding it again can cause errors.\n",
    "        task_prompt = (\n",
    "            f\"<|start_header_id|>user<|end_header_id|>\\n\\n\" # <-- Removed <|begin_of_text|>\n",
    "            f\"{task}\" # <-- Use the new, detailed prompt\n",
    "            f\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        )\n",
    "\n",
    "        # Use the SAME base_cache for each extraction\n",
    "        answer, returned_cache = run_model_function(\n",
    "            task_prompt, \n",
    "            model, \n",
    "            tokenizer, \n",
    "            gen_config, \n",
    "            kv_cache=base_cache\n",
    "        )\n",
    "        \n",
    "        # Your memory management here is good.\n",
    "        del returned_cache\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # myprint(f\"  Raw Output: {answer}\")\n",
    "        \n",
    "        try:\n",
    "            # We are now *only* expecting a JSON object\n",
    "            clean_answer = answer.strip().strip(\"```json\").strip(\"```\").strip()\n",
    "            extracted_data[key] = json.loads(clean_answer)\n",
    "        except json.JSONDecodeError:\n",
    "            extracted_data[key] = {\"error\": \"Failed to parse JSON\", \"raw\": answer}\n",
    "\n",
    "    # myprint(\"\\n--- 3. All extractions complete. ---\")\n",
    "    # myprint(\"\\n--- FINAL EXTRACTED DATA ---\")\n",
    "    res.append(json.dumps(extracted_data, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2c87f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf=[json.loads(r) for r in res]\n",
    "for i in range(2):\n",
    "    test_note=df.iloc[i]['note_text']\n",
    "    resdf[i]['note']=test_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcc8ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf=pd.DataFrame(resdf)\n",
    "resdf.to_csv(\"keysummaryv1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4fa9ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_for_Visit</th>\n",
       "      <th>What_We_Found</th>\n",
       "      <th>Treatment_Summary</th>\n",
       "      <th>What_We_Discussed</th>\n",
       "      <th>Plan_Going_Forward</th>\n",
       "      <th>Admin_Notes</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'visit_type': 'Ongoing management and treatme...</td>\n",
       "      <td>{'imaging_summary': 'Extensive osseous metasta...</td>\n",
       "      <td>{'current_meds': 'capecitabine (XELODA) 1500 m...</td>\n",
       "      <td>{'goals_of_treatment': 'Palliative', 'response...</td>\n",
       "      <td>{'medication_plan': 'Continue xeloda 1500mg BI...</td>\n",
       "      <td>{'refills': '', 'code_status': ''}</td>\n",
       "      <td>We performed this consultation using real-time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'visit_type': 'Follow-up', 'summary': 'The pa...</td>\n",
       "      <td>{'imaging_summary': 'PET/CT: significant impro...</td>\n",
       "      <td>{'current_meds': 'leuprolide, letrozole, zoled...</td>\n",
       "      <td>{'goals_of_treatment': 'Prolongation of life, ...</td>\n",
       "      <td>{'medication_plan': 'Continue leuprolide every...</td>\n",
       "      <td>{'refills': 'calcium citrate/vitamin D3 (CITRA...</td>\n",
       "      <td>ID: ***** ***** is a 39 y.o. premenopausal pat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Reason_for_Visit  \\\n",
       "0  {'visit_type': 'Ongoing management and treatme...   \n",
       "1  {'visit_type': 'Follow-up', 'summary': 'The pa...   \n",
       "\n",
       "                                       What_We_Found  \\\n",
       "0  {'imaging_summary': 'Extensive osseous metasta...   \n",
       "1  {'imaging_summary': 'PET/CT: significant impro...   \n",
       "\n",
       "                                   Treatment_Summary  \\\n",
       "0  {'current_meds': 'capecitabine (XELODA) 1500 m...   \n",
       "1  {'current_meds': 'leuprolide, letrozole, zoled...   \n",
       "\n",
       "                                   What_We_Discussed  \\\n",
       "0  {'goals_of_treatment': 'Palliative', 'response...   \n",
       "1  {'goals_of_treatment': 'Prolongation of life, ...   \n",
       "\n",
       "                                  Plan_Going_Forward  \\\n",
       "0  {'medication_plan': 'Continue xeloda 1500mg BI...   \n",
       "1  {'medication_plan': 'Continue leuprolide every...   \n",
       "\n",
       "                                         Admin_Notes  \\\n",
       "0                 {'refills': '', 'code_status': ''}   \n",
       "1  {'refills': 'calcium citrate/vitamin D3 (CITRA...   \n",
       "\n",
       "                                                note  \n",
       "0  We performed this consultation using real-time...  \n",
       "1  ID: ***** ***** is a 39 y.o. premenopausal pat...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
